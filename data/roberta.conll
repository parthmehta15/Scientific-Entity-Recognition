-DOCSTART- -X- O
Table -X- _ O
10 -X- _ O
: -X- _ O
Hyperparameters -X- _ O
for -X- _ O
ﬁnetuning -X- _ O
RoBERTaLARGE -X- _ B-MethodName
on -X- _ O
RACE -X- _ B-DatasetName
, -X- _ O
SQuAD -X- _ B-DatasetName
and -X- _ O
GLUE -X- _ B-DatasetName
. -X- _ O

Number -X- _ O
of -X- _ O
Layers -X- _ O
24 -X- _ O
12 -X- _ O
Hidden -X- _ O
size -X- _ O
1024 -X- _ O
768 -X- _ O
FFN -X- _ O
inner -X- _ O
hidden -X- _ O
size -X- _ O
4096 -X- _ O
3072 -X- _ O
Attention -X- _ O
heads -X- _ O
16 -X- _ O
12 -X- _ O
Attention -X- _ O
head -X- _ O
size -X- _ O
64 -X- _ O
64 -X- _ O
Dropout -X- _ O
0.1 -X- _ O
0.1 -X- _ O
Attention -X- _ O
Dropout -X- _ O
0.1 -X- _ O
0.1 -X- _ O
Warmup -X- _ O
Steps -X- _ O
30k -X- _ O
24k -X- _ O
Peak -X- _ O
Learning -X- _ O
Rate -X- _ O
4e-4 -X- _ O
6e-4 -X- _ O
Batch -X- _ O
Size -X- _ O
8k -X- _ O
8k -X- _ O
Weight -X- _ O
Decay -X- _ O
0.01 -X- _ O
0.01 -X- _ O
Max -X- _ O
Steps -X- _ O
500k -X- _ O
500k -X- _ O
Learning -X- _ O
Rate -X- _ O
Decay -X- _ O
Linear -X- _ O
Linear -X- _ O
Adam -X- _ O
ǫ -X- _ O
1e-6 -X- _ O
1e-6 -X- _ O
Adam -X- _ O
β1 -X- _ O
0.9 -X- _ O
0.9 -X- _ O
Adam -X- _ O
β2 -X- _ O
0.98 -X- _ O
0.98 -X- _ O
Gradient -X- _ O
Clipping -X- _ O
0.0 -X- _ O
0.0 -X- _ O

Learning -X- _ B-HyperparameterName
Rate -X- _ I-HyperparameterName
1e-5 -X- _ O
1.5e-5 -X- _ O
{ -X- _ O
1e-5 -X- _ O
, -X- _ O
2e-5 -X- _ O
, -X- _ O
3e-5 -X- _ O
} -X- _ O
Batch -X- _ B-HyperparameterName
Size -X- _ I-HyperparameterName
16 -X- _ O
48 -X- _ O
{ -X- _ O
16 -X- _ O
, -X- _ O
32 -X- _ O
} -X- _ O
Weight -X- _ B-HyperparameterName
Decay -X- _ I-HyperparameterName
0.1 -X- _ O
0.01 -X- _ O
0.1 -X- _ O
Max -X- _ B-HyperparameterName
Epochs -X- _ I-HyperparameterName
4 -X- _ O
2 -X- _ O
10 -X- _ O
Learning -X- _ B-HyperparameterName
Rate -X- _ I-HyperparameterName
Decay -X- _ I-HyperparameterName
Linear -X- _ O
Linear -X- _ O
Linear -X- _ O
Warmup -X- _ B-HyperparameterName
ratio -X- _ I-HyperparameterName
0.06 -X- _ O
0.06 -X- _ O
0.06 -X- _ O

Table -X- _ O
9 -X- _ O
: -X- _ O
Hyperparameters -X- _ O
for -X- _ O
pretraining -X- _ O
RoBERTaLARGE -X- _ B-MethodName
and -X- _ O
RoBERTaBASE -X- _ B-MethodName
. -X- _ O

Table -X- _ O
8 -X- _ O
: -X- _ O
Development -X- _ O
set -X- _ O
results -X- _ O
on -X- _ O
GLUE -X- _ B-TaskName
tasks -X- _ O
for -X- _ O
various -X- _ O
conﬁgurations -X- _ O
of -X- _ O
RoBERTa -X- _ B-MethodName
. -X- _ O

RoBERTaLARGE -X- _ B-MethodName
with -X- _ O
BOOKS -X- _ B-DatasetName
+ -X- _ O
WIKI -X- _ B-DatasetName
89.0 -X- _ O
93.9 -X- _ O
91.9 -X- _ O
84.5 -X- _ O
95.3 -X- _ O
90.2 -X- _ O
66.3 -X- _ O
91.6 -X- _ O
+ -X- _ O
additional -X- _ O
data -X- _ O
( -X- _ O
§ -X- _ O
3.2 -X- _ O
) -X- _ O
89.3 -X- _ O
94.0 -X- _ O
92.0 -X- _ O
82.7 -X- _ O
95.6 -X- _ O
91.4 -X- _ O
66.1 -X- _ O
92.2 -X- _ O
+ -X- _ O
pretrain -X- _ O
longer -X- _ O
300k -X- _ O
90.0 -X- _ O
94.5 -X- _ O
92.2 -X- _ O
83.3 -X- _ O
96.1 -X- _ O
91.1 -X- _ O
67.4 -X- _ O
92.3 -X- _ O
+ -X- _ O
pretrain -X- _ O
longer -X- _ O
500k -X- _ O
90.2 -X- _ O
94.7 -X- _ O
92.2 -X- _ O
86.6 -X- _ O
96.4 -X- _ O
90.9 -X- _ O
68.0 -X- _ O
92.4 -X- _ O

RoBERTaBASE -X- _ B-MethodName
+ -X- _ O
all -X- _ O
data -X- _ O
+ -X- _ O
500k -X- _ O
steps -X- _ O
87.6 -X- _ O
92.8 -X- _ O
91.9 -X- _ O
78.7 -X- _ O
94.8 -X- _ O
90.2 -X- _ O
63.6 -X- _ O
91.2 -X- _ O

Finetuning -X- _ O
hyperparameters -X- _ O
for -X- _ O
RACE -X- _ B-DatasetName
, -X- _ O
SQuAD -X- _ B-DatasetName
and -X- _ O
GLUE -X- _ B-DatasetName
are -X- _ O
given -X- _ O
in -X- _ O
Table -X- _ O
10 -X- _ O
. -X- _ O
We -X- _ O
select -X- _ O
the -X- _ O
best -X- _ O
hyperparameter -X- _ O
values -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
median -X- _ O
of -X- _ O
5 -X- _ O
random -X- _ O
seeds -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
. -X- _ O

Table -X- _ O
9 -X- _ O
describes -X- _ O
the -X- _ O
hyperparameters -X- _ O
for -X- _ O
pre- -X- _ O
training -X- _ O
of -X- _ O
RoBERTaLARGE -X- _ B-MethodName
and -X- _ O
RoBERTaBASE -X- _ B-MethodName

In -X- _ O
Table -X- _ O
8 -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
full -X- _ O
set -X- _ O
of -X- _ O
development -X- _ O
set -X- _ O
results -X- _ O
for -X- _ O
RoBERTa -X- _ B-MethodName
. -X- _ O
We -X- _ O
present -X- _ O
results -X- _ O
for -X- _ O
a -X- _ O
LARGE -X- _ O
conﬁguration -X- _ O
that -X- _ O
follows -X- _ O
BERTLARGE -X- _ B-MethodName
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
a -X- _ O
BASE -X- _ O
conﬁguration -X- _ O
that -X- _ O
follows -X- _ O
BERTBASE -X- _ B-MethodName
. -X- _ O

Appendix -X- _ O
for -X- _ O
“ -X- _ O
RoBERTa -X- _ B-MethodName
: -X- _ O
A -X- _ B-MethodName
Robustly -X- _ I-MethodName
Optimized -X- _ I-MethodName
BERT -X- _ I-MethodName
Pretraining -X- _ I-MethodName
Approach -X- _ I-MethodName
” -X- _ O

Yukun -X- _ O
Zhu -X- _ O
, -X- _ O
Ryan -X- _ O
Kiros -X- _ O
, -X- _ O
Richard -X- _ O
Zemel -X- _ O
, -X- _ O
Ruslan -X- _ O
Salakhutdinov -X- _ O
, -X- _ O
Raquel -X- _ O
Urtasun -X- _ O
, -X- _ O
Antonio -X- _ O
Torralba -X- _ O
, -X- _ O
and -X- _ O
Sanja -X- _ O
Fidler -X- _ O
. -X- _ O
2015 -X- _ O
. -X- _ O
Aligning -X- _ O
books -X- _ O
and -X- _ O
movies -X- _ O
: -X- _ O
Towards -X- _ O
story -X- _ O
- -X- _ O
like -X- _ O
visual -X- _ O
explanations -X- _ O
by -X- _ O
watch- -X- _ O
ing -X- _ O
movies -X- _ O
and -X- _ O
reading -X- _ O
books -X- _ O
. -X- _ O
In -X- _ O
arXiv -X- _ O
preprint -X- _ O
arXiv:1506.06724 -X- _ O
. -X- _ O

Rowan -X- _ O
Zellers -X- _ O
, -X- _ O
Ari -X- _ O
Holtzman -X- _ O
, -X- _ O
Hannah -X- _ O
Rashkin -X- _ O
, -X- _ O
Yonatan -X- _ O
Bisk -X- _ O
, -X- _ O
Ali -X- _ O
Farhadi -X- _ O
, -X- _ O
Franziska -X- _ O
Roesner -X- _ O
, -X- _ O
and -X- _ O
Yejin -X- _ O
Choi -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O
Defending -X- _ O
against -X- _ O
neural -X- _ O
fake -X- _ O
news -X- _ O
. -X- _ O
arXiv -X- _ O
preprint -X- _ O
arXiv:1905.12616 -X- _ O
. -X- _ O

Yang -X- _ O
You -X- _ O
, -X- _ O
Jing -X- _ O
Li -X- _ O
, -X- _ O
Jonathan -X- _ O
Hseu -X- _ O
, -X- _ O
Xiaodan -X- _ O
Song -X- _ O
, -X- _ O
James -X- _ O
Demmel -X- _ O
, -X- _ O
and -X- _ O
Cho -X- _ O
- -X- _ O
Jui -X- _ O
Hsieh -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O
Reduc- -X- _ O
ing -X- _ O
bert -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
time -X- _ O
from -X- _ O
3 -X- _ O
days -X- _ O
to -X- _ O
76 -X- _ O
minutes -X- _ O
. -X- _ O
arXiv -X- _ O
preprint -X- _ O
arXiv:1904.00962 -X- _ O
. -X- _ O

Zhilin -X- _ O
Yang -X- _ O
, -X- _ O
Zihang -X- _ O
Dai -X- _ O
, -X- _ O
Yiming -X- _ O
Yang -X- _ O
, -X- _ O
Jaime -X- _ O
Car- -X- _ O
bonell -X- _ O
, -X- _ O
Ruslan -X- _ O
Salakhutdinov -X- _ O
, -X- _ O
and -X- _ O
Quoc -X- _ O
V -X- _ O
Le -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O
Xlnet -X- _ O
: -X- _ O
Generalized -X- _ O
autoregressive -X- _ O
pretrain- -X- _ O
ing -X- _ O
for -X- _ O
language -X- _ O
understanding -X- _ O
. -X- _ O
arXiv -X- _ O
preprint -X- _ O
arXiv:1906.08237 -X- _ O
. -X- _ O

Adina -X- _ O
Williams -X- _ O
, -X- _ O
Nikita -X- _ O
Nangia -X- _ O
, -X- _ O
and -X- _ O
Samuel -X- _ O
Bowman -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O
A -X- _ O
broad -X- _ O
- -X- _ O
coverage -X- _ O
challenge -X- _ O
corpus -X- _ O
for -X- _ O
sen- -X- _ O
tence -X- _ O
understanding -X- _ O
through -X- _ O
inference -X- _ O
. -X- _ O
In -X- _ O
North -X- _ O
American -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguis- -X- _ O
tics -X- _ O
( -X- _ O
NAACL -X- _ O
) -X- _ O
. -X- _ O

Alex -X- _ O
Warstadt -X- _ O
, -X- _ O
Amanpreet -X- _ O
Singh -X- _ O
, -X- _ O
and -X- _ O
Samuel -X- _ O
R. -X- _ O
Bow- -X- _ O
man -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O
Neural -X- _ O
network -X- _ O
acceptability -X- _ O
judg- -X- _ O
ments -X- _ O
. -X- _ O
arXiv -X- _ O
preprint -X- _ O
1805.12471 -X- _ O
. -X- _ O

Alex -X- _ O
Wang -X- _ O
, -X- _ O
Amanpreet -X- _ O
Singh -X- _ O
, -X- _ O
Julian -X- _ O
Michael -X- _ O
, -X- _ O
Felix -X- _ O
Hill -X- _ O
, -X- _ O
Omer -X- _ O
Levy -X- _ O
, -X- _ O
and -X- _ O
Samuel -X- _ O
R. -X- _ O
Bowman -X- _ O
. -X- _ O
2019b -X- _ O
. -X- _ O
GLUE -X- _ B-MethodName
: -X- _ O
A -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
benchmark -X- _ O
and -X- _ O
analysis -X- _ O
plat- -X- _ O
form -X- _ O
for -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
. -X- _ O
In -X- _ O
Inter- -X- _ O
national -X- _ O
Conference -X- _ O
on -X- _ O
Learning -X- _ O
Representations -X- _ O
( -X- _ O
ICLR -X- _ O
) -X- _ O
. -X- _ O

Alex -X- _ O
Wang -X- _ O
, -X- _ O
Yada -X- _ O
Pruksachatkun -X- _ O
, -X- _ O
Nikita -X- _ O
Nangia -X- _ O
, -X- _ O
Amanpreet -X- _ O
Singh -X- _ O
, -X- _ O
Julian -X- _ O
Michael -X- _ O
, -X- _ O
Felix -X- _ O
Hill -X- _ O
, -X- _ O
Omer -X- _ O
Levy -X- _ O
, -X- _ O
and -X- _ O
Samuel -X- _ O
R. -X- _ O
Bowman -X- _ O
. -X- _ O
2019a -X- _ O
. -X- _ O
SuperGLUE -X- _ B-MethodName
: -X- _ O
A -X- _ O
stickier -X- _ O
benchmark -X- _ O
for -X- _ O
general -X- _ O
- -X- _ O
purpose -X- _ O
language -X- _ O
understanding -X- _ O
systems -X- _ O
. -X- _ O
arXiv -X- _ O
preprint -X- _ O
1905.00537 -X- _ O
. -X- _ O

Ashish -X- _ O
Vaswani -X- _ O
, -X- _ O
Noam -X- _ O
Shazeer -X- _ O
, -X- _ O
Niki -X- _ O
Parmar -X- _ O
, -X- _ O
Jakob -X- _ O
Uszkoreit -X- _ O
, -X- _ O
Llion -X- _ O
Jones -X- _ O
, -X- _ O
Aidan -X- _ O
N -X- _ O
Gomez -X- _ O
, -X- _ O
Łukasz -X- _ O
Kaiser -X- _ O
, -X- _ O
and -X- _ O
Illia -X- _ O
Polosukhin -X- _ O
. -X- _ O
2017 -X- _ O
. -X- _ O
Attention -X- _ O
is -X- _ O
all -X- _ O
you -X- _ O
need -X- _ O
. -X- _ O
In -X- _ O
Advances -X- _ O
in -X- _ O
neural -X- _ O
information -X- _ O
pro- -X- _ O
cessing -X- _ O
systems -X- _ O
. -X- _ O

Trieu -X- _ O
H -X- _ O
Trinh -X- _ O
and -X- _ O
Quoc -X- _ O
V -X- _ O
Le -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O
A -X- _ O
simple -X- _ O
method -X- _ O
for -X- _ O
commonsense -X- _ O
reasoning -X- _ O
. -X- _ O
arXiv -X- _ O
preprint -X- _ O
arXiv:1806.02847 -X- _ O
. -X- _ O

Yu -X- _ O
Stephanie -X- _ O
Sun -X- _ O
, -X- _ O
Shuohuan -X- _ O
Wang -X- _ O
, -X- _ O
Yukun -X- _ O
Li -X- _ O
, -X- _ O
Shikun -X- _ O
Feng -X- _ O
, -X- _ O
Xuyi -X- _ O
Chen -X- _ O
, -X- _ O
Han -X- _ O
Zhang -X- _ O
, -X- _ O
Xinlun -X- _ O
Tian -X- _ O
, -X- _ O
Danxi- -X- _ O
ang -X- _ O
Zhu -X- _ O
, -X- _ O
Hao -X- _ O
Tian -X- _ O
, -X- _ O
and -X- _ O
Hua -X- _ O
Wu -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O
ERNIE -X- _ O
: -X- _ O
En- -X- _ O
hanced -X- _ O
representation -X- _ O
through -X- _ O
knowledge -X- _ O
integra- -X- _ O
tion -X- _ O
. -X- _ O
arXiv -X- _ O
preprint -X- _ O
arXiv:1904.09223 -X- _ O
. -X- _ O

Kaitao -X- _ O
Song -X- _ O
, -X- _ O
Xu -X- _ O
Tan -X- _ O
, -X- _ O
Tao -X- _ O
Qin -X- _ O
, -X- _ O
Jianfeng -X- _ O
Lu -X- _ O
, -X- _ O
and -X- _ O
Tie -X- _ O
- -X- _ O
Yan -X- _ O
Liu -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O
MASS -X- _ O
: -X- _ O
Masked -X- _ O
sequence -X- _ O
to -X- _ O
sequence -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
for -X- _ O
language -X- _ O
generation -X- _ O
. -X- _ O
In -X- _ O
International -X- _ O
Conference -X- _ O
on -X- _ O
Machine -X- _ O
Learning -X- _ O
( -X- _ O
ICML -X- _ O
) -X- _ O
. -X- _ O

Richard -X- _ O
Socher -X- _ O
, -X- _ O
Alex -X- _ O
Perelygin -X- _ O
, -X- _ O
Jean -X- _ O
Wu -X- _ O
, -X- _ O
Jason -X- _ O
Chuang -X- _ O
, -X- _ O
Christopher -X- _ O
D -X- _ O
Manning -X- _ O
, -X- _ O
Andrew -X- _ O
Ng -X- _ O
, -X- _ O
and -X- _ O
Christopher -X- _ O
Potts -X- _ O
. -X- _ O
2013 -X- _ O
. -X- _ O
Recursive -X- _ O
deep -X- _ O
models -X- _ O
for -X- _ O
semantic -X- _ O
compositionality -X- _ O
over -X- _ O
a -X- _ O
sentiment -X- _ O
tree- -X- _ O
bank -X- _ O
. -X- _ O
In -X- _ O
Empirical -X- _ O
Methods -X- _ O
in -X- _ O
Natural -X- _ O
Language -X- _ O
Processing -X- _ O
( -X- _ O
EMNLP -X- _ O
) -X- _ O
. -X- _ O

Rico -X- _ O
Sennrich -X- _ O
, -X- _ O
Barry -X- _ O
Haddow -X- _ O
, -X- _ O
and -X- _ O
Alexandra -X- _ O
Birch -X- _ O
. -X- _ O
2016 -X- _ O
. -X- _ O
Neural -X- _ O
machine -X- _ O
translation -X- _ O
of -X- _ O
rare -X- _ O
words -X- _ O
with -X- _ O
subword -X- _ O
units -X- _ O
. -X- _ O
In -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
( -X- _ O
ACL -X- _ O
) -X- _ O
, -X- _ O
pages -X- _ O
1715–1725 -X- _ O
. -X- _ O

Pranav -X- _ O
Rajpurkar -X- _ O
, -X- _ O
Jian -X- _ O
Zhang -X- _ O
, -X- _ O
Konstantin -X- _ O
Lopyrev -X- _ O
, -X- _ O
and -X- _ O
Percy -X- _ O
Liang -X- _ O
. -X- _ O
2016 -X- _ O
. -X- _ O
SQuAD -X- _ B-DatasetName
: -X- _ O
100,000 -X- _ O
+ -X- _ O
questions -X- _ O
for -X- _ O
machine -X- _ O
comprehension -X- _ O
of -X- _ O
text -X- _ O
. -X- _ O
In -X- _ O
Empirical -X- _ O
Meth- -X- _ O
ods -X- _ O
in -X- _ O
Natural -X- _ B-TaskName
Language -X- _ I-TaskName
Processing -X- _ I-TaskName
( -X- _ O
EMNLP -X- _ O
) -X- _ O
. -X- _ O

Alec -X- _ O
Radford -X- _ O
, -X- _ O
Karthik -X- _ O
Narasimhan -X- _ O
, -X- _ O
Time -X- _ O
Salimans -X- _ O
, -X- _ O
and -X- _ O
Ilya -X- _ O
Sutskever -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O
Improving -X- _ O
language -X- _ O
un- -X- _ O
derstanding -X- _ O
with -X- _ O
unsupervised -X- _ O
learning -X- _ O
. -X- _ O
Technical -X- _ O
report -X- _ O
, -X- _ O
OpenAI -X- _ O
. -X- _ O

Pranav -X- _ O
Rajpurkar -X- _ O
, -X- _ O
Robin -X- _ O
Jia -X- _ O
, -X- _ O
and -X- _ O
Percy -X- _ O
Liang -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O
Know -X- _ O
what -X- _ O
you -X- _ O
do -X- _ O
n’t -X- _ O
know -X- _ O
: -X- _ O
Unanswerable -X- _ O
ques- -X- _ O
tions -X- _ O
for -X- _ O
squad -X- _ O
. -X- _ O
In -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
( -X- _ O
ACL -X- _ O
) -X- _ O
. -X- _ O

Alec -X- _ O
Radford -X- _ O
, -X- _ O
Jeffrey -X- _ O
Wu -X- _ O
, -X- _ O
Rewon -X- _ O
Child -X- _ O
, -X- _ O
David -X- _ O
Luan -X- _ O
, -X- _ O
Dario -X- _ O
Amodei -X- _ O
, -X- _ O
and -X- _ O
Ilya -X- _ O
Sutskever -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O
Language -X- _ O
models -X- _ O
are -X- _ O
unsupervised -X- _ O
multitask -X- _ O
learners -X- _ O
. -X- _ O
Techni- -X- _ O
cal -X- _ O
report -X- _ O
, -X- _ O
OpenAI -X- _ O
. -X- _ O

Matthew -X- _ O
Peters -X- _ O
, -X- _ O
Mark -X- _ O
Neumann -X- _ O
, -X- _ O
Mohit -X- _ O
Iyyer -X- _ O
, -X- _ O
Matt -X- _ O
Gardner -X- _ O
, -X- _ O
Christopher -X- _ O
Clark -X- _ O
, -X- _ O
Kenton -X- _ O
Lee -X- _ O
, -X- _ O
and -X- _ O
Luke -X- _ O
Zettlemoyer -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O
Deep -X- _ O
contextualized -X- _ O
word -X- _ O
repre- -X- _ O
sentations -X- _ O
. -X- _ O
In -X- _ O
North -X- _ O
American -X- _ O
Association -X- _ O
for -X- _ O
Com- -X- _ O
putational -X- _ O
Linguistics -X- _ O
( -X- _ O
NAACL -X- _ O
) -X- _ O
. -X- _ O

Adam -X- _ O
Paszke -X- _ O
, -X- _ O
Sam -X- _ O
Gross -X- _ O
, -X- _ O
Soumith -X- _ O
Chintala -X- _ O
, -X- _ O
Gre- -X- _ O
gory -X- _ O
Chanan -X- _ O
, -X- _ O
Edward -X- _ O
Yang -X- _ O
, -X- _ O
Zachary -X- _ O
DeVito -X- _ O
, -X- _ O
Zem- -X- _ O
ing -X- _ O
Lin -X- _ O
, -X- _ O
Alban -X- _ O
Desmaison -X- _ O
, -X- _ O
Luca -X- _ O
Antiga -X- _ O
, -X- _ O
and -X- _ O
Adam -X- _ O
Lerer -X- _ O
. -X- _ O
2017 -X- _ O
. -X- _ O
Automatic -X- _ O
differentiation -X- _ O
in -X- _ O
PyTorch -X- _ B-MethodName
. -X- _ O
In -X- _ O
NIPS -X- _ O
Autodiff -X- _ O
Workshop -X- _ O
. -X- _ O

Myle -X- _ O
Ott -X- _ O
, -X- _ O
Sergey -X- _ O
Edunov -X- _ O
, -X- _ O
David -X- _ O
Grangier -X- _ O
, -X- _ O
and -X- _ O
Michael -X- _ O
Auli -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O
Scaling -X- _ O
neural -X- _ O
machine -X- _ O
trans- -X- _ O
lation -X- _ O
. -X- _ O
In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
Third -X- _ O
Conference -X- _ O
on -X- _ O
Machine -X- _ O
Translation -X- _ O
( -X- _ O
WMT -X- _ O
) -X- _ O
. -X- _ O

Myle -X- _ O
Ott -X- _ O
, -X- _ O
Sergey -X- _ O
Edunov -X- _ O
, -X- _ O
Alexei -X- _ O
Baevski -X- _ O
, -X- _ O
Angela -X- _ O
Fan -X- _ O
, -X- _ O
Sam -X- _ O
Gross -X- _ O
, -X- _ O
Nathan -X- _ O
Ng -X- _ O
, -X- _ O
David -X- _ O
Grangier -X- _ O
, -X- _ O
and -X- _ O
Michael -X- _ O
Auli -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O
FAIRSEQ -X- _ B-MethodName
: -X- _ O
A -X- _ O
fast -X- _ O
, -X- _ O
exten- -X- _ O
sible -X- _ O
toolkit -X- _ O
for -X- _ O
sequence -X- _ O
modeling -X- _ O
. -X- _ O
In -X- _ O
North -X- _ O
American -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguis- -X- _ O
tics -X- _ O
( -X- _ O
NAACL -X- _ O
): -X- _ O
System -X- _ O
Demonstrations -X- _ O
. -X- _ O

Sebastian -X- _ O
Nagel -X- _ O
. -X- _ O
2016 -X- _ O
. -X- _ O
Cc -X- _ O
- -X- _ O
news -X- _ O
. -X- _ O
http -X- _ O
: -X- _ O
//web.archive.org -X- _ O
/ -X- _ O
save -X- _ O
/ -X- _ O
http -X- _ O
: -X- _ O
//commoncrawl.org/2016/10 -X- _ O
/ -X- _ O
news- -X- _ O
dataset -X- _ O
- -X- _ O
available -X- _ O
. -X- _ O

Paulius -X- _ O
Micikevicius -X- _ O
, -X- _ O
Sharan -X- _ O
Narang -X- _ O
, -X- _ O
Jonah -X- _ O
Alben -X- _ O
, -X- _ O
Gregory -X- _ O
Diamos -X- _ O
, -X- _ O
Erich -X- _ O
Elsen -X- _ O
, -X- _ O
David -X- _ O
Garcia -X- _ O
, -X- _ O
Boris -X- _ O
Ginsburg -X- _ O
, -X- _ O
Michael -X- _ O
Houston -X- _ O
, -X- _ O
Oleksii -X- _ O
Kuchaiev -X- _ O
, -X- _ O
Ganesh -X- _ O
Venkatesh -X- _ O
, -X- _ O
and -X- _ O
Hao -X- _ O
Wu -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O
Mixed -X- _ O
preci- -X- _ O
sion -X- _ O
training -X- _ O
. -X- _ O
In -X- _ O
International -X- _ O
Conference -X- _ O
on -X- _ O
Learn- -X- _ O
ing -X- _ O
Representations -X- _ O
. -X- _ O

Bryan -X- _ O
McCann -X- _ O
, -X- _ O
James -X- _ O
Bradbury -X- _ O
, -X- _ O
Caiming -X- _ O
Xiong -X- _ O
, -X- _ O
and -X- _ O
Richard -X- _ O
Socher -X- _ O
. -X- _ O
2017 -X- _ O
. -X- _ O
Learned -X- _ O
in -X- _ O
translation -X- _ O
: -X- _ O
Con- -X- _ O
textualized -X- _ O
word -X- _ O
vectors -X- _ O
. -X- _ O
In -X- _ O
Advances -X- _ O
in -X- _ O
Neural -X- _ O
In- -X- _ O
formation -X- _ O
Processing -X- _ O
Systems -X- _ O
( -X- _ O
NIPS -X- _ O
) -X- _ O
, -X- _ O
pages -X- _ O
6297 -X- _ O
– -X- _ O
6308 -X- _ O
. -X- _ O

Xiaodong -X- _ O
Liu -X- _ O
, -X- _ O
Pengcheng -X- _ O
He -X- _ O
, -X- _ O
Weizhu -X- _ O
Chen -X- _ O
, -X- _ O
and -X- _ O
Jian- -X- _ O
feng -X- _ O
Gao -X- _ O
. -X- _ O
2019b -X- _ O
. -X- _ O
Multi -X- _ O
- -X- _ O
task -X- _ O
deep -X- _ O
neural -X- _ O
networks -X- _ O
for -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
. -X- _ O
arXiv -X- _ O
preprint -X- _ O
arXiv:1901.11504 -X- _ O
. -X- _ O

Xiaodong -X- _ O
Liu -X- _ O
, -X- _ O
Pengcheng -X- _ O
He -X- _ O
, -X- _ O
Weizhu -X- _ O
Chen -X- _ O
, -X- _ O
and -X- _ O
Jianfeng -X- _ O
Gao -X- _ O
. -X- _ O
2019a -X- _ O
. -X- _ O
Improving -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
deep -X- _ O
neural -X- _ O
networks -X- _ O
via -X- _ O
knowledge -X- _ O
distillation -X- _ O
for -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
. -X- _ O
arXiv -X- _ O
preprint -X- _ O
arXiv:1904.09482 -X- _ O
. -X- _ O

Hector -X- _ O
J -X- _ O
Levesque -X- _ O
, -X- _ O
Ernest -X- _ O
Davis -X- _ O
, -X- _ O
and -X- _ O
Leora -X- _ O
Morgen- -X- _ O
stern -X- _ O
. -X- _ O
2011 -X- _ O
. -X- _ O
The -X- _ O
Winograd -X- _ O
schema -X- _ O
challenge -X- _ O
. -X- _ O
In -X- _ O
AAAI -X- _ O
Spring -X- _ O
Symposium -X- _ O
: -X- _ O
Logical -X- _ O
Formalizations -X- _ O
of -X- _ O
Commonsense -X- _ O
Reasoning -X- _ O
. -X- _ O

Guillaume -X- _ O
Lample -X- _ O
and -X- _ O
Alexis -X- _ O
Conneau -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O
Cross- -X- _ O
lingual -X- _ O
language -X- _ O
model -X- _ O
pretraining -X- _ O
. -X- _ O
arXiv -X- _ O
preprint -X- _ O
arXiv:1901.07291 -X- _ O
. -X- _ O

Guokun -X- _ O
Lai -X- _ O
, -X- _ O
Qizhe -X- _ O
Xie -X- _ O
, -X- _ O
Hanxiao -X- _ O
Liu -X- _ O
, -X- _ O
Yiming -X- _ O
Yang -X- _ O
, -X- _ O
and -X- _ O
Eduard -X- _ O
Hovy -X- _ O
. -X- _ O
2017 -X- _ O
. -X- _ O
Race -X- _ B-DatasetName
: -X- _ O
Large -X- _ O
- -X- _ O
scale -X- _ O
reading -X- _ O
comprehension -X- _ O
dataset -X- _ O
from -X- _ O
examinations -X- _ O
. -X- _ O
arXiv -X- _ O
preprint -X- _ O
arXiv:1704.04683 -X- _ O
. -X- _ O

Vid -X- _ O
Kocijan -X- _ O
, -X- _ O
Ana -X- _ O
- -X- _ O
Maria -X- _ O
Cretu -X- _ O
, -X- _ O
Oana -X- _ O
- -X- _ O
Maria -X- _ O
Camburu -X- _ O
, -X- _ O
Yordan -X- _ O
Yordanov -X- _ O
, -X- _ O
and -X- _ O
Thomas -X- _ O
Lukasiewicz -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O
A -X- _ O
surprisingly -X- _ O
robust -X- _ O
trick -X- _ O
for -X- _ O
winograd -X- _ O
schema -X- _ O
challenge -X- _ O
. -X- _ O
arXiv -X- _ O
preprint -X- _ O
arXiv:1905.06290 -X- _ O
. -X- _ O

Diederik -X- _ O
Kingma -X- _ O
and -X- _ O
Jimmy -X- _ O
Ba -X- _ O
. -X- _ O
2015 -X- _ O
. -X- _ O
Adam -X- _ O
: -X- _ O
A -X- _ O
method -X- _ O
for -X- _ O
stochastic -X- _ O
optimization -X- _ O
. -X- _ O
In -X- _ O
International -X- _ O
Conference -X- _ O
on -X- _ O
Learning -X- _ O
Representations -X- _ O
( -X- _ O
ICLR -X- _ O
) -X- _ O
. -X- _ O

Mandar -X- _ O
Joshi -X- _ O
, -X- _ O
Danqi -X- _ O
Chen -X- _ O
, -X- _ O
Yinhan -X- _ O
Liu -X- _ O
, -X- _ O
Daniel -X- _ O
S. -X- _ O
Weld -X- _ O
, -X- _ O
Luke -X- _ O
Zettlemoyer -X- _ O
, -X- _ O
and -X- _ O
Omer -X- _ O
Levy -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O
SpanBERT -X- _ B-MethodName
: -X- _ O
Improving -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
by -X- _ O
repre- -X- _ O
senting -X- _ O
and -X- _ O
predicting -X- _ O
spans -X- _ O
. -X- _ O
arXiv -X- _ O
preprint -X- _ O
arXiv:1907.10529 -X- _ O
. -X- _ O

Shankar -X- _ O
Iyer -X- _ O
, -X- _ O
Nikhil -X- _ O
Dandekar -X- _ O
, -X- _ O
and -X- _ O
Kornl -X- _ O
Cser- -X- _ O
nai -X- _ O
. -X- _ O
2016 -X- _ O
. -X- _ O
First -X- _ O
quora -X- _ O
dataset -X- _ O
release -X- _ O
: -X- _ O
Question -X- _ O
pairs -X- _ O
. -X- _ O
https://data.quora.com/First- -X- _ O
Quora -X- _ O
- -X- _ O
Dataset -X- _ O
- -X- _ O
Release -X- _ O
- -X- _ O
Question- -X- _ O
Pairs -X- _ O
. -X- _ O

Jeremy -X- _ O
Howard -X- _ O
and -X- _ O
Sebastian -X- _ O
Ruder -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O
Universal -X- _ O
language -X- _ O
model -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
for -X- _ O
text -X- _ B-TaskName
classiﬁcation -X- _ I-TaskName
. -X- _ O
arXiv -X- _ O
preprint -X- _ O
arXiv:1801.06146 -X- _ O
. -X- _ O

Matthew -X- _ O
Honnibal -X- _ O
and -X- _ O
Ines -X- _ O
Montani -X- _ O
. -X- _ O
2017 -X- _ O
. -X- _ O
spaCy -X- _ O
2 -X- _ O
: -X- _ O
Natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
with -X- _ O
Bloom -X- _ O
embed- -X- _ O
dings -X- _ O
, -X- _ O
convolutional -X- _ O
neural -X- _ O
networks -X- _ O
and -X- _ O
incremen- -X- _ O
tal -X- _ O
parsing -X- _ O
. -X- _ O
To -X- _ O
appear -X- _ O
. -X- _ O

Dan -X- _ O
Hendrycks -X- _ O
and -X- _ O
Kevin -X- _ O
Gimpel -X- _ O
. -X- _ O
2016 -X- _ O
. -X- _ O
Gaus- -X- _ O
sian -X- _ O
error -X- _ O
linear -X- _ O
units -X- _ O
( -X- _ O
gelus -X- _ O
) -X- _ O
. -X- _ O
arXiv -X- _ O
preprint -X- _ O
arXiv:1606.08415 -X- _ O
. -X- _ O

Felix -X- _ O
Hamborg -X- _ O
, -X- _ O
Norman -X- _ O
Meuschke -X- _ O
, -X- _ O
Corinna -X- _ O
Bre- -X- _ O
itinger -X- _ O
, -X- _ O
and -X- _ O
Bela -X- _ O
Gipp -X- _ O
. -X- _ O
2017 -X- _ O
. -X- _ O
news -X- _ O
- -X- _ O
please -X- _ O
: -X- _ O
A -X- _ O
generic -X- _ O
news -X- _ O
crawler -X- _ O
and -X- _ O
extractor -X- _ O
. -X- _ O
In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
15th -X- _ O
International -X- _ O
Symposium -X- _ O
of -X- _ O
Information -X- _ O
Science -X- _ O
. -X- _ O

Aaron -X- _ O
Gokaslan -X- _ O
and -X- _ O
Vanya -X- _ O
Cohen -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O
Openweb- -X- _ O
text -X- _ O
corpus -X- _ O
. -X- _ O
http://web.archive.org/ -X- _ O
save -X- _ O
/ -X- _ O
http://Skylion007.github.io/ -X- _ O
OpenWebTextCorpus -X- _ O
. -X- _ O

Danilo -X- _ O
Giampiccolo -X- _ O
, -X- _ O
Bernardo -X- _ O
Magnini -X- _ O
, -X- _ O
Ido -X- _ O
Dagan -X- _ O
, -X- _ O
and -X- _ O
Bill -X- _ O
Dolan -X- _ O
. -X- _ O
2007 -X- _ O
. -X- _ O
The -X- _ O
third -X- _ O
PASCAL -X- _ O
recog- -X- _ O
nizing -X- _ O
textual -X- _ O
entailment -X- _ O
challenge -X- _ O
. -X- _ O
In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
ACL -X- _ O
- -X- _ O
PASCAL -X- _ O
workshop -X- _ O
on -X- _ O
textual -X- _ O
entailment -X- _ O
and -X- _ O
paraphrasing -X- _ O
. -X- _ O

Li -X- _ O
Dong -X- _ O
, -X- _ O
Nan -X- _ O
Yang -X- _ O
, -X- _ O
Wenhui -X- _ O
Wang -X- _ O
, -X- _ O
Furu -X- _ O
Wei -X- _ O
, -X- _ O
Xiaodong -X- _ O
Liu -X- _ O
, -X- _ O
Yu -X- _ O
Wang -X- _ O
, -X- _ O
Jianfeng -X- _ O
Gao -X- _ O
, -X- _ O
Ming -X- _ O
Zhou -X- _ O
, -X- _ O
and -X- _ O
Hsiao -X- _ O
- -X- _ O
Wuen -X- _ O
Hon -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O
Uniﬁed -X- _ O
language -X- _ O
model -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
for -X- _ O
natural -X- _ O
language -X- _ O
understanding -X- _ O
and -X- _ O
generation -X- _ O
. -X- _ O
arXiv -X- _ O
preprint -X- _ O
arXiv:1905.03197 -X- _ O
. -X- _ O

William -X- _ O
B -X- _ O
Dolan -X- _ O
and -X- _ O
Chris -X- _ O
Brockett -X- _ O
. -X- _ O
2005 -X- _ O
. -X- _ O
Auto- -X- _ O
matically -X- _ O
constructing -X- _ O
a -X- _ O
corpus -X- _ O
of -X- _ O
sentential -X- _ O
para- -X- _ O
phrases -X- _ O
. -X- _ O
In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
International -X- _ O
Work- -X- _ O
shop -X- _ O
on -X- _ O
Paraphrasing -X- _ O
. -X- _ O

Jacob -X- _ O
Devlin -X- _ O
, -X- _ O
Ming -X- _ O
- -X- _ O
Wei -X- _ O
Chang -X- _ O
, -X- _ O
Kenton -X- _ O
Lee -X- _ O
, -X- _ O
and -X- _ O
Kristina -X- _ O
Toutanova -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O
BERT -X- _ O
: -X- _ O
Pre -X- _ O
- -X- _ O
training -X- _ O
of -X- _ O
deep -X- _ O
bidirectional -X- _ O
transformers -X- _ O
for -X- _ O
language -X- _ O
under- -X- _ O
standing -X- _ O
. -X- _ O
In -X- _ O
North -X- _ O
American -X- _ O
Association -X- _ O
for -X- _ O
Com- -X- _ O
putational -X- _ O
Linguistics -X- _ O
( -X- _ O
NAACL -X- _ O
) -X- _ O
. -X- _ O

Andrew -X- _ O
M -X- _ O
Dai -X- _ O
and -X- _ O
Quoc -X- _ O
V -X- _ O
Le -X- _ O
. -X- _ O
2015 -X- _ O
. -X- _ O
Semi -X- _ O
- -X- _ O
supervised -X- _ O
sequence -X- _ O
learning -X- _ O
. -X- _ O
In -X- _ O
Advances -X- _ O
in -X- _ O
Neural -X- _ O
Informa- -X- _ O
tion -X- _ O
Processing -X- _ O
Systems -X- _ O
( -X- _ O
NIPS -X- _ O
) -X- _ O
. -X- _ O

Ido -X- _ O
Dagan -X- _ O
, -X- _ O
Oren -X- _ O
Glickman -X- _ O
, -X- _ O
and -X- _ O
Bernardo -X- _ O
Magnini -X- _ O
. -X- _ O
2006 -X- _ O
. -X- _ O
The -X- _ O
PASCAL -X- _ O
recognising -X- _ O
textual -X- _ O
entailment -X- _ O
challenge -X- _ O
. -X- _ O
In -X- _ O
Machine -X- _ O
learning -X- _ O
challenges -X- _ O
. -X- _ O
evalu- -X- _ O
ating -X- _ O
predictive -X- _ O
uncertainty -X- _ O
, -X- _ O
visual -X- _ O
object -X- _ O
classiﬁca- -X- _ O
tion -X- _ O
, -X- _ O
and -X- _ O
recognising -X- _ O
tectual -X- _ O
entailment -X- _ O
. -X- _ O

William -X- _ O
Chan -X- _ O
, -X- _ O
Nikita -X- _ O
Kitaev -X- _ O
, -X- _ O
Kelvin -X- _ O
Guu -X- _ O
, -X- _ O
Mitchell -X- _ O
Stern -X- _ O
, -X- _ O
and -X- _ O
Jakob -X- _ O
Uszkoreit -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O
KERMIT -X- _ O
: -X- _ O
Gener- -X- _ O
ative -X- _ O
insertion -X- _ O
- -X- _ O
based -X- _ O
modeling -X- _ O
for -X- _ O
sequences -X- _ O
. -X- _ O
arXiv -X- _ O
preprint -X- _ O
arXiv:1906.01604 -X- _ O
. -X- _ O

Samuel -X- _ O
R -X- _ O
Bowman -X- _ O
, -X- _ O
Gabor -X- _ O
Angeli -X- _ O
, -X- _ O
Christopher -X- _ O
Potts -X- _ O
, -X- _ O
and -X- _ O
Christopher -X- _ O
D -X- _ O
Manning -X- _ O
. -X- _ O
2015 -X- _ O
. -X- _ O
A -X- _ O
large -X- _ O
anno- -X- _ O
tated -X- _ O
corpus -X- _ O
for -X- _ O
learning -X- _ O
natural -X- _ O
language -X- _ O
inference -X- _ O
. -X- _ O
In -X- _ O
Empirical -X- _ O
Methods -X- _ O
in -X- _ O
Natural -X- _ B-TaskName
Language -X- _ I-TaskName
Process- -X- _ I-TaskName
ing -X- _ I-TaskName
( -X- _ O
EMNLP -X- _ B-TaskName
) -X- _ O
. -X- _ O

Luisa -X- _ O
Bentivogli -X- _ O
, -X- _ O
Ido -X- _ O
Dagan -X- _ O
, -X- _ O
Hoa -X- _ O
Trang -X- _ O
Dang -X- _ O
, -X- _ O
Danilo -X- _ O
Giampiccolo -X- _ O
, -X- _ O
and -X- _ O
Bernardo -X- _ O
Magnini -X- _ O
. -X- _ O
2009 -X- _ O
. -X- _ O
The -X- _ O
ﬁfth -X- _ O
PASCAL -X- _ O
recognizing -X- _ O
textual -X- _ O
entailment -X- _ O
chal- -X- _ O
lenge -X- _ O
. -X- _ O

Roy -X- _ O
Bar -X- _ O
- -X- _ O
Haim -X- _ O
, -X- _ O
Ido -X- _ O
Dagan -X- _ O
, -X- _ O
Bill -X- _ O
Dolan -X- _ O
, -X- _ O
Lisa -X- _ O
Ferro -X- _ O
, -X- _ O
Danilo -X- _ O
Giampiccolo -X- _ O
, -X- _ O
Bernardo -X- _ O
Magnini -X- _ O
, -X- _ O
and -X- _ O
Idan -X- _ O
Szpektor -X- _ O
. -X- _ O
2006 -X- _ O
. -X- _ O
The -X- _ O
second -X- _ O
PASCAL -X- _ O
recognising -X- _ O
textual -X- _ O
entailment -X- _ O
challenge -X- _ O
. -X- _ O
In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
second -X- _ O
PASCAL -X- _ O
challenges -X- _ O
workshop -X- _ O
on -X- _ O
recognis- -X- _ O
ing -X- _ O
textual -X- _ O
entailment -X- _ O
. -X- _ O

Alexei -X- _ O
Baevski -X- _ O
, -X- _ O
Sergey -X- _ O
Edunov -X- _ O
, -X- _ O
Yinhan -X- _ O
Liu -X- _ O
, -X- _ O
Luke -X- _ O
Zettlemoyer -X- _ O
, -X- _ O
and -X- _ O
Michael -X- _ O
Auli -X- _ O
. -X- _ O
2019 -X- _ O
. -X- _ O
Cloze- -X- _ O
driven -X- _ O
pretraining -X- _ O
of -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
networks -X- _ O
. -X- _ O
arXiv -X- _ O
preprint -X- _ O
arXiv:1903.07785 -X- _ O
. -X- _ O

Eneko -X- _ O
Agirre -X- _ O
, -X- _ O
Llu’is -X- _ O
M‘arquez -X- _ O
, -X- _ O
and -X- _ O
Richard -X- _ O
Wicen- -X- _ O
towski -X- _ O
, -X- _ O
editors -X- _ O
. -X- _ O
2007 -X- _ O
. -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
Fourth -X- _ O
International -X- _ O
Workshop -X- _ O
on -X- _ O
Semantic -X- _ O
Evaluations -X- _ O
( -X- _ O
SemEval-2007 -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
carefully -X- _ O
evaluate -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
design -X- _ O
de- -X- _ O
cisions -X- _ O
when -X- _ O
pretraining -X- _ O
BERT -X- _ B-MethodName
models -X- _ O
. -X- _ O
We -X- _ O
ﬁnd -X- _ O
that -X- _ O
performance -X- _ O
can -X- _ O
be -X- _ O
substantially -X- _ O
im- -X- _ O
proved -X- _ O
by -X- _ O
training -X- _ O
the -X- _ O
model -X- _ O
longer -X- _ O
, -X- _ O
with -X- _ O
bigger -X- _ O
batches -X- _ O
over -X- _ O
more -X- _ O
data -X- _ O
; -X- _ O
removing -X- _ O
the -X- _ O
next -X- _ O
sen- -X- _ O
tence -X- _ O
prediction -X- _ O
objective -X- _ O
; -X- _ O
training -X- _ O
on -X- _ O
longer -X- _ O
se- -X- _ O
quences -X- _ O
; -X- _ O
and -X- _ O
dynamically -X- _ O
changing -X- _ O
the -X- _ O
masking -X- _ O
pattern -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
Our -X- _ O
improved -X- _ O
pretraining -X- _ O
procedure -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
call -X- _ O
RoBERTa -X- _ B-MethodName
, -X- _ O
achieves -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
on -X- _ O
GLUE -X- _ B-DatasetName
, -X- _ O
RACE -X- _ B-DatasetName
and -X- _ O
SQuAD -X- _ B-DatasetName
, -X- _ O
without -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
ﬁnetuning -X- _ O
for -X- _ O
GLUE -X- _ B-DatasetName
or -X- _ O
additional -X- _ O
data -X- _ O
for -X- _ O
SQuAD -X- _ B-DatasetName
. -X- _ O
These -X- _ O
re- -X- _ O
sults -X- _ O
illustrate -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
these -X- _ O
previ- -X- _ O
ously -X- _ O
overlooked -X- _ O
design -X- _ O
decisions -X- _ O
and -X- _ O
suggest -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
’s -X- _ O
pretraining -X- _ O
objective -X- _ O
remains -X- _ O
com- -X- _ O
petitive -X- _ O
with -X- _ O
recently -X- _ O
proposed -X- _ O
alternatives -X- _ O
. -X- _ O
We -X- _ O
additionally -X- _ O
use -X- _ O
a -X- _ O
novel -X- _ O
dataset -X- _ O
, -X- _ O
CC -X- _ B-DatasetName
- -X- _ I-DatasetName
NEWS -X- _ I-DatasetName
, -X- _ O
and -X- _ O
release -X- _ O
our -X- _ O
models -X- _ O
and -X- _ O
code -X- _ O
for -X- _ O
pretraining -X- _ O
and -X- _ O
ﬁnetuning -X- _ O
at -X- _ O
: -X- _ O

2019 -X- _ O
; -X- _ O
Baevski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
goal -X- _ O
was -X- _ O
to -X- _ O
replicate -X- _ O
, -X- _ O
simplify -X- _ O
, -X- _ O
and -X- _ O
better -X- _ O
tune -X- _ O
the -X- _ O
training -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
as -X- _ O
a -X- _ O
reference -X- _ O
point -X- _ O
for -X- _ O
better -X- _ O
understanding -X- _ O
the -X- _ O
relative -X- _ O
performance -X- _ O
of -X- _ O
all -X- _ O
of -X- _ O
these -X- _ O
methods -X- _ O
. -X- _ O

Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Howard -X- _ O
and -X- _ O
Ruder -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
( -X- _ O
McCann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
masked -X- _ B-MethodName
language -X- _ I-MethodName
modeling -X- _ I-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Lample -X- _ O
and -X- _ O
Conneau -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Many -X- _ O
recent -X- _ O
papers -X- _ O
have -X- _ O
used -X- _ O
a -X- _ O
basic -X- _ O
recipe -X- _ O
of -X- _ O
ﬁnetuning -X- _ O
models -X- _ O
for -X- _ O
each -X- _ O
end -X- _ O
task -X- _ O
( -X- _ O
Howard -X- _ O
and -X- _ O
Ruder -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
pretraining -X- _ O
with -X- _ O
some -X- _ O
variant -X- _ O
of -X- _ O
a -X- _ O
masked -X- _ O
language -X- _ O
model -X- _ O
objective -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
newer -X- _ O
methods -X- _ O
have -X- _ O
improved -X- _ O
performance -X- _ O
by -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
ﬁne -X- _ O
tun- -X- _ O
ing -X- _ O
( -X- _ O
Dong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
incorporating -X- _ O
entity -X- _ O
embeddings -X- _ O
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
span -X- _ O
predic- -X- _ O
tion -X- _ O
( -X- _ O
Joshi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
multiple -X- _ O
variants -X- _ O
of -X- _ O
autoregressive -X- _ O
pretraining -X- _ O
( -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Chan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Perfor- -X- _ O
mance -X- _ O
is -X- _ O
also -X- _ O
typically -X- _ O
improved -X- _ O
by -X- _ O
training -X- _ O
bigger -X- _ O
models -X- _ O
on -X- _ O
more -X- _ O
data -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

Pretraining -X- _ O
methods -X- _ O
have -X- _ O
been -X- _ O
designed -X- _ O
with -X- _ O
different -X- _ O
training -X- _ O
objectives -X- _ O
, -X- _ O
includ- -X- _ O
ing -X- _ O
language -X- _ O
modeling -X- _ O
( -X- _ O
Dai -X- _ O
and -X- _ O
Le -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O

Results -X- _ O
on -X- _ O
the -X- _ O
RACE -X- _ B-DatasetName
test -X- _ O
sets -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
7 -X- _ O
. -X- _ O
RoBERTa -X- _ B-MethodName
achieves -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
on -X- _ O
both -X- _ O
middle -X- _ O
- -X- _ O
school -X- _ O
and -X- _ O
high -X- _ O
- -X- _ O
school -X- _ O
settings -X- _ O
. -X- _ O

nating -X- _ O
each -X- _ O
candidate -X- _ O
answer -X- _ O
with -X- _ O
the -X- _ O
correspond- -X- _ O
ing -X- _ O
question -X- _ O
and -X- _ O
passage -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
encode -X- _ O
each -X- _ O
of -X- _ O
these -X- _ O
four -X- _ O
sequences -X- _ O
and -X- _ O
pass -X- _ O
the -X- _ O
resulting -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
representations -X- _ O
through -X- _ O
a -X- _ O
fully -X- _ O
- -X- _ O
connected -X- _ O
layer -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
. -X- _ O
We -X- _ O
truncate -X- _ O
question -X- _ O
- -X- _ O
answer -X- _ O
pairs -X- _ O
that -X- _ O
are -X- _ O
longer -X- _ O
than -X- _ O
128 -X- _ O
tokens -X- _ O
and -X- _ O
, -X- _ O
if -X- _ O
needed -X- _ O
, -X- _ O
the -X- _ O
passage -X- _ O
so -X- _ O
that -X- _ O
the -X- _ O
total -X- _ O
length -X- _ O
is -X- _ O
at -X- _ O
most -X- _ O
512 -X- _ O
tokens -X- _ O
. -X- _ O

Table -X- _ O
7 -X- _ O
: -X- _ O
Results -X- _ O
on -X- _ O
the -X- _ O
RACE -X- _ B-DatasetName
test -X- _ O
set -X- _ O
. -X- _ O
BERTLARGE -X- _ B-MethodName
and -X- _ O
XLNetLARGE -X- _ B-MethodName
results -X- _ O
are -X- _ O
from -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

Single -X- _ O
models -X- _ O
on -X- _ O
test -X- _ O
( -X- _ O
as -X- _ O
of -X- _ O
July -X- _ O
25 -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
BERTLARGE -X- _ B-MethodName
72.0 -X- _ O
76.6 -X- _ O
70.1 -X- _ O
XLNetLARGE -X- _ B-MethodName
81.7 -X- _ O
85.4 -X- _ O
80.2 -X- _ O

In -X- _ O
RACE -X- _ B-DatasetName
, -X- _ O
systems -X- _ O
are -X- _ O
provided -X- _ O
with -X- _ O
a -X- _ O
passage -X- _ O
of -X- _ O
text -X- _ O
, -X- _ O
an -X- _ O
associated -X- _ O
question -X- _ O
, -X- _ O
and -X- _ O
four -X- _ O
candidate -X- _ O
an- -X- _ O
swers -X- _ O
. -X- _ O
Systems -X- _ O
are -X- _ O
required -X- _ O
to -X- _ O
classify -X- _ O
which -X- _ O
of -X- _ O
the -X- _ O
four -X- _ O
candidate -X- _ O
answers -X- _ O
is -X- _ O
correct -X- _ O
. -X- _ O
We -X- _ O
modify -X- _ O
RoBERTa -X- _ B-MethodName
for -X- _ O
this -X- _ O
task -X- _ O
by -X- _ O
concate- -X- _ O

Results -X- _ O
We -X- _ O
present -X- _ O
our -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
SQuAD -X- _ B-DatasetName
v1.1 -X- _ I-DatasetName
development -X- _ O
set -X- _ O
, -X- _ O
RoBERTa -X- _ B-MethodName
matches -X- _ O
the -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
set -X- _ O
by -X- _ O
XLNet -X- _ B-MethodName
. -X- _ O
On -X- _ O
the -X- _ O
SQuAD -X- _ B-DatasetName
v2.0 -X- _ O
development -X- _ O
set -X- _ O
, -X- _ O
RoBERTa -X- _ B-MethodName
sets -X- _ O
a -X- _ O
new -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
, -X- _ O
improving -X- _ O
over -X- _ O
XLNet -X- _ B-MethodName
by -X- _ O
0.4 -X- _ B-MetricValue
points -X- _ O
( -X- _ O
EM -X- _ B-MetricName
) -X- _ O
and -X- _ O
0.6 -X- _ B-MetricValue
points -X- _ O
( -X- _ O
F1 -X- _ B-MetricName
) -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
submit -X- _ O
RoBERTa -X- _ B-MethodName
to -X- _ O
the -X- _ O
public -X- _ O
SQuAD -X- _ B-MethodName
2.0 -X- _ O
leaderboard -X- _ O
and -X- _ O
evaluate -X- _ O
its -X- _ O
performance -X- _ O
rel- -X- _ O
ative -X- _ O
to -X- _ O
other -X- _ O
systems -X- _ O
. -X- _ O
Most -X- _ O
of -X- _ O
the -X- _ O
top -X- _ O
systems -X- _ O
build -X- _ O
upon -X- _ O
either -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
or -X- _ O
XLNet -X- _ B-MethodName
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
both -X- _ O
of -X- _ O
which -X- _ O
rely -X- _ O
on -X- _ O
additional -X- _ O
external -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
our -X- _ O
submission -X- _ O
does -X- _ O
not -X- _ O
use -X- _ O
any -X- _ O
additional -X- _ O
data -X- _ O
. -X- _ O
Our -X- _ O
single -X- _ O
RoBERTa -X- _ B-MethodName
model -X- _ O
outperforms -X- _ O
all -X- _ O
but -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
single -X- _ O
model -X- _ O
submissions -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
the -X- _ O
top -X- _ O
scoring -X- _ O
system -X- _ O
among -X- _ O
those -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
rely -X- _ O
on -X- _ O
data -X- _ O
augmentation -X- _ O
. -X- _ O

XLNet -X- _ B-MethodName
, -X- _ O
while -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
learning -X- _ O
rate -X- _ O
for -X- _ O
all -X- _ O
layers -X- _ O
. -X- _ O
For -X- _ O
SQuAD -X- _ B-DatasetName
v1.1 -X- _ O
we -X- _ O
follow -X- _ O
the -X- _ O
same -X- _ O
ﬁnetun- -X- _ O
ing -X- _ O
procedure -X- _ O
as -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
SQuAD -X- _ B-DatasetName
v2.0 -X- _ I-DatasetName
, -X- _ O
we -X- _ O
additionally -X- _ O
classify -X- _ O
whether -X- _ O
a -X- _ O
given -X- _ O
question -X- _ O
is -X- _ O
answerable -X- _ O
; -X- _ O
we -X- _ O
train -X- _ O
this -X- _ O
classiﬁer -X- _ O
jointly -X- _ O
with -X- _ O
the -X- _ O
span -X- _ O
predictor -X- _ O
by -X- _ O
summing -X- _ O
the -X- _ O
classiﬁcation -X- _ B-TaskName
and -X- _ O
span -X- _ O
loss -X- _ O
terms -X- _ O
. -X- _ O

Table -X- _ O
6 -X- _ O
: -X- _ O
Results -X- _ O
on -X- _ O
SQuAD -X- _ B-DatasetName
. -X- _ O
† -X- _ O
indicates -X- _ O
results -X- _ O
that -X- _ O
de- -X- _ O
pend -X- _ O
on -X- _ O
additional -X- _ O
external -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
RoBERTa -X- _ B-MethodName
uses -X- _ O
only -X- _ O
the -X- _ O
provided -X- _ O
SQuAD -X- _ B-DatasetName
data -X- _ O
in -X- _ O
both -X- _ O
dev -X- _ O
and -X- _ O
test -X- _ O
settings -X- _ O
. -X- _ O
BERTLARGE -X- _ B-MethodName
and -X- _ O
XLNetLARGE -X- _ B-MethodName
results -X- _ O
are -X- _ O
from -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
re- -X- _ O
spectively -X- _ O
. -X- _ O

Single -X- _ O
models -X- _ O
on -X- _ O
test -X- _ O
( -X- _ O
as -X- _ O
of -X- _ O
July -X- _ O
25 -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
XLNetLARGE -X- _ B-MethodName
86.3† -X- _ O
89.1† -X- _ O

Single -X- _ O
models -X- _ O
on -X- _ O
dev -X- _ O
, -X- _ O
w/o -X- _ O
data -X- _ O
augmentation -X- _ O
BERTLARGE -X- _ B-MethodName
84.1 -X- _ O
90.9 -X- _ O
79.0 -X- _ O
81.8 -X- _ O
XLNetLARGE -X- _ B-MethodName
89.0 -X- _ O
94.5 -X- _ O
86.1 -X- _ O
88.8 -X- _ O
RoBERTa -X- _ B-MethodName
88.9 -X- _ O
94.6 -X- _ O
86.5 -X- _ O
89.4 -X- _ O

results -X- _ O
could -X- _ O
potentially -X- _ O
be -X- _ O
improved -X- _ O
by -X- _ O
augmenting -X- _ O
this -X- _ O
with -X- _ O
additional -X- _ O
pronoun -X- _ O
disambiguation -X- _ O
datasets -X- _ O
. -X- _ O

We -X- _ O
adopt -X- _ O
a -X- _ O
much -X- _ O
simpler -X- _ O
approach -X- _ O
for -X- _ O
SQuAD -X- _ B-DatasetName
compared -X- _ O
to -X- _ O
past -X- _ O
work -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
while -X- _ O
both -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
XL- -X- _ B-MethodName
Net -X- _ I-MethodName
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
augment -X- _ O
their -X- _ O
training -X- _ O
data -X- _ O
with -X- _ O
additional -X- _ O
QA -X- _ B-DatasetName
datasets -X- _ I-DatasetName
, -X- _ O
we -X- _ O
only -X- _ O
ﬁnetune -X- _ O
RoBERTa -X- _ B-MethodName
using -X- _ O
the -X- _ O
provided -X- _ O
SQuAD -X- _ B-DatasetName
training -X- _ O
data -X- _ O
. -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
also -X- _ O
employed -X- _ O
a -X- _ O
custom -X- _ O
layer -X- _ O
- -X- _ O
wise -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
schedule -X- _ O
to -X- _ O
ﬁnetune -X- _ O

Results -X- _ O
We -X- _ O
present -X- _ O
our -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
ﬁrst -X- _ O
setting -X- _ O
( -X- _ O
single -X- _ O
- -X- _ O
task -X- _ O
, -X- _ O
dev -X- _ O
) -X- _ O
, -X- _ O
RoBERTa -X- _ B-MethodName
achieves -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
on -X- _ O
all -X- _ O
9 -X- _ O
of -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
task -X- _ O
development -X- _ O
sets -X- _ O
. -X- _ O
Crucially -X- _ O
, -X- _ O
RoBERTa -X- _ B-MethodName
uses -X- _ O
the -X- _ O
same -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
pretrain- -X- _ O
ing -X- _ O
objective -X- _ O
and -X- _ O
architecture -X- _ O
as -X- _ O
BERTLARGE -X- _ B-MethodName
, -X- _ O
yet -X- _ O
consistently -X- _ O
outperforms -X- _ O
both -X- _ O
BERTLARGE -X- _ B-MethodName
and -X- _ O
XLNetLARGE -X- _ B-MethodName
. -X- _ O
This -X- _ O
raises -X- _ O
questions -X- _ O
about -X- _ O
the -X- _ O
rel- -X- _ O
ative -X- _ O
importance -X- _ O
of -X- _ O
model -X- _ O
architecture -X- _ O
and -X- _ O
pre- -X- _ O
training -X- _ O
objective -X- _ O
, -X- _ O
compared -X- _ O
to -X- _ O
more -X- _ O
mundane -X- _ O
de- -X- _ O
tails -X- _ O
like -X- _ O
dataset -X- _ O
size -X- _ O
and -X- _ O
training -X- _ O
time -X- _ O
that -X- _ O
we -X- _ O
ex- -X- _ O
plore -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
second -X- _ O
setting -X- _ O
( -X- _ O
ensembles -X- _ O
, -X- _ O
test -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
submit -X- _ O
RoBERTa -X- _ B-MethodName
to -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
leaderboard -X- _ O
and -X- _ O
achieve -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
on -X- _ O
4 -X- _ O
out -X- _ O
of -X- _ O
9 -X- _ O
tasks -X- _ O
and -X- _ O
the -X- _ O
highest -X- _ O
average -X- _ O
score -X- _ O
to -X- _ O
date -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
espe- -X- _ O
cially -X- _ O
exciting -X- _ O
because -X- _ O
RoBERTa -X- _ B-MethodName
does -X- _ O
not -X- _ O
depend -X- _ O
on -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
ﬁnetuning -X- _ O
, -X- _ O
unlike -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
other -X- _ O
top -X- _ O
submissions -X- _ O
. -X- _ O
We -X- _ O
expect -X- _ O
future -X- _ O
work -X- _ O
may -X- _ O
fur- -X- _ O
ther -X- _ O
improve -X- _ O
these -X- _ O
results -X- _ O
by -X- _ O
incorporating -X- _ O
more -X- _ O
sophisticated -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
ﬁnetuning -X- _ O
procedures -X- _ O
. -X- _ O

: -X- _ O
We -X- _ O
found -X- _ O
the -X- _ O
provided -X- _ O
NLI -X- _ B-TaskName
- -X- _ O
format -X- _ O
data -X- _ O
to -X- _ O
be -X- _ O
challenging -X- _ O
to -X- _ O
work -X- _ O
with -X- _ O
. -X- _ O
Instead -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
reformatted -X- _ O
WNLI -X- _ B-DatasetName
data -X- _ O
from -X- _ O
Super- -X- _ O
GLUE -X- _ B-DatasetName
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019a -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
indicates -X- _ O
the -X- _ O
span -X- _ O
of -X- _ O
the -X- _ O
query -X- _ O
pronoun -X- _ O
and -X- _ O
referent -X- _ O
. -X- _ O
We -X- _ O
ﬁne- -X- _ O
tune -X- _ O
RoBERTa -X- _ B-MethodName
using -X- _ O
the -X- _ O
margin -X- _ O
ranking -X- _ O
loss -X- _ O
from -X- _ O
Kocijan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
a -X- _ O
given -X- _ O
input -X- _ O
sentence -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
spaCy -X- _ O
( -X- _ O
Honnibal -X- _ O
and -X- _ O
Montani -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
to -X- _ O
extract -X- _ O
additional -X- _ O
candidate -X- _ O
noun -X- _ O
phrases -X- _ O
from -X- _ O
the -X- _ O
sentence -X- _ O
and -X- _ O
ﬁnetune -X- _ O
our -X- _ O
model -X- _ O
so -X- _ O
that -X- _ O
it -X- _ O
assigns -X- _ O
higher -X- _ O
scores -X- _ O
to -X- _ O
positive -X- _ O
referent -X- _ O
phrases -X- _ O
than -X- _ O
for -X- _ O
any -X- _ O
of -X- _ O
the -X- _ O
generated -X- _ O
negative -X- _ O
candidate -X- _ O
phrases -X- _ O
. -X- _ O
One -X- _ O
unfortunate -X- _ O
consequence -X- _ O
of -X- _ O
this -X- _ O
formulation -X- _ O
is -X- _ O
that -X- _ O
we -X- _ O
can -X- _ O
only -X- _ O
make -X- _ O
use -X- _ O
of -X- _ O
the -X- _ O
positive -X- _ O
train- -X- _ O
ing -X- _ O
examples -X- _ O
, -X- _ O
which -X- _ O
excludes -X- _ O
over -X- _ O
half -X- _ O
of -X- _ O
the -X- _ O
pro- -X- _ O
vided -X- _ O
training -X- _ O
examples.10 -X- _ O

: -X- _ O
Recent -X- _ O
submissions -X- _ O
on -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
leaderboard -X- _ O
adopt -X- _ O
a -X- _ O
pairwise -X- _ O
ranking -X- _ O
formulation -X- _ O
for -X- _ O
the -X- _ O
QNLI -X- _ B-TaskName
task -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
candidate -X- _ O
answers -X- _ O
are -X- _ O
mined -X- _ O
from -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
and -X- _ O
compared -X- _ O
to -X- _ O
one -X- _ O
another -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
single -X- _ O
( -X- _ O
question -X- _ O
, -X- _ O
candidate -X- _ O
) -X- _ O
pair -X- _ O
is -X- _ O
classiﬁed -X- _ O
as -X- _ O
positive -X- _ O
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019b -X- _ O
, -X- _ O
a -X- _ O
; -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
This -X- _ O
formulation -X- _ O
signiﬁcantly -X- _ O
simpliﬁes -X- _ O
the -X- _ O
task -X- _ O
, -X- _ O
but -X- _ O
is -X- _ O
not -X- _ O
directly -X- _ O
comparable -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Following -X- _ O
recent -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
ranking -X- _ O
approach -X- _ O
for -X- _ O
our -X- _ O
test -X- _ O
submission -X- _ O
, -X- _ O
but -X- _ O
for -X- _ O
direct -X- _ O
comparison -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
we -X- _ O
report -X- _ O
development -X- _ O
set -X- _ O
results -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
pure -X- _ O
classiﬁcation -X- _ O
approach -X- _ O
. -X- _ O
WNLI -X- _ B-MethodName

Task -X- _ O
- -X- _ O
speciﬁc -X- _ O
modiﬁcations -X- _ O
Two -X- _ O
of -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
tasks -X- _ O
require -X- _ O
task -X- _ O
- -X- _ O
speciﬁc -X- _ O
ﬁnetuning -X- _ O
approaches -X- _ O
to -X- _ O
achieve -X- _ O
competitive -X- _ O
leaderboard -X- _ O
results -X- _ O
. -X- _ O
QNLI -X- _ B-DatasetName

Table -X- _ O
5 -X- _ O
: -X- _ O
Results -X- _ O
on -X- _ O
GLUE -X- _ B-DatasetName
. -X- _ O
All -X- _ O
results -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
24 -X- _ O
- -X- _ O
layer -X- _ O
architecture -X- _ O
. -X- _ O
BERTLARGE -X- _ B-MethodName
and -X- _ O
XLNetLARGE -X- _ B-MethodName
results -X- _ O
are -X- _ O
from -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
RoBERTa -X- _ B-MethodName
results -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
are -X- _ O
a -X- _ O
median -X- _ O
over -X- _ O
ﬁve -X- _ O
runs -X- _ O
. -X- _ O
RoBERTa -X- _ B-MethodName
results -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
are -X- _ O
ensembles -X- _ O
of -X- _ O
single -X- _ O
- -X- _ O
task -X- _ O
models -X- _ O
. -X- _ O
For -X- _ O
RTE -X- _ B-DatasetName
, -X- _ O
STS -X- _ B-DatasetName
and -X- _ O
MRPC -X- _ B-DatasetName
we -X- _ O
ﬁnetune -X- _ O
starting -X- _ O
from -X- _ O
the -X- _ O
MNLI -X- _ B-TaskName
model -X- _ O
instead -X- _ O
of -X- _ O
the -X- _ O
baseline -X- _ O
pretrained -X- _ O
model -X- _ O
. -X- _ O
Averages -X- _ O
are -X- _ O
obtained -X- _ O
from -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
leaderboard -X- _ O
. -X- _ O

Ensembles -X- _ O
on -X- _ O
test -X- _ O
( -X- _ O
from -X- _ O
leaderboard -X- _ O
as -X- _ O
of -X- _ O
July -X- _ O
25 -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
ALICE -X- _ B-MethodName
88.2/87.9 -X- _ O
95.7 -X- _ O
90.7 -X- _ O
83.5 -X- _ O
95.2 -X- _ O
92.6 -X- _ O
68.6 -X- _ O
91.1 -X- _ O
80.8 -X- _ O
86.3 -X- _ O
MT -X- _ B-MethodName
- -X- _ I-MethodName
DNN -X- _ I-MethodName
87.9/87.4 -X- _ O
96.0 -X- _ O
89.9 -X- _ O
86.3 -X- _ O
96.5 -X- _ O
92.7 -X- _ O
68.4 -X- _ O
91.1 -X- _ O
89.0 -X- _ O
87.6 -X- _ O
XLNet -X- _ B-MethodName
90.2/89.8 -X- _ O
98.6 -X- _ O
90.3 -X- _ O
86.3 -X- _ O
96.8 -X- _ O
93.0 -X- _ O
67.8 -X- _ O
91.6 -X- _ O
90.4 -X- _ O
88.4 -X- _ O
RoBERTa -X- _ B-MethodName
90.8/90.2 -X- _ O
98.9 -X- _ O
90.2 -X- _ O
88.2 -X- _ O
96.7 -X- _ O
92.3 -X- _ O
67.8 -X- _ O
92.2 -X- _ O
89.0 -X- _ O
88.5 -X- _ O

Single -X- _ O
- -X- _ O
task -X- _ O
single -X- _ O
models -X- _ O
on -X- _ O
dev -X- _ O
BERTLARGE -X- _ B-MethodName
86.6/- -X- _ O
92.3 -X- _ O
91.3 -X- _ O
70.4 -X- _ O
93.2 -X- _ O
88.0 -X- _ O
60.6 -X- _ O
90.0 -X- _ O
- -X- _ O
- -X- _ O
XLNetLARGE -X- _ B-MethodName
89.8/- -X- _ O
93.9 -X- _ O
91.8 -X- _ O
83.8 -X- _ O
95.6 -X- _ O
89.2 -X- _ O
63.6 -X- _ O
91.8 -X- _ O
- -X- _ O
- -X- _ O
RoBERTa -X- _ B-MethodName
90.2/90.2 -X- _ O
94.7 -X- _ O
92.2 -X- _ O
86.6 -X- _ O
96.4 -X- _ O
90.9 -X- _ O
68.0 -X- _ O
92.4 -X- _ O
91.3 -X- _ O
- -X- _ O

In -X- _ O
the -X- _ O
second -X- _ O
setting -X- _ O
( -X- _ O
ensembles -X- _ O
, -X- _ O
test -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
com- -X- _ O
pare -X- _ B-DatasetName
RoBERTa -X- _ B-MethodName
to -X- _ O
other -X- _ O
approaches -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
via -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
leaderboard -X- _ O
. -X- _ O
While -X- _ O
many -X- _ O
submis- -X- _ O
sions -X- _ O
to -X- _ O
the -X- _ O
GLUE -X- _ O
leaderboard -X- _ O
depend -X- _ O
on -X- _ O
multi- -X- _ O
task -X- _ O
ﬁnetuning -X- _ O
, -X- _ O
our -X- _ O
submission -X- _ O
depends -X- _ O
only -X- _ O
on -X- _ O
single -X- _ O
- -X- _ O
task -X- _ O
ﬁnetuning -X- _ O
. -X- _ O
For -X- _ O
RTE -X- _ B-DatasetName
, -X- _ O
STS -X- _ B-DatasetName
and -X- _ O
MRPC -X- _ B-DatasetName
we -X- _ O
found -X- _ O
it -X- _ O
helpful -X- _ O
to -X- _ O
ﬁnetune -X- _ O
starting -X- _ O
from -X- _ O
the -X- _ O
MNLI -X- _ B-TaskName
single -X- _ O
- -X- _ O
task -X- _ O
model -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
the -X- _ O
baseline -X- _ O
pretrained -X- _ O
RoBERTa -X- _ B-MethodName
. -X- _ O
We -X- _ O
explore -X- _ O
a -X- _ O
slightly -X- _ O
wider -X- _ O
hyperparameter -X- _ O
space -X- _ O
, -X- _ O
described -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
, -X- _ O
and -X- _ O
ensemble -X- _ O
between -X- _ O
5 -X- _ O
and -X- _ O
7 -X- _ O
models -X- _ O
per -X- _ O
task -X- _ O
. -X- _ O

For -X- _ O
GLUE -X- _ B-TaskName
we -X- _ O
consider -X- _ O
two -X- _ O
ﬁnetuning -X- _ O
settings -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
ﬁrst -X- _ O
setting -X- _ O
( -X- _ O
single -X- _ O
- -X- _ O
task -X- _ O
, -X- _ O
dev -X- _ O
) -X- _ O
we -X- _ O
ﬁnetune -X- _ O
RoBERTa -X- _ B-MethodName
separately -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
GLUE -X- _ B-TaskName
tasks -X- _ O
, -X- _ O
using -X- _ O
only -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
for -X- _ O
the -X- _ O
correspond- -X- _ O
ing -X- _ O
task -X- _ O
. -X- _ O
We -X- _ O
consider -X- _ O
a -X- _ O
limited -X- _ O
hyperparameter -X- _ O
sweep -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
, -X- _ O
with -X- _ O
batch -X- _ B-HyperparameterName
sizes -X- _ I-HyperparameterName
∈ -X- _ O
{ -X- _ O
16 -X- _ B-HyperparameterValue
, -X- _ O
32 -X- _ B-HyperparameterValue
} -X- _ O
and -X- _ O
learning -X- _ B-HyperparameterName
rates -X- _ I-HyperparameterName
∈ -X- _ O
{ -X- _ O
1e−5 -X- _ B-HyperparameterValue
, -X- _ O
2e−5 -X- _ B-HyperparameterValue
, -X- _ O
3e−5 -X- _ B-HyperparameterValue
} -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
linear -X- _ O
warmup -X- _ O
for -X- _ O
the -X- _ O
ﬁrst -X- _ O
6 -X- _ O
% -X- _ O
of -X- _ O
steps -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
linear -X- _ B-HyperparameterName
decay -X- _ I-HyperparameterName
to -X- _ O
0 -X- _ B-HyperparameterValue
. -X- _ O
We -X- _ O
ﬁnetune -X- _ O
for -X- _ O
10 -X- _ O
epochs -X- _ O
and -X- _ O
perform -X- _ O
early -X- _ O
stopping -X- _ O
based -X- _ O
on -X- _ O
each -X- _ O
task -X- _ O
’s -X- _ O
eval- -X- _ O
uation -X- _ O
metric -X- _ O
on -X- _ O
the -X- _ O
dev -X- _ O
set -X- _ O
. -X- _ O
The -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
hyper- -X- _ O
parameters -X- _ O
remain -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
during -X- _ O
pretraining -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
setting -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
median -X- _ O
development -X- _ O
set -X- _ O
results -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
over -X- _ O
ﬁve -X- _ O
random -X- _ O
initial- -X- _ O
izations -X- _ O
, -X- _ O
without -X- _ O
model -X- _ O
ensembling -X- _ O
. -X- _ O

we -X- _ O
consider -X- _ O
RoBERTa -X- _ B-MethodName
trained -X- _ O
for -X- _ O
500 -X- _ O
K -X- _ O
steps -X- _ O
over -X- _ O
all -X- _ O
ﬁve -X- _ O
of -X- _ O
the -X- _ O
datasets -X- _ O
introduced -X- _ O
in -X- _ O
Section -X- _ O
3.2 -X- _ O
. -X- _ O

9Our -X- _ O
experiments -X- _ O
conﬂate -X- _ O
increases -X- _ O
in -X- _ O
data -X- _ O
size -X- _ O
and -X- _ O
di- -X- _ O
versity -X- _ O
. -X- _ O
We -X- _ O
leave -X- _ O
a -X- _ O
more -X- _ O
careful -X- _ O
analysis -X- _ O
of -X- _ O
these -X- _ O
two -X- _ O
dimen- -X- _ O
sions -X- _ O
to -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O

Finally -X- _ O
, -X- _ O
we -X- _ O
pretrain -X- _ O
RoBERTa -X- _ B-MethodName
for -X- _ O
signiﬁcantly -X- _ O
longer -X- _ O
, -X- _ O
increasing -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
pretraining -X- _ O
steps -X- _ O
from -X- _ O
100 -X- _ O
K -X- _ O
to -X- _ O
300 -X- _ O
K -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
further -X- _ O
to -X- _ O
500K. -X- _ O
We -X- _ O
again -X- _ O
observe -X- _ O
signiﬁcant -X- _ O
gains -X- _ O
in -X- _ O
downstream -X- _ O
task -X- _ O
performance -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
300 -X- _ O
K -X- _ O
and -X- _ O
500 -X- _ O
K -X- _ O
step -X- _ O
mod- -X- _ O
els -X- _ O
outperform -X- _ O
XLNetLARGE -X- _ B-MethodName
across -X- _ O
most -X- _ O
tasks -X- _ O
. -X- _ O
We -X- _ O
note -X- _ O
that -X- _ O
even -X- _ O
our -X- _ O
longest -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
does -X- _ O
not -X- _ O
appear -X- _ O
to -X- _ O
overﬁt -X- _ O
our -X- _ O
data -X- _ O
and -X- _ O
would -X- _ O
likely -X- _ O
beneﬁt -X- _ O
from -X- _ O
additional -X- _ O
training -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
our -X- _ O
best -X- _ O
RoBERTa -X- _ B-MethodName
model -X- _ O
on -X- _ O
the -X- _ O
three -X- _ O
different -X- _ O
bench- -X- _ O
marks -X- _ O
: -X- _ O
GLUE -X- _ B-DatasetName
, -X- _ O
SQuaD -X- _ B-DatasetName
and -X- _ O
RACE -X- _ B-DatasetName
. -X- _ O
Speciﬁcally -X- _ O

Results -X- _ O
We -X- _ O
present -X- _ O
our -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O
When -X- _ O
controlling -X- _ O
for -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
RoBERTa -X- _ B-MethodName
provides -X- _ O
a -X- _ O
large -X- _ O
improvement -X- _ O
over -X- _ O
the -X- _ O
originally -X- _ O
reported -X- _ O
BERTLARGE -X- _ B-MethodName
results -X- _ O
, -X- _ O
reafﬁrming -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
the -X- _ O
design -X- _ O
choices -X- _ O
we -X- _ O
explored -X- _ O
in -X- _ O
Section -X- _ O
4 -X- _ O
. -X- _ O
Next -X- _ O
, -X- _ O
we -X- _ O
combine -X- _ O
this -X- _ O
data -X- _ O
with -X- _ O
the -X- _ O
three -X- _ O
ad- -X- _ O
ditional -X- _ O
datasets -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
3.2 -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
RoBERTa -X- _ B-MethodName
over -X- _ O
the -X- _ O
combined -X- _ O
data -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
number -X- _ O
of -X- _ O
training -X- _ O
steps -X- _ O
as -X- _ O
before -X- _ O
( -X- _ O
100 -X- _ O
K -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
total -X- _ O
, -X- _ O
we -X- _ O
pretrain -X- _ O
over -X- _ O
160 -X- _ O
GB -X- _ O
of -X- _ O
text -X- _ O
. -X- _ O
We -X- _ O
ob- -X- _ O
serve -X- _ O
further -X- _ O
improvements -X- _ O
in -X- _ O
performance -X- _ O
across -X- _ O
all -X- _ O
downstream -X- _ O
tasks -X- _ O
, -X- _ O
validating -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
data -X- _ O
size -X- _ O
and -X- _ O
diversity -X- _ O
in -X- _ O
pretraining.9 -X- _ O

Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
pretrain -X- _ O
our -X- _ O
model -X- _ O
using -X- _ O
1024 -X- _ O
V100 -X- _ O
GPUs -X- _ O
for -X- _ O
approximately -X- _ O
one -X- _ O
day -X- _ O
. -X- _ O

Table -X- _ O
4 -X- _ O
: -X- _ O
Development -X- _ O
set -X- _ O
results -X- _ O
for -X- _ O
RoBERTa -X- _ B-MethodName
as -X- _ O
we -X- _ O
pretrain -X- _ O
over -X- _ O
more -X- _ O
data -X- _ O
( -X- _ O
16 -X- _ O
GB -X- _ O
→ -X- _ O
160 -X- _ O
GB -X- _ O
of -X- _ O
text -X- _ O
) -X- _ O
and -X- _ O
pretrain -X- _ O
for -X- _ O
longer -X- _ O
( -X- _ O
100 -X- _ O
K -X- _ O
→ -X- _ O
300 -X- _ O
K -X- _ O
→ -X- _ O
500 -X- _ O
K -X- _ O
steps -X- _ O
) -X- _ O
. -X- _ O
Each -X- _ O
row -X- _ O
accumulates -X- _ O
improvements -X- _ O
from -X- _ O
the -X- _ O
rows -X- _ O
above -X- _ O
. -X- _ O
RoBERTa -X- _ B-MethodName
matches -X- _ O
the -X- _ O
architecture -X- _ O
and -X- _ O
training -X- _ O
objective -X- _ O
of -X- _ O
BERTLARGE -X- _ B-MethodName
. -X- _ O
Results -X- _ O
for -X- _ O
BERTLARGE -X- _ B-MethodName
and -X- _ O
XLNetLARGE -X- _ B-MethodName
are -X- _ O
from -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
Complete -X- _ O
results -X- _ O
on -X- _ O
all -X- _ O
GLUE -X- _ B-TaskName
tasks -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
the -X- _ O
Appendix -X- _ O
. -X- _ O

BERTLARGE -X- _ B-MethodName
with -X- _ O
BOOKS -X- _ B-DatasetName
+ -X- _ O
WIKI -X- _ B-DatasetName
13 -X- _ O
GB -X- _ O
256 -X- _ O
1 -X- _ O
M -X- _ O
90.9/81.8 -X- _ O
86.6 -X- _ O
93.7 -X- _ O
XLNetLARGE -X- _ B-MethodName
with -X- _ O
BOOKS -X- _ B-DatasetName
+ -X- _ O
WIKI -X- _ B-DatasetName
13 -X- _ O
GB -X- _ O
256 -X- _ O
1 -X- _ O
M -X- _ O
94.0/87.8 -X- _ O
88.4 -X- _ O
94.4 -X- _ O
+ -X- _ O
additional -X- _ O
data -X- _ O
126 -X- _ O
GB -X- _ O
2 -X- _ O
K -X- _ O
500 -X- _ O
K -X- _ O
94.5/88.8 -X- _ O
89.8 -X- _ O
95.6 -X- _ O

RoBERTa -X- _ B-MethodName
with -X- _ O
BOOKS -X- _ B-DatasetName
+ -X- _ O
WIKI -X- _ B-DatasetName
16 -X- _ O
GB -X- _ O
8 -X- _ O
K -X- _ O
100 -X- _ O
K -X- _ O
93.6/87.3 -X- _ O
89.0 -X- _ O
95.3 -X- _ O
+ -X- _ O
additional -X- _ O
data -X- _ O
( -X- _ O
§ -X- _ O
3.2 -X- _ O
) -X- _ O
160 -X- _ O
GB -X- _ O
8 -X- _ O
K -X- _ O
100 -X- _ O
K -X- _ O
94.0/87.7 -X- _ O
89.3 -X- _ O
95.6 -X- _ O
+ -X- _ O
pretrain -X- _ O
longer -X- _ O
160 -X- _ O
GB -X- _ O
8 -X- _ O
K -X- _ O
300 -X- _ O
K -X- _ O
94.4/88.7 -X- _ O
90.0 -X- _ O
96.1 -X- _ O
+ -X- _ O
pretrain -X- _ O
even -X- _ O
longer -X- _ O
160 -X- _ O
GB -X- _ O
8 -X- _ O
K -X- _ O
500 -X- _ O
K -X- _ O
94.6/89.4 -X- _ O
90.2 -X- _ O
96.4 -X- _ O

pproach -X- _ O
. -X- _ O
Speciﬁ- -X- _ O
cally -X- _ O
, -X- _ O
RoBERTa -X- _ B-MethodName
is -X- _ O
trained -X- _ O
with -X- _ O
dynamic -X- _ O
mask- -X- _ O
ing -X- _ O
( -X- _ O
Section -X- _ O
4.1 -X- _ O
) -X- _ O
, -X- _ O
FULL -X- _ O
- -X- _ O
SENTENCES -X- _ O
without -X- _ O
NSP -X- _ B-MetricName
loss -X- _ I-MetricName
( -X- _ O
Section -X- _ O
4.2 -X- _ O
) -X- _ O
, -X- _ O
large -X- _ O
mini -X- _ O
- -X- _ O
batches -X- _ O
( -X- _ O
Section -X- _ O
4.3 -X- _ O
) -X- _ O
and -X- _ O
a -X- _ O
larger -X- _ O
byte -X- _ O
- -X- _ O
level -X- _ O
BPE -X- _ B-TaskName
( -X- _ O
Section -X- _ O
4.4 -X- _ O
) -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
we -X- _ O
investigate -X- _ O
two -X- _ O
other -X- _ O
impor- -X- _ O
tant -X- _ O
factors -X- _ O
that -X- _ O
have -X- _ O
been -X- _ O
under -X- _ O
- -X- _ O
emphasized -X- _ O
in -X- _ O
previous -X- _ O
work -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
the -X- _ O
data -X- _ O
used -X- _ O
for -X- _ O
pretraining -X- _ O
, -X- _ O
and -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
training -X- _ O
passes -X- _ O
through -X- _ O
the -X- _ O
data -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
recently -X- _ O
proposed -X- _ O
XLNet -X- _ B-MethodName
architecture -X- _ O
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
is -X- _ O
pretrained -X- _ O
us- -X- _ O
ing -X- _ O
nearly -X- _ O
10 -X- _ O
times -X- _ O
more -X- _ O
data -X- _ O
than -X- _ O
the -X- _ O
original -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
also -X- _ O
trained -X- _ O
with -X- _ O
a -X- _ O
batch -X- _ O
size -X- _ O
eight -X- _ O
times -X- _ O
larger -X- _ O
for -X- _ O
half -X- _ O
as -X- _ O
many -X- _ O
op- -X- _ O
timization -X- _ O
steps -X- _ O
, -X- _ O
thus -X- _ O
seeing -X- _ O
four -X- _ O
times -X- _ O
as -X- _ O
many -X- _ O
sequences -X- _ O
in -X- _ O
pretraining -X- _ O
compared -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
To -X- _ O
help -X- _ O
disentangle -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
these -X- _ O
fac- -X- _ O
tors -X- _ O
from -X- _ O
other -X- _ O
modeling -X- _ O
choices -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
the -X- _ O
pre- -X- _ O
training -X- _ O
objective -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
begin -X- _ O
by -X- _ O
training -X- _ O
RoBERTa -X- _ B-MethodName
following -X- _ O
the -X- _ O
BERTLARGE -X- _ B-MethodName
architecture -X- _ O
( -X- _ O
L -X- _ B-HyperparameterName
= -X- _ O
24 -X- _ B-HyperparameterValue
, -X- _ O
H -X- _ B-HyperparameterName
= -X- _ O
1024 -X- _ B-HyperparameterValue
, -X- _ O
A -X- _ B-HyperparameterName
= -X- _ O
16 -X- _ B-HyperparameterValue
, -X- _ O
355 -X- _ O
M -X- _ O
parameters -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
pretrain -X- _ O
for -X- _ O
100 -X- _ O
K -X- _ O
steps -X- _ O
over -X- _ O
a -X- _ O
comparable -X- _ O
BOOK- -X- _ B-DatasetName
CORPUS -X- _ I-DatasetName
plus -X- _ O
WIKIPEDIA -X- _ B-DatasetName
dataset -X- _ O
as -X- _ O
was -X- _ O
used -X- _ O
in -X- _ O

In -X- _ O
the -X- _ O
previous -X- _ O
section -X- _ O
we -X- _ O
propose -X- _ O
modiﬁcations -X- _ O
to -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
pretraining -X- _ O
procedure -X- _ O
that -X- _ O
improve -X- _ O
end -X- _ O
- -X- _ O
task -X- _ O
performance -X- _ O
. -X- _ O
We -X- _ O
now -X- _ O
aggregate -X- _ O
these -X- _ O
improvements -X- _ O
and -X- _ O
evaluate -X- _ O
their -X- _ O
combined -X- _ O
im- -X- _ O
pact -X- _ O
. -X- _ O
We -X- _ O
call -X- _ O
this -X- _ O
conﬁguration -X- _ O
RoBERTa -X- _ B-MethodName
for -X- _ O
R -X- _ O

Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
BPE -X- _ B-TaskName
achieving -X- _ O
slightly -X- _ O
worse -X- _ O
end -X- _ O
- -X- _ O
task -X- _ O
performance -X- _ O
on -X- _ O
some -X- _ O
tasks -X- _ O
. -X- _ O
Nev- -X- _ O
ertheless -X- _ O
, -X- _ O
we -X- _ O
believe -X- _ O
the -X- _ O
advantages -X- _ O
of -X- _ O
a -X- _ O
univer- -X- _ O
sal -X- _ O
encoding -X- _ O
scheme -X- _ O
outweighs -X- _ O
the -X- _ O
minor -X- _ O
degre- -X- _ O
dation -X- _ O
in -X- _ O
performance -X- _ O
and -X- _ O
use -X- _ O
this -X- _ O
encoding -X- _ O
in -X- _ O
the -X- _ O
remainder -X- _ O
of -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O
A -X- _ O
more -X- _ O
de- -X- _ O
tailed -X- _ O
comparison -X- _ O
of -X- _ O
these -X- _ O
encodings -X- _ O
is -X- _ O
left -X- _ O
to -X- _ O
fu- -X- _ O
ture -X- _ O
work -X- _ O
. -X- _ O

The -X- _ O
original -X- _ O
BERT -X- _ B-MethodName
implementa- -X- _ O
tion -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
uses -X- _ O
a -X- _ O
character -X- _ O
- -X- _ O
level -X- _ O
BPE -X- _ B-TaskName
vocabulary -X- _ O
of -X- _ O
size -X- _ O
30 -X- _ O
K -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
learned -X- _ O
after -X- _ O
preprocessing -X- _ O
the -X- _ O
input -X- _ O
with -X- _ O
heuristic -X- _ O
tok- -X- _ O
enization -X- _ O
rules -X- _ O
. -X- _ O
Following -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
instead -X- _ O
consider -X- _ O
training -X- _ O
BERT -X- _ B-MethodName
with -X- _ O
a -X- _ O
larger -X- _ O
byte -X- _ O
- -X- _ O
level -X- _ O
BPE -X- _ B-TaskName
vocabulary -X- _ O
containing -X- _ O
50 -X- _ O
K -X- _ O
sub- -X- _ O
word -X- _ O
units -X- _ O
, -X- _ O
without -X- _ O
any -X- _ O
additional -X- _ O
preprocessing -X- _ O
or -X- _ O
tokenization -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O
This -X- _ O
adds -X- _ O
approxi- -X- _ O
mately -X- _ O
15 -X- _ O
M -X- _ O
and -X- _ O
20 -X- _ O
M -X- _ O
additional -X- _ O
parameters -X- _ O
for -X- _ O
BERTBASE -X- _ B-MethodName
and -X- _ O
BERTLARGE -X- _ B-MethodName
, -X- _ O
respectively -X- _ O
. -X- _ O
Early -X- _ O
experiments -X- _ O
revealed -X- _ O
only -X- _ O
slight -X- _ O
dif- -X- _ O
ferences -X- _ O
between -X- _ O
these -X- _ O
encodings -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O

8Large -X- _ O
batch -X- _ O
training -X- _ O
can -X- _ O
improve -X- _ O
training -X- _ O
efﬁciency -X- _ O
even -X- _ O
without -X- _ O
large -X- _ O
scale -X- _ O
parallel -X- _ O
hardware -X- _ O
through -X- _ O
gradient -X- _ O
ac- -X- _ O
cumulation -X- _ O
, -X- _ O
whereby -X- _ O
gradients -X- _ O
from -X- _ O
multiple -X- _ O
mini -X- _ O
- -X- _ O
batches -X- _ O
are -X- _ O
accumulated -X- _ O
locally -X- _ O
before -X- _ O
each -X- _ O
optimization -X- _ O
step -X- _ O
. -X- _ O
This -X- _ O
functionality -X- _ O
is -X- _ O
supported -X- _ O
natively -X- _ O
in -X- _ O
FAIRSEQ -X- _ B-MethodName
( -X- _ O
Ott -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

Byte -X- _ B-TaskName
- -X- _ I-TaskName
Pair -X- _ I-TaskName
Encoding -X- _ I-TaskName
( -X- _ O
BPE -X- _ B-TaskName
) -X- _ O
( -X- _ O
Sennrich -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
hybrid -X- _ O
between -X- _ O
character- -X- _ O
and -X- _ O
word -X- _ O
- -X- _ O
level -X- _ O
rep- -X- _ O
resentations -X- _ O
that -X- _ O
allows -X- _ O
handling -X- _ O
the -X- _ O
large -X- _ O
vocab- -X- _ O
ularies -X- _ O
common -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
corpora -X- _ O
. -X- _ O
In- -X- _ O
stead -X- _ O
of -X- _ O
full -X- _ O
words -X- _ O
, -X- _ O
BPE -X- _ B-TaskName
relies -X- _ O
on -X- _ O
subwords -X- _ O
units -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
extracted -X- _ O
by -X- _ O
performing -X- _ O
statistical -X- _ O
anal- -X- _ O
ysis -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
corpus -X- _ O
. -X- _ O
BPE -X- _ B-TaskName
vocabulary -X- _ O
sizes -X- _ O
typically -X- _ O
range -X- _ O
from -X- _ O
10K-100 -X- _ O
K -X- _ O
subword -X- _ O
units -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
unicode -X- _ O
char- -X- _ O
acters -X- _ O
can -X- _ O
account -X- _ O
for -X- _ O
a -X- _ O
sizeable -X- _ O
portion -X- _ O
of -X- _ O
this -X- _ O
vocabulary -X- _ O
when -X- _ O
modeling -X- _ O
large -X- _ O
and -X- _ O
diverse -X- _ O
cor- -X- _ O
pora -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
ones -X- _ O
considered -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
. -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
introduce -X- _ O
a -X- _ O
clever -X- _ O
imple- -X- _ O
mentation -X- _ O
of -X- _ O
BPE -X- _ B-TaskName
that -X- _ O
uses -X- _ O
bytes -X- _ O
instead -X- _ O
of -X- _ O
uni- -X- _ O
code -X- _ O
characters -X- _ O
as -X- _ O
the -X- _ O
base -X- _ O
subword -X- _ O
units -X- _ O
. -X- _ O
Using -X- _ O
bytes -X- _ O
makes -X- _ O
it -X- _ O
possible -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
subword -X- _ O
vocab- -X- _ O
ulary -X- _ O
of -X- _ O
a -X- _ O
modest -X- _ O
size -X- _ O
( -X- _ O
50 -X- _ O
K -X- _ O
units -X- _ O
) -X- _ O
that -X- _ O
can -X- _ O
still -X- _ O
en- -X- _ O
code -X- _ O
any -X- _ O
input -X- _ O
text -X- _ O
without -X- _ O
introducing -X- _ O
any -X- _ O
“ -X- _ O
un- -X- _ O
known -X- _ O
” -X- _ O
tokens -X- _ O
. -X- _ O

and -X- _ O
in -X- _ O
later -X- _ O
experiments -X- _ O
we -X- _ O
train -X- _ O
with -X- _ O
batches -X- _ O
of -X- _ O
8 -X- _ O
K -X- _ O
sequences -X- _ O
. -X- _ O
Notably -X- _ O
You -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
train -X- _ O
BERT -X- _ B-MethodName
with -X- _ O
even -X- _ O
larger -X- _ O
batche -X- _ B-HyperparameterName
sizes -X- _ I-HyperparameterName
, -X- _ O
up -X- _ O
to -X- _ O
32 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
sequences -X- _ I-HyperparameterValue
. -X- _ O
We -X- _ O
leave -X- _ O
further -X- _ O
exploration -X- _ O
of -X- _ O
the -X- _ O
limits -X- _ O
of -X- _ O
large -X- _ O
batch -X- _ O
training -X- _ O
to -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O

task -X- _ O
performance -X- _ O
of -X- _ O
BERTBASE -X- _ B-MethodName
as -X- _ O
we -X- _ O
increase -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
, -X- _ O
controlling -X- _ O
for -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
passes -X- _ O
through -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
train- -X- _ O
ing -X- _ O
with -X- _ O
large -X- _ O
batches -X- _ O
improves -X- _ O
perplexity -X- _ O
for -X- _ O
the -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
objective -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
end -X- _ O
- -X- _ O
task -X- _ O
accuracy -X- _ O
. -X- _ O
Large -X- _ O
batches -X- _ O
are -X- _ O
also -X- _ O
easier -X- _ O
to -X- _ O
parallelize -X- _ O
via -X- _ O
distributed -X- _ O
data -X- _ O
parallel -X- _ O
training,8 -X- _ O

Table -X- _ O
3 -X- _ O
: -X- _ O
Perplexity -X- _ O
on -X- _ O
held -X- _ O
- -X- _ O
out -X- _ O
training -X- _ O
data -X- _ O
( -X- _ O
ppl -X- _ O
) -X- _ O
and -X- _ O
development -X- _ O
set -X- _ O
accuracy -X- _ O
for -X- _ O
base -X- _ O
models -X- _ O
trained -X- _ O
over -X- _ O
BOOKCORPUS -X- _ B-DatasetName
and -X- _ O
WIKIPEDIA -X- _ B-DatasetName
with -X- _ O
varying -X- _ O
batch -X- _ B-HyperparameterName
sizes -X- _ I-HyperparameterName
( -X- _ O
bsz -X- _ B-HyperparameterName
) -X- _ O
. -X- _ O
We -X- _ O
tune -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
( -X- _ O
lr -X- _ B-HyperparameterName
) -X- _ O
for -X- _ O
each -X- _ O
set- -X- _ O
ting -X- _ O
. -X- _ O
Models -X- _ O
make -X- _ O
the -X- _ O
same -X- _ O
number -X- _ O
of -X- _ O
passes -X- _ O
over -X- _ O
the -X- _ O
data -X- _ O
( -X- _ O
epochs -X- _ B-HyperparameterName
) -X- _ O
and -X- _ O
have -X- _ O
the -X- _ O
same -X- _ O
computational -X- _ O
cost -X- _ O
. -X- _ O

256 -X- _ O
1 -X- _ O
M -X- _ O
1e-4 -X- _ O
3.99 -X- _ O
84.7 -X- _ O
92.7 -X- _ O
2 -X- _ O
K -X- _ O
125 -X- _ O
K -X- _ O
7e-4 -X- _ O
3.68 -X- _ O
85.2 -X- _ O
92.9 -X- _ O
8 -X- _ O
K -X- _ O
31 -X- _ O
K -X- _ O
1e-3 -X- _ O
3.77 -X- _ O
84.6 -X- _ O
92.8 -X- _ O

Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
originally -X- _ O
trained -X- _ O
BERTBASE -X- _ B-MethodName
for -X- _ O
1 -X- _ O
M -X- _ O
steps -X- _ O
with -X- _ O
a -X- _ O
batch -X- _ O
size -X- _ O
of -X- _ O
256 -X- _ O
sequences -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
equivalent -X- _ O
in -X- _ O
computa- -X- _ O
tional -X- _ O
cost -X- _ O
, -X- _ O
via -X- _ O
gradient -X- _ O
accumulation -X- _ O
, -X- _ O
to -X- _ O
training -X- _ O
for -X- _ O
125 -X- _ O
K -X- _ O
steps -X- _ O
with -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
2 -X- _ B-HyperparameterValue
K -X- _ I-HyperparameterValue
sequences -X- _ O
, -X- _ O
or -X- _ O
for -X- _ O
31 -X- _ O
K -X- _ O
steps -X- _ O
with -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
8K. -X- _ B-HyperparameterValue
In -X- _ O
Table -X- _ O
3 -X- _ O
we -X- _ O
compare -X- _ O
perplexity -X- _ O
and -X- _ O
end- -X- _ O

Past -X- _ O
work -X- _ O
in -X- _ O
Neural -X- _ B-TaskName
Machine -X- _ I-TaskName
Translation -X- _ I-TaskName
has -X- _ O
shown -X- _ O
that -X- _ O
training -X- _ O
with -X- _ O
very -X- _ O
large -X- _ O
mini -X- _ O
- -X- _ O
batches -X- _ O
can -X- _ O
both -X- _ O
improve -X- _ O
optimization -X- _ O
speed -X- _ O
and -X- _ O
end -X- _ O
- -X- _ O
task -X- _ O
performance -X- _ O
when -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
increased -X- _ O
appropriately -X- _ O
( -X- _ O
Ott -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Recent -X- _ O
work -X- _ O
has -X- _ O
shown -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
also -X- _ O
amenable -X- _ O
to -X- _ O
large -X- _ O
batch -X- _ O
training -X- _ O
( -X- _ O
You -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

SENTENCES -X- _ O
in -X- _ O
the -X- _ O
remainder -X- _ O
of -X- _ O
our -X- _ O
experiments -X- _ O
for -X- _ O
easier -X- _ O
comparison -X- _ O
with -X- _ O
related -X- _ O
work -X- _ O
. -X- _ O

We -X- _ O
next -X- _ O
compare -X- _ O
training -X- _ O
without -X- _ O
the -X- _ O
NSP -X- _ B-TaskName
loss -X- _ I-TaskName
and -X- _ O
training -X- _ O
with -X- _ O
blocks -X- _ O
of -X- _ O
text -X- _ O
from -X- _ O
a -X- _ O
sin- -X- _ O
gle -X- _ O
document -X- _ O
( -X- _ O
DOC -X- _ O
- -X- _ O
SENTENCES -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
ﬁnd -X- _ O
that -X- _ O
this -X- _ O
setting -X- _ O
outperforms -X- _ O
the -X- _ O
originally -X- _ O
published -X- _ O
BERTBASE -X- _ B-MethodName
results -X- _ O
and -X- _ O
that -X- _ O
removing -X- _ O
the -X- _ O
NSP -X- _ B-MetricName
loss -X- _ I-MetricName
matches -X- _ O
or -X- _ O
slightly -X- _ O
improves -X- _ O
downstream -X- _ O
task -X- _ O
performance -X- _ O
, -X- _ O
in -X- _ O
contrast -X- _ O
to -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
possible -X- _ O
that -X- _ O
the -X- _ O
original -X- _ O
BERT -X- _ B-MethodName
implementa- -X- _ O
tion -X- _ O
may -X- _ O
only -X- _ O
have -X- _ O
removed -X- _ O
the -X- _ O
loss -X- _ O
term -X- _ O
while -X- _ O
still -X- _ O
retaining -X- _ O
the -X- _ O
SEGMENT -X- _ O
- -X- _ O
PAIR -X- _ O
input -X- _ O
format -X- _ O
. -X- _ O
Finally -X- _ O
we -X- _ O
ﬁnd -X- _ O
that -X- _ O
restricting -X- _ O
sequences -X- _ O
to -X- _ O
come -X- _ O
from -X- _ O
a -X- _ O
single -X- _ O
document -X- _ O
( -X- _ O
DOC -X- _ O
- -X- _ O
SENTENCES -X- _ O
) -X- _ O
performs -X- _ O
slightly -X- _ O
better -X- _ O
than -X- _ O
packing -X- _ O
sequences -X- _ O
from -X- _ O
multiple -X- _ O
documents -X- _ O
( -X- _ O
FULL -X- _ O
- -X- _ O
SENTENCES -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
because -X- _ O
the -X- _ O
DOC -X- _ O
- -X- _ O
SENTENCES -X- _ O
format -X- _ O
results -X- _ O
in -X- _ O
variable -X- _ O
batch -X- _ O
sizes -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
FULL- -X- _ O

SEGMENT -X- _ O
- -X- _ O
PAIR -X- _ O
input -X- _ O
format -X- _ O
from -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
to -X- _ O
the -X- _ O
SENTENCE -X- _ O
- -X- _ O
PAIR -X- _ O
format -X- _ O
; -X- _ O
both -X- _ O
for- -X- _ O
mats -X- _ O
retain -X- _ O
the -X- _ O
NSP -X- _ B-MetricName
loss -X- _ I-MetricName
, -X- _ O
but -X- _ O
the -X- _ O
latter -X- _ O
uses -X- _ O
sin- -X- _ O
gle -X- _ O
sentences -X- _ O
. -X- _ O
We -X- _ O
ﬁnd -X- _ O
that -X- _ O
using -X- _ O
individual -X- _ O
sentences -X- _ O
hurts -X- _ O
performance -X- _ O
on -X- _ O
downstream -X- _ O
tasks -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
hypothesize -X- _ O
is -X- _ O
because -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
not -X- _ O
able -X- _ O
to -X- _ O
learn -X- _ O
long -X- _ O
- -X- _ O
range -X- _ O
dependencies -X- _ O
. -X- _ O

Results -X- _ O
Table -X- _ O
2 -X- _ O
shows -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
four -X- _ O
dif- -X- _ O
ferent -X- _ O
settings -X- _ O
. -X- _ O
We -X- _ O
ﬁrst -X- _ O
compare -X- _ O
the -X- _ O
original -X- _ O

• -X- _ O
DOC -X- _ B-TaskName
- -X- _ I-TaskName
SENTENCES -X- _ I-TaskName
: -X- _ O
Inputs -X- _ O
are -X- _ O
constructed -X- _ O
sim- -X- _ O
ilarly -X- _ O
to -X- _ O
FULL -X- _ B-TaskName
- -X- _ I-TaskName
SENTENCES -X- _ I-TaskName
, -X- _ O
except -X- _ O
that -X- _ O
they -X- _ O
may -X- _ O
not -X- _ O
cross -X- _ O
document -X- _ O
boundaries -X- _ O
. -X- _ O
Inputs -X- _ O
sampled -X- _ O
near -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
a -X- _ O
document -X- _ O
may -X- _ O
be -X- _ O
shorter -X- _ O
than -X- _ O
512 -X- _ O
tokens -X- _ O
, -X- _ O
so -X- _ O
we -X- _ O
dynamically -X- _ O
in- -X- _ O
crease -X- _ O
the -X- _ O
batch -X- _ O
size -X- _ O
in -X- _ O
these -X- _ O
cases -X- _ O
to -X- _ O
achieve -X- _ O
a -X- _ O
similar -X- _ O
number -X- _ O
of -X- _ O
total -X- _ O
tokens -X- _ O
as -X- _ O
FULL- -X- _ O

• -X- _ O
FULL -X- _ B-TaskName
- -X- _ I-TaskName
SENTENCES -X- _ I-TaskName
: -X- _ O
Each -X- _ O
input -X- _ O
is -X- _ O
packed -X- _ O
with -X- _ O
full -X- _ O
sentences -X- _ O
sampled -X- _ O
contiguously -X- _ O
from -X- _ O
one -X- _ O
or -X- _ O
more -X- _ O
documents -X- _ O
, -X- _ O
such -X- _ O
that -X- _ O
the -X- _ O
total -X- _ O
length -X- _ O
is -X- _ O
at -X- _ O
most -X- _ O
512 -X- _ O
tokens -X- _ O
. -X- _ O
Inputs -X- _ O
may -X- _ O
cross -X- _ O
document -X- _ O
boundaries -X- _ O
. -X- _ O
When -X- _ O
we -X- _ O
reach -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
one -X- _ O
doc- -X- _ O
ument -X- _ O
, -X- _ O
we -X- _ O
begin -X- _ O
sampling -X- _ O
sentences -X- _ O
from -X- _ O
the -X- _ O
next -X- _ O
document -X- _ O
and -X- _ O
add -X- _ O
an -X- _ O
extra -X- _ O
separator -X- _ O
token -X- _ O
between -X- _ O
documents -X- _ O
. -X- _ O
We -X- _ O
remove -X- _ O
the -X- _ O
NSP -X- _ B-MetricName
loss -X- _ I-MetricName
. -X- _ O

• -X- _ O
SENTENCE -X- _ B-TaskName
- -X- _ I-TaskName
PAIR+NSP -X- _ I-TaskName
: -X- _ O
Each -X- _ O
input -X- _ O
contains -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
natural -X- _ O
sentences -X- _ O
, -X- _ O
either -X- _ O
sampled -X- _ O
from -X- _ O
a -X- _ O
contiguous -X- _ O
portion -X- _ O
of -X- _ O
one -X- _ O
document -X- _ O
or -X- _ O
from -X- _ O
separate -X- _ O
documents -X- _ O
. -X- _ O
Since -X- _ O
these -X- _ O
inputs -X- _ O
are -X- _ O
sig- -X- _ O
niﬁcantly -X- _ O
shorter -X- _ O
than -X- _ O
512 -X- _ O
tokens -X- _ O
, -X- _ O
we -X- _ O
increase -X- _ O
the -X- _ O
batch -X- _ O
size -X- _ O
so -X- _ O
that -X- _ O
the -X- _ O
total -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
remains -X- _ O
similar -X- _ O
to -X- _ O
SEGMENT -X- _ B-TaskName
- -X- _ I-TaskName
PAIR+NSP -X- _ I-TaskName
. -X- _ O
We -X- _ O
re- -X- _ O
tain -X- _ O
the -X- _ O
NSP -X- _ B-MetricName
loss -X- _ I-MetricName
. -X- _ O

Table -X- _ O
2 -X- _ O
: -X- _ O
Development -X- _ O
set -X- _ O
results -X- _ O
for -X- _ O
base -X- _ O
models -X- _ O
pretrained -X- _ O
over -X- _ O
BOOKCORPUS -X- _ B-DatasetName
and -X- _ O
WIKIPEDIA -X- _ B-DatasetName
. -X- _ O
All -X- _ O
models -X- _ O
are -X- _ O
trained -X- _ O
for -X- _ O
1 -X- _ O
M -X- _ O
steps -X- _ O
with -X- _ O
a -X- _ O
batch -X- _ O
size -X- _ O
of -X- _ O
256 -X- _ O
sequences -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
F1 -X- _ B-MetricName
for -X- _ O
SQuAD -X- _ B-DatasetName
and -X- _ O
accuracy -X- _ B-MetricName
for -X- _ O
MNLI -X- _ B-DatasetName
- -X- _ I-DatasetName
m -X- _ I-DatasetName
, -X- _ O
SST-2 -X- _ B-DatasetName
and -X- _ O
RACE -X- _ B-DatasetName
. -X- _ O
Reported -X- _ O
results -X- _ O
are -X- _ O
medians -X- _ O
over -X- _ O
ﬁve -X- _ O
random -X- _ O
initializations -X- _ O
( -X- _ O
seeds -X- _ O
) -X- _ O
. -X- _ O
Results -X- _ O
for -X- _ O
BERTBASE -X- _ B-MethodName
and -X- _ O
XLNetBASE -X- _ B-MethodName
are -X- _ O
from -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

BERTBASE -X- _ B-MethodName
88.5/76.3 -X- _ O
84.3 -X- _ O
92.8 -X- _ O
64.3 -X- _ O
XLNetBASE -X- _ B-MethodName
( -X- _ O
K -X- _ B-HyperparameterName
= -X- _ O
7 -X- _ B-HyperparameterValue
) -X- _ O
– -X- _ O
/81.3 -X- _ O
85.8 -X- _ O
92.7 -X- _ O
66.1 -X- _ O
XLNetBASE -X- _ B-MethodName
( -X- _ O
K -X- _ B-HyperparameterName
= -X- _ O
6 -X- _ B-HyperparameterValue
) -X- _ O
– -X- _ O
/81.0 -X- _ O
85.6 -X- _ O
93.4 -X- _ O
66.7 -X- _ O

• -X- _ O
SEGMENT -X- _ O
- -X- _ O
PAIR+NSP -X- _ O
: -X- _ O
This -X- _ O
follows -X- _ O
the -X- _ O
original -X- _ O
input -X- _ O
format -X- _ O
used -X- _ O
in -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
NSP -X- _ B-MetricName
loss -X- _ I-MetricName
. -X- _ O
Each -X- _ O
input -X- _ O
has -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
seg- -X- _ O
ments -X- _ O
, -X- _ O
which -X- _ O
can -X- _ O
each -X- _ O
contain -X- _ O
multiple -X- _ O
natural -X- _ O
sentences -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
total -X- _ O
combined -X- _ O
length -X- _ O
must -X- _ O
be -X- _ O
less -X- _ O
than -X- _ O
512 -X- _ O
tokens -X- _ O
. -X- _ O

In -X- _ O
the -X- _ O
original -X- _ O
BERT -X- _ B-MethodName
pretraining -X- _ O
procedure -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
observes -X- _ O
two -X- _ O
concatenated -X- _ O
document -X- _ O
seg- -X- _ O
ments -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
either -X- _ O
sampled -X- _ O
contiguously -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
document -X- _ O
( -X- _ O
with -X- _ O
p -X- _ B-HyperparameterName
= -X- _ O
0.5 -X- _ B-HyperparameterValue
) -X- _ O
or -X- _ O
from -X- _ O
distinct -X- _ O
documents -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
masked -X- _ O
lan- -X- _ O
guage -X- _ O
modeling -X- _ O
objective -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
to -X- _ O
predict -X- _ O
whether -X- _ O
the -X- _ O
observed -X- _ O
document -X- _ O
segments -X- _ O
come -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
or -X- _ O
distinct -X- _ O
documents -X- _ O
via -X- _ O
an -X- _ O
auxiliary -X- _ O
Next -X- _ B-MetricName
Sentence -X- _ I-MetricName
Prediction -X- _ I-MetricName
( -X- _ O
NSP -X- _ B-MetricName
) -X- _ O
loss -X- _ O
. -X- _ O
The -X- _ O
NSP -X- _ B-MetricName
loss -X- _ I-MetricName
was -X- _ O
hypothesized -X- _ O
to -X- _ O
be -X- _ O
an -X- _ O
impor- -X- _ O
tant -X- _ O
factor -X- _ O
in -X- _ O
training -X- _ O
the -X- _ O
original -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
. -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
observe -X- _ O
that -X- _ O
removing -X- _ O
NSP -X- _ B-MetricName
hurts -X- _ O
performance -X- _ O
, -X- _ O
with -X- _ O
signiﬁcant -X- _ O
performance -X- _ O
degradation -X- _ O
on -X- _ O
QNLI -X- _ B-DatasetName
, -X- _ O
MNLI -X- _ B-DatasetName
, -X- _ O
and -X- _ O
SQuAD -X- _ B-DatasetName
1.1 -X- _ I-DatasetName
. -X- _ O
However -X- _ O
, -X- _ O
some -X- _ O
recent -X- _ O
work -X- _ O
has -X- _ O
questioned -X- _ O
the -X- _ O
necessity -X- _ O
of -X- _ O
the -X- _ O
NSP -X- _ B-MetricName
loss -X- _ I-MetricName
( -X- _ O
Lample -X- _ O
and -X- _ O
Conneau -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Joshi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
better -X- _ O
understand -X- _ O
this -X- _ O
discrepancy -X- _ O
, -X- _ O
we -X- _ O
com- -X- _ O
pare -X- _ O
several -X- _ O
alternative -X- _ O
training -X- _ O
formats -X- _ O
: -X- _ O

Results -X- _ O
Table -X- _ O
1 -X- _ O
compares -X- _ O
the -X- _ O
published -X- _ O
BERTBASE -X- _ B-MethodName
results -X- _ O
from -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
to -X- _ O
our -X- _ O
reimplementation -X- _ O
with -X- _ O
either -X- _ O
static -X- _ O
or -X- _ O
dynamic -X- _ O
masking -X- _ O
. -X- _ O
We -X- _ O
ﬁnd -X- _ O
that -X- _ O
our -X- _ O
reimplementation -X- _ O
with -X- _ O
static -X- _ O
masking -X- _ O
performs -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
, -X- _ O
and -X- _ O
dynamic -X- _ O
masking -X- _ O
is -X- _ O
comparable -X- _ O
or -X- _ O
slightly -X- _ O
better -X- _ O
than -X- _ O
static -X- _ O
masking -X- _ O
. -X- _ O
Given -X- _ O
these -X- _ O
results -X- _ O
and -X- _ O
the -X- _ O
additional -X- _ O
efﬁciency -X- _ O
beneﬁts -X- _ O
of -X- _ O
dynamic -X- _ O
masking -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
dynamic -X- _ O
masking -X- _ O
in -X- _ O
the -X- _ O
remainder -X- _ O
of -X- _ O
the -X- _ O
experiments -X- _ O
. -X- _ O

Table -X- _ O
1 -X- _ O
: -X- _ O
Comparison -X- _ O
between -X- _ O
static -X- _ O
and -X- _ O
dynamic -X- _ O
masking -X- _ O
for -X- _ O
BERTBASE -X- _ B-MethodName
. -X- _ O
We -X- _ O
report -X- _ O
F1 -X- _ B-MetricName
for -X- _ O
SQuAD -X- _ B-DatasetName
and -X- _ O
accuracy -X- _ B-MetricName
for -X- _ O
MNLI -X- _ B-TaskName
- -X- _ I-TaskName
m -X- _ I-TaskName
and -X- _ O
SST-2 -X- _ B-TaskName
. -X- _ O
Reported -X- _ O
results -X- _ O
are -X- _ O
medians -X- _ O
over -X- _ O
5 -X- _ O
random -X- _ O
initializations -X- _ O
( -X- _ O
seeds -X- _ O
) -X- _ O
. -X- _ O
Refer- -X- _ O
ence -X- _ O
results -X- _ O
are -X- _ O
from -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

Our -X- _ O
reimplementation -X- _ O
: -X- _ O
static -X- _ O
78.3 -X- _ O
84.3 -X- _ O
92.5 -X- _ O
dynamic -X- _ O
78.7 -X- _ O
84.0 -X- _ O
92.9 -X- _ O

7Studying -X- _ O
architectural -X- _ O
changes -X- _ O
, -X- _ O
including -X- _ O
larger -X- _ O
archi- -X- _ O
tectures -X- _ O
, -X- _ O
is -X- _ O
an -X- _ O
important -X- _ O
area -X- _ O
for -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O

As -X- _ O
discussed -X- _ O
in -X- _ O
Section -X- _ O
2 -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
relies -X- _ O
on -X- _ O
ran- -X- _ O
domly -X- _ O
masking -X- _ O
and -X- _ O
predicting -X- _ O
tokens -X- _ O
. -X- _ O
The -X- _ O
orig- -X- _ O
inal -X- _ O
BERT -X- _ B-MethodName
implementation -X- _ O
performed -X- _ O
masking -X- _ O
once -X- _ O
during -X- _ O
data -X- _ O
preprocessing -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
a -X- _ O
sin- -X- _ O
gle -X- _ O
static -X- _ O
mask -X- _ O
. -X- _ O
To -X- _ O
avoid -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
mask -X- _ O
for -X- _ O
each -X- _ O
training -X- _ O
instance -X- _ O
in -X- _ O
every -X- _ O
epoch -X- _ O
, -X- _ O
training -X- _ O
data -X- _ O
was -X- _ O
duplicated -X- _ O
10 -X- _ O
times -X- _ O
so -X- _ O
that -X- _ O
each -X- _ O
sequence -X- _ O
is -X- _ O
masked -X- _ O
in -X- _ O
10 -X- _ O
different -X- _ O
ways -X- _ O
over -X- _ O
the -X- _ O
40 -X- _ O
epochs -X- _ O
of -X- _ O
training -X- _ O
. -X- _ O
Thus -X- _ O
, -X- _ O
each -X- _ O
training -X- _ O
sequence -X- _ O
was -X- _ O
seen -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
mask -X- _ O
four -X- _ O
times -X- _ O
during -X- _ O
training -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
this -X- _ O
strategy -X- _ O
with -X- _ O
dynamic -X- _ O
mask- -X- _ O
ing -X- _ O
where -X- _ O
we -X- _ O
generate -X- _ O
the -X- _ O
masking -X- _ O
pattern -X- _ O
every -X- _ O
time -X- _ O
we -X- _ O
feed -X- _ O
a -X- _ O
sequence -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
This -X- _ O
be- -X- _ O
comes -X- _ O
crucial -X- _ O
when -X- _ O
pretraining -X- _ O
for -X- _ O
more -X- _ O
steps -X- _ O
or -X- _ O
with -X- _ O
larger -X- _ O
datasets -X- _ O
. -X- _ O

Speciﬁcally -X- _ O
, -X- _ O
we -X- _ O
begin -X- _ O
by -X- _ O
training -X- _ O
BERT -X- _ B-MethodName
models -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
conﬁguration -X- _ O
as -X- _ O
BERTBASE -X- _ B-MethodName
( -X- _ O
L -X- _ B-HyperparameterName
= -X- _ O
12 -X- _ B-HyperparameterValue
, -X- _ O
H -X- _ B-HyperparameterName
= -X- _ O
768 -X- _ B-HyperparameterValue
, -X- _ O
A -X- _ B-HyperparameterName
= -X- _ O
12 -X- _ B-HyperparameterValue
, -X- _ O
110 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
params -X- _ B-HyperparameterName
) -X- _ O
. -X- _ O

This -X- _ O
section -X- _ O
explores -X- _ O
and -X- _ O
quantiﬁes -X- _ O
which -X- _ O
choices -X- _ O
are -X- _ O
important -X- _ O
for -X- _ O
successfully -X- _ O
pretraining -X- _ O
BERT -X- _ B-MethodName
models -X- _ O
. -X- _ O
We -X- _ O
keep -X- _ O
the -X- _ O
model -X- _ O
architecture -X- _ O
ﬁxed.7 -X- _ O

RACE -X- _ B-TaskName
The -X- _ B-TaskName
ReAding -X- _ I-TaskName
Comprehension -X- _ I-TaskName
from -X- _ I-TaskName
Ex- -X- _ I-TaskName
aminations -X- _ I-TaskName
( -X- _ O
RACE -X- _ B-TaskName
) -X- _ O
( -X- _ O
Lai -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
task -X- _ O
is -X- _ O
a -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
reading -X- _ O
comprehension -X- _ O
dataset -X- _ O
with -X- _ O
more -X- _ O
than -X- _ O
28,000 -X- _ O
passages -X- _ O
and -X- _ O
nearly -X- _ O
100,000 -X- _ O
questions -X- _ O
. -X- _ O
The -X- _ O
dataset -X- _ O
is -X- _ O
collected -X- _ O
from -X- _ O
English -X- _ O
examinations -X- _ O
in -X- _ O
China -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
designed -X- _ O
for -X- _ O
middle -X- _ O
and -X- _ O
high -X- _ O
school -X- _ O
students -X- _ O
. -X- _ O
In -X- _ O
RACE -X- _ B-TaskName
, -X- _ O
each -X- _ O
passage -X- _ O
is -X- _ O
associated -X- _ O
with -X- _ O
multiple -X- _ O
questions -X- _ O
. -X- _ O
For -X- _ O
every -X- _ O
question -X- _ O
, -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
select -X- _ O
one -X- _ O
correct -X- _ O
an- -X- _ O
swer -X- _ O
from -X- _ O
four -X- _ O
options -X- _ O
. -X- _ O
RACE -X- _ B-TaskName
has -X- _ O
signiﬁcantly -X- _ O
longer -X- _ O
context -X- _ O
than -X- _ O
other -X- _ O
popular -X- _ O
reading -X- _ O
compre- -X- _ O
hension -X- _ O
datasets -X- _ O
and -X- _ O
the -X- _ O
proportion -X- _ O
of -X- _ O
questions -X- _ O
that -X- _ O
requires -X- _ O
reasoning -X- _ O
is -X- _ O
very -X- _ O
large -X- _ O
. -X- _ O

V2.0 -X- _ O
some -X- _ O
questions -X- _ O
are -X- _ O
not -X- _ O
answered -X- _ O
in -X- _ O
the -X- _ O
pro- -X- _ O
vided -X- _ O
context -X- _ O
, -X- _ O
making -X- _ O
the -X- _ O
task -X- _ O
more -X- _ O
challenging -X- _ O
. -X- _ O
For -X- _ O
SQuAD -X- _ B-DatasetName
V1.1 -X- _ I-DatasetName
we -X- _ O
adopt -X- _ O
the -X- _ O
same -X- _ O
span -X- _ O
pre- -X- _ O
diction -X- _ O
method -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
SQuAD -X- _ B-DatasetName
V2.0 -X- _ I-DatasetName
, -X- _ O
we -X- _ O
add -X- _ O
an -X- _ O
additional -X- _ O
binary -X- _ O
classi- -X- _ O
ﬁer -X- _ O
to -X- _ O
predict -X- _ O
whether -X- _ O
the -X- _ O
question -X- _ O
is -X- _ O
answerable -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
train -X- _ O
jointly -X- _ O
by -X- _ O
summing -X- _ O
the -X- _ O
classiﬁca- -X- _ O
tion -X- _ O
and -X- _ O
span -X- _ O
loss -X- _ O
terms -X- _ O
. -X- _ O
During -X- _ O
evaluation -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
predict -X- _ O
span -X- _ O
indices -X- _ O
on -X- _ O
pairs -X- _ O
that -X- _ O
are -X- _ O
classi- -X- _ O
ﬁed -X- _ O
as -X- _ O
answerable -X- _ O
. -X- _ O

2006 -X- _ O
; -X- _ O
Giampiccolo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2007 -X- _ O
; -X- _ O
Bentivogli -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
and -X- _ O
Winograd -X- _ B-DatasetName
NLI -X- _ I-DatasetName
( -X- _ O
WNLI -X- _ B-DatasetName
) -X- _ O
( -X- _ O
Levesque -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
. -X- _ O

2013 -X- _ O
) -X- _ O
, -X- _ O
Microsoft -X- _ B-DatasetName
Research -X- _ I-DatasetName
Paragraph -X- _ I-DatasetName
Corpus -X- _ I-DatasetName
( -X- _ O
MRPC -X- _ B-DatasetName
) -X- _ O
( -X- _ O
Dolan -X- _ O
and -X- _ O
Brockett -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
, -X- _ O
Semantic -X- _ B-DatasetName
Tex- -X- _ I-DatasetName
tual -X- _ I-DatasetName
Similarity -X- _ I-DatasetName
Benchmark -X- _ I-DatasetName
( -X- _ O
STS -X- _ B-DatasetName
) -X- _ O
( -X- _ O
Agirre -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2007 -X- _ O
) -X- _ O
, -X- _ O
Quora -X- _ B-DatasetName
Question -X- _ I-DatasetName
Pairs -X- _ I-DatasetName
( -X- _ O
QQP -X- _ B-DatasetName
) -X- _ O
( -X- _ O
Iyer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
Multi- -X- _ B-DatasetName
Genre -X- _ I-DatasetName
NLI -X- _ I-DatasetName
( -X- _ O
MNLI -X- _ B-DatasetName
) -X- _ O
( -X- _ O
Williams -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
Question -X- _ B-DatasetName
NLI -X- _ I-DatasetName
( -X- _ O
QNLI -X- _ B-DatasetName
) -X- _ O
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
Recognizing -X- _ B-DatasetName
Textual -X- _ I-DatasetName
Entailment -X- _ I-DatasetName
( -X- _ O
RTE -X- _ B-DatasetName
) -X- _ O
( -X- _ O
Dagan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2006 -X- _ O
; -X- _ O
Bar -X- _ O
- -X- _ O
Haim -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

5The -X- _ O
authors -X- _ O
and -X- _ O
their -X- _ O
afﬁliated -X- _ O
institutions -X- _ O
are -X- _ O
not -X- _ O
in -X- _ O
any -X- _ O
way -X- _ O
afﬁliated -X- _ O
with -X- _ O
the -X- _ O
creation -X- _ O
of -X- _ O
the -X- _ O
OpenWebText -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
6The -X- _ O
datasets -X- _ O
are -X- _ O
: -X- _ O
CoLA -X- _ B-DatasetName
( -X- _ O
Warstadt -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
Stanford -X- _ B-DatasetName
Sentiment -X- _ I-DatasetName
Treebank -X- _ I-DatasetName
( -X- _ O
SST -X- _ B-DatasetName
) -X- _ O
( -X- _ O
Socher -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

SQuAD -X- _ B-DatasetName
The -X- _ B-DatasetName
Stanford -X- _ I-DatasetName
Question -X- _ I-DatasetName
Answering -X- _ I-DatasetName
Dataset -X- _ I-DatasetName
( -X- _ O
SQuAD -X- _ B-DatasetName
) -X- _ O
provides -X- _ O
a -X- _ O
paragraph -X- _ O
of -X- _ O
context -X- _ O
and -X- _ O
a -X- _ O
question -X- _ O
. -X- _ O
The -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
answer -X- _ O
the -X- _ O
question -X- _ O
by -X- _ O
extracting -X- _ O
the -X- _ O
relevant -X- _ O
span -X- _ O
from -X- _ O
the -X- _ O
context -X- _ O
. -X- _ O
We -X- _ O
evaluate -X- _ O
on -X- _ O
two -X- _ O
versions -X- _ O
of -X- _ O
SQuAD -X- _ B-DatasetName
: -X- _ I-DatasetName
V1.1 -X- _ I-DatasetName
and -X- _ I-DatasetName
V2.0 -X- _ I-DatasetName
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
V1.1 -X- _ O
the -X- _ O
context -X- _ O
always -X- _ O
contains -X- _ O
an -X- _ O
answer -X- _ O
, -X- _ O
whereas -X- _ O
in -X- _ O

GLUE -X- _ B-MetricName
The -X- _ B-MetricName
General -X- _ I-MetricName
Language -X- _ I-MetricName
Understand- -X- _ I-MetricName
ing -X- _ I-MetricName
Evaluation -X- _ I-MetricName
( -X- _ O
GLUE -X- _ B-MetricName
) -X- _ O
benchmark -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019b -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
9 -X- _ O
datasets -X- _ O
for -X- _ O
evaluating -X- _ O
natural -X- _ O
language -X- _ O
understanding -X- _ O
systems.6 -X- _ O
Tasks -X- _ O
are -X- _ O
framed -X- _ O
as -X- _ O
either -X- _ O
single -X- _ B-TaskName
- -X- _ I-TaskName
sentence -X- _ I-TaskName
classiﬁcation -X- _ I-TaskName
or -X- _ O
sentence -X- _ B-TaskName
- -X- _ I-TaskName
pair -X- _ I-TaskName
classiﬁcation -X- _ I-TaskName
tasks -X- _ O
. -X- _ O
The -X- _ O
GLUE -X- _ B-MetricName
organizers -X- _ O
provide -X- _ O
training -X- _ O
and -X- _ O
development -X- _ O
data -X- _ O
splits -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
a -X- _ O
submission -X- _ O
server -X- _ O
and -X- _ O
leader- -X- _ O
board -X- _ O
that -X- _ O
allows -X- _ O
participants -X- _ O
to -X- _ O
evaluate -X- _ O
and -X- _ O
com- -X- _ O
pare -X- _ O
their -X- _ O
systems -X- _ O
on -X- _ O
private -X- _ O
held -X- _ O
- -X- _ O
out -X- _ O
test -X- _ O
data -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
replication -X- _ O
study -X- _ O
in -X- _ O
Section -X- _ O
4 -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
sets -X- _ O
after -X- _ O
ﬁnetuning -X- _ O
the -X- _ O
pretrained -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
corresponding -X- _ O
single- -X- _ O
task -X- _ O
training -X- _ O
data -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
without -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
training -X- _ O
or -X- _ O
ensembling -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
ﬁnetuning -X- _ O
procedure -X- _ O
follows -X- _ O
the -X- _ O
original -X- _ O
BERT -X- _ B-MethodName
paper -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
Section -X- _ O
5 -X- _ O
we -X- _ O
additionally -X- _ O
report -X- _ O
test -X- _ O
set -X- _ O
re- -X- _ O
sults -X- _ O
obtained -X- _ O
from -X- _ O
the -X- _ O
public -X- _ O
leaderboard -X- _ O
. -X- _ O
These -X- _ O
results -X- _ O
depend -X- _ O
on -X- _ O
a -X- _ O
several -X- _ O
task -X- _ O
- -X- _ O
speciﬁc -X- _ O
modiﬁca- -X- _ O
tions -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
describe -X- _ O
in -X- _ O
Section -X- _ O
5.1 -X- _ O
. -X- _ O

Following -X- _ O
previous -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
our -X- _ O
pre- -X- _ O
trained -X- _ O
models -X- _ O
on -X- _ O
downstream -X- _ O
tasks -X- _ O
using -X- _ O
the -X- _ O
fol- -X- _ O
lowing -X- _ O
three -X- _ O
benchmarks -X- _ O
. -X- _ O

( -X- _ O
2018 -X- _ O
) -X- _ O
containing -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
CommonCrawl -X- _ B-DatasetName
data -X- _ O
ﬁltered -X- _ O
to -X- _ O
match -X- _ O
the -X- _ O
story -X- _ O
- -X- _ O
like -X- _ O
style -X- _ O
of -X- _ O
Winograd -X- _ O
schemas -X- _ O
. -X- _ O
( -X- _ O
31 -X- _ O
GB -X- _ O
) -X- _ O
. -X- _ O

pus -X- _ O
described -X- _ O
in -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
text -X- _ O
is -X- _ O
web -X- _ O
content -X- _ O
extracted -X- _ O
from -X- _ O
URLs -X- _ O
shared -X- _ O
on -X- _ O
Reddit -X- _ O
with -X- _ O
at -X- _ O
least -X- _ O
three -X- _ O
upvotes -X- _ O
. -X- _ O
( -X- _ O
38GB).5 -X- _ O

4We -X- _ O
use -X- _ O
news -X- _ O
- -X- _ O
please -X- _ O
( -X- _ O
Hamborg -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
to -X- _ O
col- -X- _ O
lect -X- _ O
and -X- _ O
extract -X- _ O
CC -X- _ B-DatasetName
- -X- _ I-DatasetName
NEWS -X- _ I-DatasetName
. -X- _ O
CC -X- _ B-DatasetName
- -X- _ I-DatasetName
NEWS -X- _ I-DatasetName
is -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
RE- -X- _ B-DatasetName
ALNEWS -X- _ I-DatasetName
dataset -X- _ O
described -X- _ O
in -X- _ O
Zellers -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O

• -X- _ O
OPENWEBTEXT -X- _ B-DatasetName
( -X- _ O
Gokaslan -X- _ O
and -X- _ O
Cohen -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
an -X- _ O
open -X- _ O
- -X- _ O
source -X- _ O
recreation -X- _ O
of -X- _ O
the -X- _ O
WebText -X- _ O
cor- -X- _ O

• -X- _ O
CC -X- _ B-DatasetName
- -X- _ I-DatasetName
NEWS -X- _ I-DatasetName
, -X- _ O
which -X- _ O
we -X- _ O
collected -X- _ O
from -X- _ O
the -X- _ O
En- -X- _ O
glish -X- _ O
portion -X- _ O
of -X- _ O
the -X- _ O
CommonCrawl -X- _ B-DatasetName
News -X- _ I-DatasetName
dataset -X- _ I-DatasetName
( -X- _ O
Nagel -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
data -X- _ O
contains -X- _ O
63 -X- _ O
million -X- _ O
English -X- _ O
news -X- _ O
articles -X- _ O
crawled -X- _ O
between -X- _ O
September -X- _ O
2016 -X- _ O
and -X- _ O
February -X- _ O
2019 -X- _ O
. -X- _ O
( -X- _ O
76 -X- _ O
GB -X- _ O
af- -X- _ O
ter -X- _ O
ﬁltering).4 -X- _ O

• -X- _ O
BOOKCORPUS -X- _ B-DatasetName
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
plus -X- _ O
English -X- _ B-DatasetName
WIKIPEDIA -X- _ I-DatasetName
. -X- _ O
This -X- _ O
is -X- _ O
the -X- _ O
original -X- _ O
data -X- _ O
used -X- _ O
to -X- _ O
train -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
( -X- _ O
16 -X- _ O
GB -X- _ O
) -X- _ O
. -X- _ O

BERT -X- _ B-MethodName
- -X- _ O
style -X- _ O
pretraining -X- _ O
crucially -X- _ O
relies -X- _ O
on -X- _ O
large -X- _ O
quantities -X- _ O
of -X- _ O
text -X- _ O
. -X- _ O
Baevski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
demon- -X- _ O
strate -X- _ O
that -X- _ O
increasing -X- _ O
data -X- _ O
size -X- _ O
can -X- _ O
result -X- _ O
in -X- _ O
im- -X- _ O
proved -X- _ O
end -X- _ O
- -X- _ O
task -X- _ O
performance -X- _ O
. -X- _ O
Several -X- _ O
efforts -X- _ O
have -X- _ O
trained -X- _ O
on -X- _ O
datasets -X- _ O
larger -X- _ O
and -X- _ O
more -X- _ O
diverse -X- _ O
than -X- _ O
the -X- _ O
original -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Zellers -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Unfortu- -X- _ O
nately -X- _ O
, -X- _ O
not -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
additional -X- _ O
datasets -X- _ O
can -X- _ O
be -X- _ O
publicly -X- _ O
released -X- _ O
. -X- _ O
For -X- _ O
our -X- _ O
study -X- _ O
, -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
gath- -X- _ O
ering -X- _ O
as -X- _ O
much -X- _ O
data -X- _ O
as -X- _ O
possible -X- _ O
for -X- _ O
experimenta- -X- _ O
tion -X- _ O
, -X- _ O
allowing -X- _ O
us -X- _ O
to -X- _ O
match -X- _ O
the -X- _ O
overall -X- _ O
quality -X- _ O
and -X- _ O
quantity -X- _ O
of -X- _ O
data -X- _ O
as -X- _ O
appropriate -X- _ O
for -X- _ O
each -X- _ O
compari- -X- _ O
son -X- _ O
. -X- _ O
We -X- _ O
consider -X- _ O
ﬁve -X- _ O
English -X- _ O
- -X- _ O
language -X- _ O
corpora -X- _ O
of -X- _ O
varying -X- _ O
sizes -X- _ O
and -X- _ O
domains -X- _ O
, -X- _ O
totaling -X- _ O
over -X- _ O
160 -X- _ O
GB -X- _ O
of -X- _ O
uncompressed -X- _ O
text -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
following -X- _ O
text -X- _ O
corpora -X- _ O
: -X- _ O

optimization -X- _ O
hyperparameters -X- _ O
, -X- _ O
given -X- _ O
in -X- _ O
Section -X- _ O
2 -X- _ O
, -X- _ O
except -X- _ O
for -X- _ O
the -X- _ O
peak -X- _ O
learning -X- _ O
rate -X- _ O
and -X- _ O
number -X- _ O
of -X- _ O
warmup -X- _ O
steps -X- _ O
, -X- _ O
which -X- _ O
are -X- _ O
tuned -X- _ O
separately -X- _ O
for -X- _ O
each -X- _ O
setting -X- _ O
. -X- _ O
We -X- _ O
additionally -X- _ O
found -X- _ O
training -X- _ O
to -X- _ O
be -X- _ O
very -X- _ O
sensitive -X- _ O
to -X- _ O
the -X- _ O
Adam -X- _ O
epsilon -X- _ O
term -X- _ O
, -X- _ O
and -X- _ O
in -X- _ O
some -X- _ O
cases -X- _ O
we -X- _ O
obtained -X- _ O
better -X- _ O
performance -X- _ O
or -X- _ O
improved -X- _ O
stability -X- _ O
after -X- _ O
tuning -X- _ O
it -X- _ O
. -X- _ O
Similarly -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
setting -X- _ O
β2 -X- _ B-HyperparameterName
= -X- _ O
0.98 -X- _ B-HyperparameterValue
to -X- _ O
improve -X- _ O
stability -X- _ O
when -X- _ O
training -X- _ O
with -X- _ O
large -X- _ O
batch -X- _ O
sizes -X- _ O
. -X- _ O
We -X- _ O
pretrain -X- _ O
with -X- _ O
sequences -X- _ O
of -X- _ O
at -X- _ O
most -X- _ O
T -X- _ B-HyperparameterName
= -X- _ O
512 -X- _ B-HyperparameterValue
tokens -X- _ O
. -X- _ O
Unlike -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
ran- -X- _ O
domly -X- _ O
inject -X- _ O
short -X- _ O
sequences -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
train -X- _ O
with -X- _ O
a -X- _ O
reduced -X- _ O
sequence -X- _ O
length -X- _ O
for -X- _ O
the -X- _ O
ﬁrst -X- _ O
90 -X- _ O
% -X- _ O
of -X- _ O
updates -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
only -X- _ O
with -X- _ O
full -X- _ O
- -X- _ O
length -X- _ O
sequences -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
with -X- _ O
mixed -X- _ O
precision -X- _ O
ﬂoating -X- _ O
point -X- _ O
arithmetic -X- _ O
on -X- _ O
DGX-1 -X- _ O
machines -X- _ O
, -X- _ O
each -X- _ O
with -X- _ O
8 -X- _ O
× -X- _ O
32 -X- _ O
GB -X- _ O
Nvidia -X- _ O
V100 -X- _ O
GPUs -X- _ O
interconnected -X- _ O
by -X- _ O
In- -X- _ O
ﬁniband -X- _ O
( -X- _ O
Micikevicius -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

3Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
dataset -X- _ O
but -X- _ O
report -X- _ O
having -X- _ O
only -X- _ O
13 -X- _ O
GB -X- _ O
of -X- _ O
text -X- _ O
after -X- _ O
data -X- _ O
cleaning -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
most -X- _ O
likely -X- _ O
due -X- _ O
to -X- _ O
subtle -X- _ O
differences -X- _ O
in -X- _ O
cleaning -X- _ O
of -X- _ O
the -X- _ O
Wikipedia -X- _ B-DatasetName
data -X- _ O
. -X- _ O

We -X- _ O
reimplement -X- _ O
BERT -X- _ B-MethodName
in -X- _ O
FAIRSEQ -X- _ B-MethodName
( -X- _ O
Ott -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
primarily -X- _ O
follow -X- _ O
the -X- _ O
original -X- _ O
BERT -X- _ B-MethodName

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
describe -X- _ O
the -X- _ O
experimental -X- _ O
setup -X- _ O
for -X- _ O
our -X- _ O
replication -X- _ O
study -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
. -X- _ O

PUS -X- _ B-DatasetName
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
plus -X- _ O
English -X- _ B-DatasetName
WIKIPEDIA -X- _ I-DatasetName
, -X- _ O
which -X- _ O
totals -X- _ O
16 -X- _ O
GB -X- _ O
of -X- _ O
uncompressed -X- _ O
text.3 -X- _ O

BERT -X- _ B-MethodName
is -X- _ O
optimized -X- _ O
with -X- _ O
Adam -X- _ O
( -X- _ O
Kingma -X- _ O
and -X- _ O
Ba -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
using -X- _ O
the -X- _ O
following -X- _ O
parameters -X- _ O
: -X- _ O
β1 -X- _ B-HyperparameterName
= -X- _ O
0.9 -X- _ B-HyperparameterValue
, -X- _ O
β2 -X- _ B-HyperparameterName
= -X- _ O
0.999 -X- _ B-HyperparameterValue
, -X- _ O
ǫ -X- _ B-HyperparameterName
= -X- _ O
1e-6 -X- _ B-HyperparameterValue
and -X- _ O
L2 -X- _ B-HyperparameterName
weight -X- _ B-HyperparameterName
de- -X- _ I-HyperparameterName
cay -X- _ I-HyperparameterName
of -X- _ O
0.01 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
warmed -X- _ O
up -X- _ O
over -X- _ O
the -X- _ O
ﬁrst -X- _ O
10,000 -X- _ O
steps -X- _ O
to -X- _ O
a -X- _ O
peak -X- _ O
value -X- _ O
of -X- _ O
1e-4 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
then -X- _ O
linearly -X- _ O
decayed -X- _ O
. -X- _ O
BERT -X- _ B-MethodName
trains -X- _ O
with -X- _ O
a -X- _ O
dropout -X- _ B-HyperparameterName
of -X- _ O
0.1 -X- _ B-HyperparameterValue
on -X- _ O
all -X- _ O
layers -X- _ O
and -X- _ O
at- -X- _ O
tention -X- _ O
weights -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
GELU -X- _ B-HyperparameterName
activation -X- _ I-HyperparameterName
func- -X- _ I-HyperparameterName
tion -X- _ I-HyperparameterName
( -X- _ O
Hendrycks -X- _ O
and -X- _ O
Gimpel -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
Models -X- _ O
are -X- _ O
pretrained -X- _ O
for -X- _ O
S -X- _ O
= -X- _ O
1,000,000 -X- _ O
updates -X- _ O
, -X- _ O
with -X- _ O
mini- -X- _ O
batches -X- _ O
containing -X- _ O
B -X- _ B-HyperparameterName
= -X- _ O
256 -X- _ B-HyperparameterValue
sequences -X- _ O
of -X- _ O
maxi- -X- _ O
mum -X- _ O
length -X- _ O
T -X- _ B-HyperparameterName
= -X- _ O
512 -X- _ B-HyperparameterValue
tokens -X- _ O
. -X- _ O

Next -X- _ B-TaskName
Sentence -X- _ I-TaskName
Prediction -X- _ I-TaskName
( -X- _ O
NSP -X- _ B-TaskName
) -X- _ O
NSP -X- _ B-TaskName
is -X- _ O
a -X- _ O
bi- -X- _ O
nary -X- _ O
classiﬁcation -X- _ O
loss -X- _ O
for -X- _ O
predicting -X- _ O
whether -X- _ O
two -X- _ O
segments -X- _ O
follow -X- _ O
each -X- _ O
other -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
text -X- _ O
. -X- _ O
Positive -X- _ O
examples -X- _ O
are -X- _ O
created -X- _ O
by -X- _ O
taking -X- _ O
consecu- -X- _ O
tive -X- _ O
sentences -X- _ O
from -X- _ O
the -X- _ O
text -X- _ O
corpus -X- _ O
. -X- _ O
Negative -X- _ O
ex- -X- _ O
amples -X- _ O
are -X- _ O
created -X- _ O
by -X- _ O
pairing -X- _ O
segments -X- _ O
from -X- _ O
dif- -X- _ O
ferent -X- _ O
documents -X- _ O
. -X- _ O
Positive -X- _ O
and -X- _ O
negative -X- _ O
examples -X- _ O
are -X- _ O
sampled -X- _ O
with -X- _ O
equal -X- _ O
probability -X- _ O
. -X- _ O
The -X- _ O
NSP -X- _ B-TaskName
objective -X- _ O
was -X- _ O
designed -X- _ O
to -X- _ O
improve -X- _ O
performance -X- _ O
on -X- _ O
downstream -X- _ O
tasks -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
Natural -X- _ B-TaskName
Language -X- _ I-TaskName
Inference -X- _ I-TaskName
( -X- _ O
Bowman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
require -X- _ O
reasoning -X- _ O
about -X- _ O
the -X- _ O
relationships -X- _ O
between -X- _ O
pairs -X- _ O
of -X- _ O
sentences -X- _ O
. -X- _ O

and -X- _ O
10 -X- _ O
% -X- _ O
are -X- _ O
replaced -X- _ O
by -X- _ O
a -X- _ O
randomly -X- _ O
selected -X- _ O
vo- -X- _ O
cabulary -X- _ O
token -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
original -X- _ O
implementation -X- _ O
, -X- _ O
random -X- _ O
mask- -X- _ O
ing -X- _ O
and -X- _ O
replacement -X- _ O
is -X- _ O
performed -X- _ O
once -X- _ O
in -X- _ O
the -X- _ O
be- -X- _ O
ginning -X- _ O
and -X- _ O
saved -X- _ O
for -X- _ O
the -X- _ O
duration -X- _ O
of -X- _ O
training -X- _ O
, -X- _ O
al- -X- _ O
though -X- _ O
in -X- _ O
practice -X- _ O
, -X- _ O
data -X- _ O
is -X- _ O
duplicated -X- _ O
so -X- _ O
the -X- _ O
mask -X- _ O
is -X- _ O
not -X- _ O
always -X- _ O
the -X- _ O
same -X- _ O
for -X- _ O
every -X- _ O
training -X- _ O
sentence -X- _ O
( -X- _ O
see -X- _ O
Section -X- _ O
4.1 -X- _ O
) -X- _ O
. -X- _ O

Masked -X- _ B-MethodName
Language -X- _ I-MethodName
Model -X- _ I-MethodName
( -X- _ O
MLM -X- _ B-MethodName
) -X- _ O
A -X- _ O
random -X- _ O
sample -X- _ O
of -X- _ O
the -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
sequence -X- _ O
is -X- _ O
selected -X- _ O
and -X- _ O
replaced -X- _ O
with -X- _ O
the -X- _ O
special -X- _ O
token -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
. -X- _ O
The -X- _ O
MLM -X- _ B-MethodName
objective -X- _ O
is -X- _ O
a -X- _ O
cross -X- _ B-MetricName
- -X- _ I-MetricName
entropy -X- _ I-MetricName
loss -X- _ I-MetricName
on -X- _ O
predicting -X- _ O
the -X- _ O
masked -X- _ O
tokens -X- _ O
. -X- _ O
BERT -X- _ B-MethodName
uni- -X- _ O
formly -X- _ O
selects -X- _ O
15 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
tokens -X- _ O
for -X- _ O
possi- -X- _ O
ble -X- _ O
replacement -X- _ O
. -X- _ O
Of -X- _ O
the -X- _ O
selected -X- _ O
tokens -X- _ O
, -X- _ O
80 -X- _ O
% -X- _ O
are -X- _ O
replaced -X- _ O
with -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
, -X- _ O
10 -X- _ O
% -X- _ O
are -X- _ O
left -X- _ O
unchanged -X- _ O
, -X- _ O

During -X- _ O
pretraining -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
uses -X- _ O
two -X- _ O
objectives -X- _ O
: -X- _ O
masked -X- _ B-TaskName
language -X- _ I-TaskName
modeling -X- _ I-TaskName
and -X- _ O
next -X- _ B-TaskName
sentence -X- _ I-TaskName
pre- -X- _ I-TaskName
diction -X- _ I-TaskName
. -X- _ O

BERT -X- _ B-MethodName
uses -X- _ O
the -X- _ O
now -X- _ O
ubiquitous -X- _ O
transformer -X- _ O
archi- -X- _ O
tecture -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
will -X- _ O
not -X- _ O
review -X- _ O
in -X- _ O
detail -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
transformer -X- _ O
architecture -X- _ O
with -X- _ O
L -X- _ B-HyperparameterName
layers -X- _ B-HyperparameterName
. -X- _ O
Each -X- _ O
block -X- _ O
uses -X- _ O
A -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
heads -X- _ O
and -X- _ O
hidden -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
H. -X- _ B-HyperparameterName

BERT -X- _ B-MethodName
takes -X- _ O
as -X- _ O
input -X- _ O
a -X- _ O
concatenation -X- _ O
of -X- _ O
two -X- _ O
segments -X- _ O
( -X- _ O
sequences -X- _ O
of -X- _ O
tokens -X- _ O
) -X- _ O
, -X- _ O
x1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
xN -X- _ O
and -X- _ O
y1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
yM. -X- _ O
Segments -X- _ O
usually -X- _ O
consist -X- _ O
of -X- _ O
more -X- _ O
than -X- _ O
one -X- _ O
natural -X- _ O
sentence -X- _ O
. -X- _ O
The -X- _ O
two -X- _ O
seg- -X- _ O
ments -X- _ O
are -X- _ O
presented -X- _ O
as -X- _ O
a -X- _ O
single -X- _ O
input -X- _ O
sequence -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
with -X- _ O
special -X- _ O
tokens -X- _ O
delimiting -X- _ O
them -X- _ O
: -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
, -X- _ O
x1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
xN -X- _ O
, -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
, -X- _ O
y1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
yM -X- _ O
, -X- _ O
[ -X- _ O
EOS -X- _ O
] -X- _ O
. -X- _ O
M -X- _ O
and -X- _ O
N -X- _ O
are -X- _ O
constrained -X- _ O
such -X- _ O
that -X- _ O
M -X- _ O
+ -X- _ O
N -X- _ O
< -X- _ O
T -X- _ O
, -X- _ O
where -X- _ O
T -X- _ O
is -X- _ O
a -X- _ O
parameter -X- _ O
that -X- _ O
controls -X- _ O
the -X- _ O
maximum -X- _ O
sequence -X- _ O
length -X- _ O
during -X- _ O
training -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
is -X- _ O
ﬁrst -X- _ O
pretrained -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
unla- -X- _ O
beled -X- _ O
text -X- _ O
corpus -X- _ O
and -X- _ O
subsequently -X- _ O
ﬁnetuned -X- _ O
us- -X- _ O
ing -X- _ O
end -X- _ O
- -X- _ O
task -X- _ O
labeled -X- _ O
data -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
give -X- _ O
a -X- _ O
brief -X- _ O
overview -X- _ O
of -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
pretraining -X- _ O
approach -X- _ O
and -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
choices -X- _ O
that -X- _ O
we -X- _ O
will -X- _ O
ex- -X- _ O
amine -X- _ O
experimentally -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
section -X- _ O
. -X- _ O

alternatives -X- _ O
that -X- _ O
lead -X- _ O
to -X- _ O
better -X- _ O
downstream -X- _ O
task -X- _ O
performance -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
novel -X- _ O
dataset -X- _ O
, -X- _ O
CC- -X- _ B-DatasetName
NEWS -X- _ I-DatasetName
, -X- _ O
and -X- _ O
conﬁrm -X- _ O
that -X- _ O
using -X- _ O
more -X- _ O
data -X- _ O
for -X- _ O
pre- -X- _ O
training -X- _ O
further -X- _ O
improves -X- _ O
performance -X- _ O
on -X- _ O
down- -X- _ O
stream -X- _ O
tasks -X- _ O
; -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
Our -X- _ O
training -X- _ O
improvements -X- _ O
show -X- _ O
that -X- _ O
masked -X- _ O
language -X- _ O
model -X- _ O
pretraining -X- _ O
, -X- _ O
under -X- _ O
the -X- _ O
right -X- _ O
design -X- _ O
choices -X- _ O
, -X- _ O
is -X- _ O
competitive -X- _ O
with -X- _ O
all -X- _ O
other -X- _ O
recently -X- _ O
published -X- _ O
methods -X- _ O
. -X- _ O
We -X- _ O
release -X- _ O
our -X- _ O
model -X- _ O
, -X- _ O
pretraining -X- _ O
and -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
code -X- _ O
imple- -X- _ O
mented -X- _ O
in -X- _ O
PyTorch -X- _ O
( -X- _ O
Paszke -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O

2It -X- _ O
is -X- _ O
possible -X- _ O
that -X- _ O
these -X- _ O
other -X- _ O
methods -X- _ O
could -X- _ O
also -X- _ O
improve -X- _ O
with -X- _ O
more -X- _ O
tuning -X- _ O
. -X- _ O
We -X- _ O
leave -X- _ O
this -X- _ O
exploration -X- _ O
to -X- _ O
future -X- _ O
work -X- _ O
. -X- _ O

In -X- _ O
summary -X- _ O
, -X- _ O
the -X- _ O
contributions -X- _ O
of -X- _ O
this -X- _ O
paper -X- _ O
are -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
We -X- _ O
present -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
important -X- _ O
BERT -X- _ B-MethodName
de- -X- _ O
sign -X- _ O
choices -X- _ O
and -X- _ O
training -X- _ O
strategies -X- _ O
and -X- _ O
introduce -X- _ O

We -X- _ O
present -X- _ O
a -X- _ O
replication -X- _ O
study -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
pre- -X- _ O
training -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
includes -X- _ O
a -X- _ O
careful -X- _ O
evaluation -X- _ O
of -X- _ O
the -X- _ O
effects -X- _ O
of -X- _ O
hyperparmeter -X- _ O
tuning -X- _ O
and -X- _ O
training -X- _ O
set -X- _ O
size -X- _ O
. -X- _ O
We -X- _ O
ﬁnd -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
was -X- _ O
signiﬁcantly -X- _ O
undertrained -X- _ O
and -X- _ O
propose -X- _ O
an -X- _ O
im- -X- _ O
proved -X- _ O
recipe -X- _ O
for -X- _ O
training -X- _ O
BERT -X- _ B-MethodName
models -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
call -X- _ O
RoBERTa -X- _ B-MethodName
, -X- _ O
that -X- _ O
can -X- _ O
match -X- _ O
or -X- _ O
exceed -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
post -X- _ O
- -X- _ O
BERT -X- _ B-MethodName
methods -X- _ O
. -X- _ O
Our -X- _ O
modiﬁcations -X- _ O
are -X- _ O
simple -X- _ O
, -X- _ O
they -X- _ O
include -X- _ O
: -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
training -X- _ O
the -X- _ O
model -X- _ O
longer -X- _ O
, -X- _ O
with -X- _ O
bigger -X- _ O
batches -X- _ O
, -X- _ O
over -X- _ O
more -X- _ O
data -X- _ O
; -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
removing -X- _ O
the -X- _ O
next -X- _ O
sentence -X- _ O
prediction -X- _ O
objective -X- _ O
; -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
training -X- _ O
on -X- _ O
longer -X- _ O
se- -X- _ O
quences -X- _ O
; -X- _ O
and -X- _ O
( -X- _ O
4 -X- _ O
) -X- _ O
dynamically -X- _ O
changing -X- _ O
the -X- _ O
mask- -X- _ O
ing -X- _ O
pattern -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
collect -X- _ O
a -X- _ O
large -X- _ O
new -X- _ O
dataset -X- _ O
( -X- _ O
CC -X- _ B-DatasetName
- -X- _ I-DatasetName
NEWS -X- _ I-DatasetName
) -X- _ O
of -X- _ O
compa- -X- _ O
rable -X- _ O
size -X- _ O
to -X- _ O
other -X- _ O
privately -X- _ O
used -X- _ O
datasets -X- _ O
, -X- _ O
to -X- _ O
better -X- _ O
control -X- _ O
for -X- _ O
training -X- _ O
set -X- _ O
size -X- _ O
effects -X- _ O
. -X- _ O
When -X- _ O
controlling -X- _ O
for -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
our -X- _ O
im- -X- _ O
proved -X- _ O
training -X- _ O
procedure -X- _ O
improves -X- _ O
upon -X- _ O
the -X- _ O
pub- -X- _ O
lished -X- _ O
BERT -X- _ B-MethodName
results -X- _ O
on -X- _ O
both -X- _ O
GLUE -X- _ B-DatasetName
and -X- _ O
SQuAD -X- _ B-DatasetName
. -X- _ O
When -X- _ O
trained -X- _ O
for -X- _ O
longer -X- _ O
over -X- _ O
additional -X- _ O
data -X- _ O
, -X- _ O
our -X- _ O
model -X- _ O
achieves -X- _ O
a -X- _ O
score -X- _ O
of -X- _ O
88.5 -X- _ B-MetricValue
on -X- _ O
the -X- _ O
public -X- _ O
GLUE -X- _ B-DatasetName
leaderboard -X- _ O
, -X- _ O
matching -X- _ O
the -X- _ O
88.4 -X- _ B-MetricValue
reported -X- _ O
by -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
model -X- _ O
establishes -X- _ O
a -X- _ O
new -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
on -X- _ O
4/9 -X- _ O
of -X- _ O
the -X- _ O
GLUE -X- _ B-TaskName
tasks -X- _ I-TaskName
: -X- _ O
MNLI -X- _ B-TaskName
, -X- _ O
QNLI -X- _ B-TaskName
, -X- _ O
RTE -X- _ B-TaskName
and -X- _ O
STS -X- _ B-TaskName
- -X- _ I-TaskName
B. -X- _ I-TaskName
We -X- _ O
also -X- _ O
match -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
on -X- _ O
SQuAD -X- _ B-DatasetName
and -X- _ O
RACE -X- _ B-DatasetName
. -X- _ O
Overall -X- _ O
, -X- _ O
we -X- _ O
re -X- _ O
- -X- _ O
establish -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
’s -X- _ O
masked -X- _ O
lan- -X- _ O
guage -X- _ O
model -X- _ O
training -X- _ O
objective -X- _ O
is -X- _ O
competitive -X- _ O
with -X- _ O
other -X- _ O
recently -X- _ O
proposed -X- _ O
training -X- _ O
objectives -X- _ O
such -X- _ O
as -X- _ O
perturbed -X- _ O
autoregressive -X- _ O
language -X- _ O
model- -X- _ O
ing -X- _ O
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019).2 -X- _ O

∗Equal -X- _ O
contribution -X- _ O
. -X- _ O
1Our -X- _ O
models -X- _ O
and -X- _ O
code -X- _ O
are -X- _ O
available -X- _ O
at -X- _ O
: -X- _ O

Self -X- _ O
- -X- _ O
training -X- _ O
methods -X- _ O
such -X- _ O
as -X- _ O
ELMo -X- _ B-MethodName
( -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
GPT -X- _ B-MethodName
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
XLM -X- _ B-MethodName
( -X- _ O
Lample -X- _ O
and -X- _ O
Conneau -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
XLNet -X- _ B-MethodName
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
have -X- _ O
brought -X- _ O
signiﬁcant -X- _ O
performance -X- _ O
gains -X- _ O
, -X- _ O
but -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
challenging -X- _ O
to -X- _ O
determine -X- _ O
which -X- _ O
aspects -X- _ O
of -X- _ O
the -X- _ O
methods -X- _ O
contribute -X- _ O
the -X- _ O
most -X- _ O
. -X- _ O
Training -X- _ O
is -X- _ O
computationally -X- _ O
expensive -X- _ O
, -X- _ O
limiting -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
tuning -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
done -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
often -X- _ O
done -X- _ O
with -X- _ O
private -X- _ O
training -X- _ O
data -X- _ O
of -X- _ O
varying -X- _ O
sizes -X- _ O
, -X- _ O
limiting -X- _ O
our -X- _ O
ability -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
effects -X- _ O
of -X- _ O
the -X- _ O
modeling -X- _ O
advances -X- _ O
. -X- _ O

Language -X- _ B-MethodName
model -X- _ I-MethodName
pretraining -X- _ O
has -X- _ O
led -X- _ O
to -X- _ O
sig- -X- _ O
niﬁcant -X- _ O
performance -X- _ O
gains -X- _ O
but -X- _ O
careful -X- _ O
com- -X- _ O
parison -X- _ O
between -X- _ O
different -X- _ O
approaches -X- _ O
is -X- _ O
chal- -X- _ O
lenging -X- _ O
. -X- _ O
Training -X- _ O
is -X- _ O
computationally -X- _ O
expen- -X- _ O
sive -X- _ O
, -X- _ O
often -X- _ O
done -X- _ O
on -X- _ O
private -X- _ O
datasets -X- _ O
of -X- _ O
different -X- _ O
sizes -X- _ O
, -X- _ O
and -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
will -X- _ O
show -X- _ O
, -X- _ O
hyperparameter -X- _ O
choices -X- _ O
have -X- _ O
signiﬁcant -X- _ O
impact -X- _ O
on -X- _ O
the -X- _ O
ﬁnal -X- _ O
re- -X- _ O
sults -X- _ O
. -X- _ O
We -X- _ O
present -X- _ O
a -X- _ O
replication -X- _ O
study -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
pretraining -X- _ O
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
that -X- _ O
carefully -X- _ O
measures -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
many -X- _ O
key -X- _ O
hyperparam- -X- _ O
eters -X- _ O
and -X- _ O
training -X- _ O
data -X- _ O
size -X- _ O
. -X- _ O
We -X- _ O
ﬁnd -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
was -X- _ O
signiﬁcantly -X- _ O
undertrained -X- _ O
, -X- _ O
and -X- _ O
can -X- _ O
match -X- _ O
or -X- _ O
exceed -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
every -X- _ O
model -X- _ O
published -X- _ O
after -X- _ O
it -X- _ O
. -X- _ O
Our -X- _ O
best -X- _ O
model -X- _ O
achieves -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
on -X- _ O
GLUE -X- _ B-DatasetName
, -X- _ O
RACE -X- _ B-DatasetName
and -X- _ O
SQuAD -X- _ B-DatasetName
. -X- _ O
These -X- _ O
results -X- _ O
highlight -X- _ O
the -X- _ O
impor- -X- _ O
tance -X- _ O
of -X- _ O
previously -X- _ O
overlooked -X- _ O
design -X- _ O
choices -X- _ O
, -X- _ O
and -X- _ O
raise -X- _ O
questions -X- _ O
about -X- _ O
the -X- _ O
source -X- _ O
of -X- _ O
re- -X- _ O
cently -X- _ O
reported -X- _ O
improvements -X- _ O
. -X- _ O
We -X- _ O
release -X- _ O
our -X- _ O
models -X- _ O
and -X- _ O
code.1 -X- _ O

§ -X- _ O
Facebook -X- _ O
AI -X- _ O
{ -X- _ O
yinhanliu -X- _ O
, -X- _ O
myleott -X- _ O
, -X- _ O
naman -X- _ O
, -X- _ O
jingfeidu -X- _ O
, -X- _ O
danqi,omerlevy,mikelewis,lsz,ves}@fb.com -X- _ O

† -X- _ O
Paul -X- _ O
G. -X- _ O
Allen -X- _ O
School -X- _ O
of -X- _ O
Computer -X- _ O
Science -X- _ O
& -X- _ O
Engineering -X- _ O
, -X- _ O
University -X- _ O
of -X- _ O
Washington -X- _ O
, -X- _ O
Seattle -X- _ O
, -X- _ O
WA -X- _ O
{ -X- _ O
mandar90,lsz}@cs.washington.edu -X- _ O

Danqi -X- _ O
Chen§ -X- _ O
Omer -X- _ O
Levy§ -X- _ O
Mike -X- _ O
Lewis§ -X- _ O
Luke -X- _ O
Zettlemoyer†§ -X- _ O
Veselin -X- _ O
Stoyanov§ -X- _ O

Yinhan -X- _ O
Liu∗§ -X- _ O
Myle -X- _ O
Ott∗§ -X- _ O
Naman -X- _ O
Goyal∗§ -X- _ O
Jingfei -X- _ O
Du∗§ -X- _ O
Mandar -X- _ O
Joshi† -X- _ O

