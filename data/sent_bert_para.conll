-DOCSTART- -X- O
We -X- _ O
showed -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
out -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
box -X- _ O
maps -X- _ O
sen- -X- _ O
tences -X- _ O
to -X- _ O
a -X- _ O
vector -X- _ O
space -X- _ O
that -X- _ O
is -X- _ O
rather -X- _ O
unsuit- -X- _ O
able -X- _ O
to -X- _ O
be -X- _ O
used -X- _ O
with -X- _ O
common -X- _ O
similarity -X- _ O
measures -X- _ O
like -X- _ O
cosine -X- _ B-MetricName
- -X- _ I-MetricName
similarity -X- _ I-MetricName
. -X- _ O
The -X- _ O
performance -X- _ O
for -X- _ O
seven -X- _ O
STS -X- _ B-TaskName
tasks -X- _ O
was -X- _ O
below -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
average -X- _ O
GloVe -X- _ B-MethodName
embeddings -X- _ I-MethodName
. -X- _ O
To -X- _ O
overcome -X- _ O
this -X- _ O
shortcoming -X- _ O
, -X- _ O
we -X- _ O
presented -X- _ O
Sentence -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
( -X- _ O
SBERT -X- _ B-MethodName
) -X- _ O
. -X- _ O
SBERT -X- _ B-MethodName
ﬁne -X- _ O
- -X- _ O
tunes -X- _ O
BERT -X- _ B-MethodName
in -X- _ O
a -X- _ O
siamese -X- _ O
/ -X- _ O
triplet -X- _ O
network -X- _ O
architec- -X- _ O
ture -X- _ O
. -X- _ O
We -X- _ O
evaluated -X- _ O
the -X- _ O
quality -X- _ O
on -X- _ O
various -X- _ O
com- -X- _ O
mon -X- _ O
benchmarks -X- _ O
, -X- _ O
where -X- _ O
it -X- _ O
could -X- _ O
achieve -X- _ O
a -X- _ O
sig- -X- _ O
niﬁcant -X- _ O
improvement -X- _ O
over -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
sen- -X- _ O
tence -X- _ O
embeddings -X- _ O
methods -X- _ O
. -X- _ O
Replacing -X- _ O
BERT -X- _ B-MethodName
with -X- _ O
RoBERTa -X- _ B-MethodName
did -X- _ O
not -X- _ O
yield -X- _ O
a -X- _ O
signiﬁcant -X- _ O
improvement -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O
SBERT -X- _ B-MethodName
is -X- _ O
computationally -X- _ O
efﬁcient -X- _ O
. -X- _ O
On -X- _ O
a -X- _ O
GPU -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
about -X- _ O
9 -X- _ B-MetricValue
% -X- _ I-MetricValue
faster -X- _ O
than -X- _ O
InferSent -X- _ B-MethodName
and -X- _ O
about -X- _ O
55 -X- _ B-MetricValue
% -X- _ I-MetricValue
faster -X- _ O
than -X- _ O
Universal -X- _ B-MethodName
Sentence -X- _ I-MethodName
Encoder -X- _ I-MethodName
. -X- _ O
SBERT -X- _ B-MethodName
can -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
tasks -X- _ O
which -X- _ O
are -X- _ O
computationally -X- _ O
not -X- _ O
feasible -X- _ O
to -X- _ O
be -X- _ O
modeled -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
For -X- _ O
exam- -X- _ O
ple -X- _ O
, -X- _ O
clustering -X- _ O
of -X- _ O
10,000 -X- _ O
sentences -X- _ O
with -X- _ O
hierarchi- -X- _ O
cal -X- _ O
clustering -X- _ O
requires -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
about -X- _ O
65 -X- _ O
hours -X- _ O
, -X- _ O
as -X- _ O
around -X- _ O
50 -X- _ O
Million -X- _ O
sentence -X- _ O
combinations -X- _ O
must -X- _ O
be -X- _ O
computed -X- _ O
. -X- _ O
With -X- _ O
SBERT -X- _ B-MethodName
, -X- _ O
we -X- _ O
were -X- _ O
able -X- _ O
to -X- _ O
re- -X- _ O
duce -X- _ O
the -X- _ O
effort -X- _ O
to -X- _ O
about -X- _ O
5 -X- _ O
seconds -X- _ O
. -X- _ O

On -X- _ O
CPU -X- _ O
, -X- _ O
InferSent -X- _ B-MethodName
is -X- _ O
about -X- _ O
65 -X- _ O
% -X- _ O
faster -X- _ O
than -X- _ O
SBERT -X- _ B-MethodName
. -X- _ O
This -X- _ O
is -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
much -X- _ O
simpler -X- _ O
net- -X- _ O
work -X- _ O
architecture -X- _ O
. -X- _ O
InferSent -X- _ B-MethodName
uses -X- _ O
a -X- _ O
single -X- _ O
Bi- -X- _ O
LSTM -X- _ O
layer -X- _ O
, -X- _ O
while -X- _ O
BERT -X- _ B-MethodName
uses -X- _ O
12 -X- _ B-HyperparameterValue
stacked -X- _ O
trans- -X- _ O
former -X- _ O
layers -X- _ B-HyperparameterName
. -X- _ O
However -X- _ O
, -X- _ O
an -X- _ O
advantage -X- _ O
of -X- _ O
trans- -X- _ O
former -X- _ O
networks -X- _ O
is -X- _ O
the -X- _ O
computational -X- _ O
efﬁciency -X- _ O
on -X- _ O
GPUs -X- _ O
. -X- _ O
There -X- _ O
, -X- _ O
SBERT -X- _ B-MethodName
with -X- _ O
smart -X- _ O
batching -X- _ O
is -X- _ O
about -X- _ O
9 -X- _ B-MetricValue
% -X- _ I-MetricValue
faster -X- _ O
than -X- _ O
InferSent -X- _ B-MethodName
and -X- _ O
about -X- _ O
55 -X- _ B-MetricValue
% -X- _ I-MetricValue
faster -X- _ O
than -X- _ O
Universal -X- _ B-MethodName
Sentence -X- _ I-MethodName
Encoder -X- _ I-MethodName
. -X- _ O
Smart -X- _ O
batching -X- _ O
achieves -X- _ O
a -X- _ O
speed -X- _ O
- -X- _ O
up -X- _ O
of -X- _ O
89 -X- _ O
% -X- _ O
on -X- _ O
CPU -X- _ O
and -X- _ O
48 -X- _ O
% -X- _ O
on -X- _ O
GPU -X- _ O
. -X- _ O
Average -X- _ O
GloVe -X- _ B-MethodName
embeddings -X- _ I-MethodName
is -X- _ O
obvi- -X- _ O
ously -X- _ O
by -X- _ O
a -X- _ O
large -X- _ O
margin -X- _ O
the -X- _ O
fastest -X- _ O
method -X- _ O
to -X- _ O
com- -X- _ O
pute -X- _ O
sentence -X- _ O
embeddings -X- _ O
. -X- _ O

Sentence -X- _ O
embeddings -X- _ O
need -X- _ O
potentially -X- _ O
be -X- _ O
com- -X- _ O
puted -X- _ O
for -X- _ O
Millions -X- _ O
of -X- _ O
sentences -X- _ O
, -X- _ O
hence -X- _ O
, -X- _ O
a -X- _ O
high -X- _ O
computation -X- _ O
speed -X- _ O
is -X- _ O
desired -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
SBERT -X- _ B-MethodName
to -X- _ O
average -X- _ O
GloVe -X- _ B-MethodName
embeddings -X- _ I-MethodName
, -X- _ O
InferSent -X- _ B-MethodName
( -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
Universal -X- _ B-MethodName
Sentence -X- _ I-MethodName
Encoder -X- _ I-MethodName
( -X- _ O
Cer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
our -X- _ O
comparison -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
sentences -X- _ O
from -X- _ O
the -X- _ O
STS -X- _ B-DatasetName
benchmark -X- _ I-DatasetName
( -X- _ O
Cer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
com- -X- _ O
pute -X- _ O
average -X- _ O
GloVe -X- _ B-MethodName
embeddings -X- _ I-MethodName
using -X- _ O
a -X- _ O
sim- -X- _ O
ple -X- _ O
for -X- _ O
- -X- _ O
loop -X- _ O
with -X- _ O
python -X- _ O
dictionary -X- _ O
lookups -X- _ O
and -X- _ O
NumPy -X- _ O
. -X- _ O
InferSent4 -X- _ B-MethodName
is -X- _ O
based -X- _ O
on -X- _ O
PyTorch -X- _ O
. -X- _ O
For -X- _ O
Universal -X- _ B-MethodName
Sentence -X- _ I-MethodName
Encoder -X- _ I-MethodName
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
Tensor- -X- _ O
Flow -X- _ O
Hub -X- _ O
version5 -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
Tensor- -X- _ O
Flow -X- _ O
. -X- _ O
SBERT -X- _ B-MethodName
is -X- _ O
based -X- _ O
on -X- _ O
PyTorch -X- _ O
. -X- _ O
For -X- _ O
improved -X- _ O
computation -X- _ O
of -X- _ O
sentence -X- _ O
embeddings -X- _ O
, -X- _ O
we -X- _ O
imple- -X- _ O
mented -X- _ O
a -X- _ O
smart -X- _ O
batching -X- _ O
strategy -X- _ O
: -X- _ O
Sentences -X- _ O
with -X- _ O
similar -X- _ O
lengths -X- _ O
are -X- _ O
grouped -X- _ O
together -X- _ O
and -X- _ O
are -X- _ O
only -X- _ O
padded -X- _ O
to -X- _ O
the -X- _ O
longest -X- _ O
element -X- _ O
in -X- _ O
a -X- _ O
mini -X- _ O
- -X- _ O
batch -X- _ O
. -X- _ O
This -X- _ O
drastically -X- _ O
reduces -X- _ O
computational -X- _ O
overhead -X- _ O
from -X- _ O
padding -X- _ O
tokens -X- _ O
. -X- _ O
Performances -X- _ O
were -X- _ O
measured -X- _ O
on -X- _ O
a -X- _ O
server -X- _ O
with -X- _ O
Intel -X- _ O
i7 -X- _ O
- -X- _ O
5820 -X- _ O
K -X- _ O
CPU -X- _ O
@ -X- _ O
3.30GHz -X- _ O
, -X- _ O
Nvidia -X- _ O
Tesla -X- _ O

et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
Universal -X- _ B-MethodName
Sentence -X- _ I-MethodName
Encoder -X- _ I-MethodName
( -X- _ O
Cer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
both -X- _ O
use -X- _ O
( -X- _ O
u -X- _ O
, -X- _ O
v -X- _ O
, -X- _ O
|u -X- _ O
− -X- _ O
v| -X- _ O
, -X- _ O
u -X- _ O
∗ -X- _ O
v -X- _ O
) -X- _ O
as -X- _ O
input -X- _ O
for -X- _ O
a -X- _ O
softmax -X- _ O
classiﬁer -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
in -X- _ O
our -X- _ O
architec- -X- _ O
ture -X- _ O
, -X- _ O
adding -X- _ O
the -X- _ O
element -X- _ O
- -X- _ O
wise -X- _ O
u -X- _ O
∗ -X- _ O
v -X- _ O
decreased -X- _ O
the -X- _ O
performance -X- _ O
. -X- _ O
The -X- _ O
most -X- _ O
important -X- _ O
component -X- _ O
is -X- _ O
the -X- _ O
element- -X- _ O
wise -X- _ O
difference -X- _ O
|u -X- _ O
− -X- _ O
v| -X- _ O
. -X- _ O
Note -X- _ O
, -X- _ O
that -X- _ O
the -X- _ O
concate- -X- _ O
nation -X- _ O
mode -X- _ O
is -X- _ O
only -X- _ O
relevant -X- _ O
for -X- _ O
training -X- _ O
the -X- _ O
soft- -X- _ O
max -X- _ O
classiﬁer -X- _ O
. -X- _ O
At -X- _ O
inference -X- _ O
, -X- _ O
when -X- _ O
predicting -X- _ O
sim- -X- _ O
ilarities -X- _ O
for -X- _ O
the -X- _ O
STS -X- _ B-DatasetName
benchmark -X- _ I-DatasetName
dataset -X- _ I-DatasetName
, -X- _ O
only -X- _ O
the -X- _ O
sentence -X- _ O
embeddings -X- _ O
u -X- _ O
and -X- _ O
v -X- _ O
are -X- _ O
used -X- _ O
in -X- _ O
combi- -X- _ O
nation -X- _ O
with -X- _ O
cosine -X- _ B-MetricName
- -X- _ I-MetricName
similarity -X- _ I-MetricName
. -X- _ O
The -X- _ O
element -X- _ O
- -X- _ O
wise -X- _ O
difference -X- _ O
measures -X- _ O
the -X- _ O
distance -X- _ O
between -X- _ O
the -X- _ O
di- -X- _ O
mensions -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
sentence -X- _ O
embeddings -X- _ O
, -X- _ O
ensur- -X- _ O
ing -X- _ O
that -X- _ O
similar -X- _ O
pairs -X- _ O
are -X- _ O
closer -X- _ O
and -X- _ O
dissimilar -X- _ O
pairs -X- _ O
are -X- _ O
further -X- _ O
apart -X- _ O
. -X- _ O
When -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
regression -X- _ O
objective -X- _ O
function -X- _ O
, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
pooling -X- _ O
strategy -X- _ O
has -X- _ O
a -X- _ O
large -X- _ O
impact -X- _ O
. -X- _ O
There -X- _ O
, -X- _ O
the -X- _ O
MAX -X- _ O
strategy -X- _ O
perform -X- _ O
signiﬁcantly -X- _ O
worse -X- _ O
than -X- _ O
MEAN -X- _ O
or -X- _ O
CLS -X- _ O
- -X- _ O
token -X- _ O
strat- -X- _ O
egy -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
in -X- _ O
contrast -X- _ O
to -X- _ O
( -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
who -X- _ O
found -X- _ O
it -X- _ O
beneﬁcial -X- _ O
for -X- _ O
the -X- _ O
BiLSTM -X- _ O
- -X- _ O
layer -X- _ O
of -X- _ O
InferSent -X- _ B-MethodName
to -X- _ O
use -X- _ O
MAX -X- _ O
instead -X- _ O
of -X- _ O
MEAN -X- _ O
pooling -X- _ O
. -X- _ O

When -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
classiﬁcation -X- _ O
objective -X- _ O
function -X- _ O
on -X- _ O
NLI -X- _ B-DatasetName
data -X- _ O
, -X- _ O
the -X- _ O
pooling -X- _ O
strategy -X- _ O
has -X- _ O
a -X- _ O
rather -X- _ O
minor -X- _ O
impact -X- _ O
. -X- _ O
The -X- _ O
impact -X- _ O
of -X- _ O
the -X- _ O
concate- -X- _ O
nation -X- _ O
mode -X- _ O
is -X- _ O
much -X- _ O
larger -X- _ O
. -X- _ O
InferSent -X- _ B-MethodName
( -X- _ O
Conneau -X- _ O

this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
an -X- _ O
ablation -X- _ O
study -X- _ O
of -X- _ O
dif- -X- _ O
ferent -X- _ O
aspects -X- _ O
of -X- _ O
SBERT -X- _ B-MethodName
in -X- _ O
order -X- _ O
to -X- _ O
get -X- _ O
a -X- _ O
better -X- _ O
understanding -X- _ O
of -X- _ O
their -X- _ O
relative -X- _ O
importance -X- _ O
. -X- _ O
We -X- _ O
evaluated -X- _ O
different -X- _ O
pooling -X- _ O
strategies -X- _ O
( -X- _ O
MEAN -X- _ O
, -X- _ O
MAX -X- _ O
, -X- _ O
and -X- _ O
CLS -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
classiﬁcation -X- _ O
objective -X- _ O
function -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
different -X- _ O
concate- -X- _ O
nation -X- _ O
methods -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
possible -X- _ O
conﬁguration -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
SBERT -X- _ B-MethodName
with -X- _ O
10 -X- _ O
different -X- _ O
random -X- _ O
seeds -X- _ O
and -X- _ O
average -X- _ O
the -X- _ O
performances -X- _ O
. -X- _ O
The -X- _ O
objective -X- _ O
function -X- _ O
( -X- _ O
classiﬁcation -X- _ O
vs. -X- _ O
regres- -X- _ O
sion -X- _ O
) -X- _ O
depends -X- _ O
on -X- _ O
the -X- _ O
annotated -X- _ O
dataset -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
classiﬁcation -X- _ O
objective -X- _ O
function -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
SBERT- -X- _ B-MethodName
base -X- _ O
on -X- _ O
the -X- _ O
SNLI -X- _ B-DatasetName
and -X- _ O
the -X- _ O
Multi -X- _ B-DatasetName
- -X- _ I-DatasetName
NLI -X- _ I-DatasetName
dataset -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
regression -X- _ O
objective -X- _ O
function -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
on -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
of -X- _ O
the -X- _ O
STS -X- _ B-DatasetName
benchmark -X- _ I-DatasetName
dataset -X- _ I-DatasetName
. -X- _ O
Perfor- -X- _ O
mances -X- _ O
are -X- _ O
measured -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
split -X- _ O
of -X- _ O
the -X- _ O
STS -X- _ B-DatasetName
benchmark -X- _ I-DatasetName
dataset -X- _ I-DatasetName
. -X- _ O
Results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
. -X- _ O

We -X- _ O
have -X- _ O
demonstrated -X- _ O
strong -X- _ O
empirical -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
SBERT -X- _ B-MethodName
sentence -X- _ O
embeddings -X- _ O
. -X- _ O
In -X- _ O

It -X- _ O
appears -X- _ O
that -X- _ O
the -X- _ O
sentence -X- _ O
embeddings -X- _ O
from -X- _ O
SBERT -X- _ B-MethodName
capture -X- _ O
well -X- _ O
sentiment -X- _ O
information -X- _ O
: -X- _ O
We -X- _ O
observe -X- _ O
large -X- _ O
improvements -X- _ O
for -X- _ O
all -X- _ O
sentiment -X- _ O
tasks -X- _ O
( -X- _ O
MR -X- _ B-DatasetName
, -X- _ O
CR -X- _ B-DatasetName
, -X- _ O
and -X- _ O
SST -X- _ B-DatasetName
) -X- _ O
from -X- _ O
SentEval -X- _ O
in -X- _ O
comparison -X- _ O
to -X- _ O
InferSent -X- _ B-MethodName
and -X- _ O
Universal -X- _ B-MethodName
Sentence -X- _ I-MethodName
Encoder -X- _ I-MethodName
. -X- _ O
The -X- _ O
only -X- _ O
dataset -X- _ O
where -X- _ O
SBERT -X- _ B-MethodName
is -X- _ O
signiﬁcantly -X- _ O
worse -X- _ O
than -X- _ O
Universal -X- _ B-MethodName
Sentence -X- _ I-MethodName
Encoder -X- _ I-MethodName
is -X- _ O
the -X- _ O
TREC -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
Universal -X- _ B-MethodName
Sentence -X- _ I-MethodName
Encoder -X- _ I-MethodName
was -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
on -X- _ O
question -X- _ B-TaskName
- -X- _ I-TaskName
answering -X- _ I-TaskName
data -X- _ O
, -X- _ O
which -X- _ O
ap- -X- _ O
pears -X- _ O
to -X- _ O
be -X- _ O
beneﬁcial -X- _ O
for -X- _ O
the -X- _ O
question -X- _ O
- -X- _ O
type -X- _ O
classi- -X- _ B-TaskName
ﬁcation -X- _ I-TaskName
task -X- _ O
of -X- _ O
the -X- _ O
TREC -X- _ B-DatasetName
dataset -X- _ O
. -X- _ O
Average -X- _ O
BERT -X- _ B-MethodName
embeddings -X- _ O
or -X- _ O
using -X- _ O
the -X- _ O
CLS- -X- _ O
token -X- _ O
output -X- _ O
from -X- _ O
a -X- _ O
BERT -X- _ B-MethodName
network -X- _ O
achieved -X- _ O
bad -X- _ O
results -X- _ O
for -X- _ O
various -X- _ O
STS -X- _ B-TaskName
tasks -X- _ O
( -X- _ O
Table -X- _ O
1 -X- _ O
) -X- _ O
, -X- _ O
worse -X- _ O
than -X- _ O
average -X- _ O
GloVe -X- _ O
embeddings -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
for -X- _ O
Sent- -X- _ B-MethodName
Eval -X- _ I-MethodName
, -X- _ O
average -X- _ O
BERT -X- _ B-MethodName
embeddings -X- _ O
and -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
CLS -X- _ O
- -X- _ O
token -X- _ O
output -X- _ O
achieves -X- _ O
decent -X- _ O
results -X- _ O
( -X- _ O
Ta- -X- _ O
ble -X- _ O
5 -X- _ O
) -X- _ O
, -X- _ O
outperforming -X- _ O
average -X- _ O
GloVe -X- _ O
embeddings -X- _ O
. -X- _ O
The -X- _ O
reason -X- _ O
for -X- _ O
this -X- _ O
are -X- _ O
the -X- _ O
different -X- _ O
setups -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
STS -X- _ B-TaskName
tasks -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
cosine -X- _ B-MetricName
- -X- _ I-MetricName
similarity -X- _ I-MetricName
to -X- _ O
es- -X- _ O
timate -X- _ O
the -X- _ O
similarities -X- _ O
between -X- _ O
sentence -X- _ O
embed- -X- _ O
dings -X- _ O
. -X- _ O
Cosine -X- _ B-MetricName
- -X- _ I-MetricName
similarity -X- _ I-MetricName
treats -X- _ O
all -X- _ O
dimensions -X- _ O
equally -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
SentEval -X- _ O
ﬁts -X- _ O
a -X- _ O
logistic -X- _ O
regres- -X- _ O
sion -X- _ O
classiﬁer -X- _ O
to -X- _ O
the -X- _ O
sentence -X- _ O
embeddings -X- _ O
. -X- _ O
This -X- _ O
allows -X- _ O
that -X- _ O
certain -X- _ O
dimensions -X- _ O
can -X- _ O
have -X- _ O
higher -X- _ O
or -X- _ O
lower -X- _ O
impact -X- _ O
on -X- _ O
the -X- _ O
classiﬁcation -X- _ O
result -X- _ O
. -X- _ O
We -X- _ O
conclude -X- _ O
that -X- _ O
average -X- _ O
BERT -X- _ B-MethodName
embeddings -X- _ O
/ -X- _ O
CLS -X- _ O
- -X- _ O
token -X- _ O
output -X- _ O
from -X- _ O
BERT -X- _ B-MethodName
return -X- _ O
sentence -X- _ O
em- -X- _ O
beddings -X- _ O
that -X- _ O
are -X- _ O
infeasible -X- _ O
to -X- _ O
be -X- _ O
used -X- _ O
with -X- _ O
cosine- -X- _ B-MetricName
similarity -X- _ I-MetricName
or -X- _ O
with -X- _ O
Manhatten -X- _ B-MetricName
/ -X- _ I-MetricName
Euclidean -X- _ I-MetricName
distance -X- _ I-MetricName
. -X- _ O
For -X- _ O
transfer -X- _ O
learning -X- _ O
, -X- _ O
they -X- _ O
yield -X- _ O
slightly -X- _ O
worse -X- _ O
results -X- _ O
than -X- _ O
InferSent -X- _ B-MethodName
or -X- _ O
Universal -X- _ B-MethodName
Sentence -X- _ I-MethodName
En- -X- _ I-MethodName
coder -X- _ I-MethodName
. -X- _ O
However -X- _ O
, -X- _ O
using -X- _ O
the -X- _ O
described -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
setup -X- _ O
with -X- _ O
a -X- _ O
siamese -X- _ O
network -X- _ O
structure -X- _ O
on -X- _ O
NLI -X- _ B-DatasetName
datasets -X- _ O
yields -X- _ O
sentence -X- _ O
embeddings -X- _ O
that -X- _ O
achieve -X- _ O
a -X- _ O
new -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
for -X- _ O
the -X- _ O
SentEval -X- _ O
toolkit -X- _ O
. -X- _ O

The -X- _ O
results -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
. -X- _ O
SBERT -X- _ B-MethodName
is -X- _ O
able -X- _ O
to -X- _ O
achieve -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
in -X- _ O
5 -X- _ O
out -X- _ O
of -X- _ O
7 -X- _ O
tasks -X- _ O
. -X- _ O
The -X- _ O
average -X- _ O
performance -X- _ O
increases -X- _ O
by -X- _ O
about -X- _ O
2 -X- _ O
percentage -X- _ O
points -X- _ O
compared -X- _ O
to -X- _ O
In- -X- _ B-MethodName
ferSent -X- _ I-MethodName
as -X- _ O
well -X- _ O
as -X- _ O
the -X- _ O
Universal -X- _ B-MethodName
Sentence -X- _ I-MethodName
Encoder -X- _ I-MethodName
. -X- _ O
Even -X- _ O
though -X- _ O
transfer -X- _ O
learning -X- _ O
is -X- _ O
not -X- _ O
the -X- _ O
purpose -X- _ O
of -X- _ O
SBERT -X- _ B-MethodName
, -X- _ O
it -X- _ O
outperforms -X- _ O
other -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
sen- -X- _ O
tence -X- _ O
embeddings -X- _ O
methods -X- _ O
on -X- _ O
this -X- _ O
task -X- _ O
. -X- _ O

• -X- _ O
MRPC -X- _ B-DatasetName
: -X- _ O
Microsoft -X- _ B-DatasetName
Research -X- _ I-DatasetName
Paraphrase -X- _ I-DatasetName
Cor- -X- _ I-DatasetName
pus -X- _ I-DatasetName
from -X- _ O
parallel -X- _ O
news -X- _ O
sources -X- _ O
( -X- _ O
Dolan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
. -X- _ O

• -X- _ O
TREC -X- _ B-DatasetName
: -X- _ O
Fine -X- _ O
grained -X- _ O
question -X- _ O
- -X- _ O
type -X- _ O
classiﬁ- -X- _ O
cation -X- _ O
from -X- _ O
TREC -X- _ O
( -X- _ O
Li -X- _ O
and -X- _ O
Roth -X- _ O
, -X- _ O
2002 -X- _ O
) -X- _ O
. -X- _ O

• -X- _ O
SST -X- _ B-DatasetName
: -X- _ O
Stanford -X- _ B-DatasetName
Sentiment -X- _ I-DatasetName
Treebank -X- _ I-DatasetName
with -X- _ O
bi- -X- _ O
nary -X- _ O
labels -X- _ O
( -X- _ O
Socher -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O

• -X- _ O
MPQA -X- _ B-DatasetName
: -X- _ O
Phrase -X- _ O
level -X- _ O
opinion -X- _ B-TaskName
polarity -X- _ I-TaskName
classi- -X- _ I-TaskName
ﬁcation -X- _ I-TaskName
from -X- _ O
newswire -X- _ O
( -X- _ O
Wiebe -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
. -X- _ O

• -X- _ O
SUBJ -X- _ B-DatasetName
: -X- _ O
Subjectivity -X- _ B-TaskName
prediction -X- _ I-TaskName
of -X- _ O
sentences -X- _ O
from -X- _ O
movie -X- _ O
reviews -X- _ O
and -X- _ O
plot -X- _ O
summaries -X- _ O
( -X- _ O
Pang -X- _ O
and -X- _ O
Lee -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
. -X- _ O

• -X- _ O
CR -X- _ B-DatasetName
: -X- _ O
Sentiment -X- _ B-TaskName
prediction -X- _ I-TaskName
of -X- _ O
customer -X- _ O
prod- -X- _ O
uct -X- _ O
reviews -X- _ O
( -X- _ O
Hu -X- _ O
and -X- _ O
Liu -X- _ O
, -X- _ O
2004 -X- _ O
) -X- _ O
. -X- _ O

• -X- _ O
MR -X- _ B-DatasetName
: -X- _ O
Sentiment -X- _ B-TaskName
prediction -X- _ I-TaskName
for -X- _ O
movie -X- _ O
reviews -X- _ O
snippets -X- _ O
on -X- _ O
a -X- _ O
ﬁve -X- _ O
start -X- _ O
scale -X- _ O
( -X- _ O
Pang -X- _ O
and -X- _ O
Lee -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
. -X- _ O

The -X- _ O
purpose -X- _ O
of -X- _ O
SBERT -X- _ B-MethodName
sentence -X- _ O
embeddings -X- _ O
are -X- _ O
not -X- _ O
to -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
transfer -X- _ O
learning -X- _ O
for -X- _ O
other -X- _ O
tasks -X- _ O
. -X- _ O
Here -X- _ O
, -X- _ O
we -X- _ O
think -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
BERT -X- _ B-MethodName
as -X- _ O
de- -X- _ O
scribed -X- _ O
by -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
for -X- _ O
new -X- _ O
tasks -X- _ O
is -X- _ O
the -X- _ O
more -X- _ O
suitable -X- _ O
method -X- _ O
, -X- _ O
as -X- _ O
it -X- _ O
updates -X- _ O
all -X- _ O
layers -X- _ O
of -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
network -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
SentEval -X- _ O
can -X- _ O
still -X- _ O
give -X- _ O
an -X- _ O
impression -X- _ O
on -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
our -X- _ O
sentence -X- _ O
embeddings -X- _ O
for -X- _ O
various -X- _ O
tasks -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
the -X- _ O
SBERT -X- _ B-MethodName
sentence -X- _ O
embeddings -X- _ O
to -X- _ O
other -X- _ O
sentence -X- _ O
embeddings -X- _ O
methods -X- _ O
on -X- _ O
the -X- _ O
fol- -X- _ O
lowing -X- _ O
seven -X- _ O
SentEval -X- _ O
transfer -X- _ O
tasks -X- _ O
: -X- _ O

SentEval -X- _ O
( -X- _ O
Conneau -X- _ O
and -X- _ O
Kiela -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
popular -X- _ O
toolkit -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
sentence -X- _ O
embed- -X- _ O
dings -X- _ O
. -X- _ O
Sentence -X- _ O
embeddings -X- _ O
are -X- _ O
used -X- _ O
as -X- _ O
features -X- _ O
for -X- _ O
a -X- _ O
logistic -X- _ O
regression -X- _ O
classiﬁer -X- _ O
. -X- _ O
The -X- _ O
logistic -X- _ O
re- -X- _ O
gression -X- _ O
classiﬁer -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
various -X- _ O
tasks -X- _ O
in -X- _ O
a -X- _ O
10 -X- _ O
- -X- _ O
fold -X- _ O
cross -X- _ O
- -X- _ O
validation -X- _ O
setup -X- _ O
and -X- _ O
the -X- _ O
prediction -X- _ O
accuracy -X- _ O
is -X- _ O
computed -X- _ O
for -X- _ O
the -X- _ O
test -X- _ O
- -X- _ O
fold -X- _ O
. -X- _ O

tences -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
section -X- _ O
are -X- _ O
thematically -X- _ O
closer -X- _ O
than -X- _ O
sentences -X- _ O
in -X- _ O
different -X- _ O
sections -X- _ O
. -X- _ O
They -X- _ O
use -X- _ O
this -X- _ O
to -X- _ O
create -X- _ O
a -X- _ O
large -X- _ O
dataset -X- _ O
of -X- _ O
weakly -X- _ O
labeled -X- _ O
sen- -X- _ O
tence -X- _ O
triplets -X- _ O
: -X- _ O
The -X- _ O
anchor -X- _ O
and -X- _ O
the -X- _ O
positive -X- _ O
exam- -X- _ O
ple -X- _ O
come -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
section -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
neg- -X- _ O
ative -X- _ O
example -X- _ O
comes -X- _ O
from -X- _ O
a -X- _ O
different -X- _ O
section -X- _ O
of -X- _ O
the -X- _ O
same -X- _ O
article -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
from -X- _ O
the -X- _ O
Alice -X- _ O
Arnold -X- _ O
article -X- _ O
: -X- _ O
Anchor -X- _ O
: -X- _ O
Arnold -X- _ O
joined -X- _ O
the -X- _ O
BBC -X- _ O
Radio -X- _ O
Drama -X- _ O
Company -X- _ O
in -X- _ O
1988 -X- _ O
. -X- _ O
, -X- _ O
positive -X- _ O
: -X- _ O
Arnold -X- _ O
gained -X- _ O
media -X- _ O
attention -X- _ O
in -X- _ O
May -X- _ O
2012 -X- _ O
. -X- _ O
, -X- _ O
negative -X- _ O
: -X- _ O
Balding -X- _ O
and -X- _ O
Arnold -X- _ O
are -X- _ O
keen -X- _ O
amateur -X- _ O
golfers -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
dataset -X- _ O
from -X- _ O
Dor -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
Triplet -X- _ B-MetricName
Objective -X- _ I-MetricName
, -X- _ O
train -X- _ O
SBERT -X- _ B-MethodName
for -X- _ O
one -X- _ O
epoch -X- _ O
on -X- _ O
the -X- _ O
about -X- _ O
1.8 -X- _ O
Million -X- _ O
training -X- _ O
triplets -X- _ O
and -X- _ O
evaluate -X- _ O
it -X- _ O
on -X- _ O
the -X- _ O
222,957 -X- _ O
test -X- _ O
triplets -X- _ O
. -X- _ O
Test -X- _ O
triplets -X- _ O
are -X- _ O
from -X- _ O
a -X- _ O
distinct -X- _ O
set -X- _ O
of -X- _ O
Wikipedia -X- _ B-DatasetName
articles -X- _ I-DatasetName
. -X- _ O
As -X- _ O
evaluation -X- _ O
metric -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
accuracy -X- _ B-MetricName
: -X- _ O
Is -X- _ O
the -X- _ O
positive -X- _ O
example -X- _ O
closer -X- _ O
to -X- _ O
the -X- _ O
anchor -X- _ O
than -X- _ O
the -X- _ O
negative -X- _ O
example -X- _ O
? -X- _ O
Results -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O
Dor -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
ﬁne- -X- _ O
tuned -X- _ O
a -X- _ O
BiLSTM -X- _ O
architecture -X- _ O
with -X- _ O
triplet -X- _ B-MetricName
loss -X- _ I-MetricName
to -X- _ O
derive -X- _ O
sentence -X- _ O
embeddings -X- _ O
for -X- _ O
this -X- _ O
dataset -X- _ O
. -X- _ O
As -X- _ O
the -X- _ O
table -X- _ O
shows -X- _ O
, -X- _ O
SBERT -X- _ B-MethodName
clearly -X- _ O
outperforms -X- _ O
the -X- _ O
BiLSTM -X- _ O
approach -X- _ O
by -X- _ O
Dor -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O

Table -X- _ O
3 -X- _ O
: -X- _ O
Average -X- _ O
Pearson -X- _ O
correlation -X- _ O
r -X- _ O
and -X- _ O
average -X- _ O
Spearman -X- _ O
’s -X- _ O
rank -X- _ O
correlation -X- _ O
ρ -X- _ O
on -X- _ O
the -X- _ O
Argument -X- _ O
Facet -X- _ O
Similarity -X- _ O
( -X- _ O
AFS -X- _ O
) -X- _ O
corpus -X- _ O
( -X- _ O
Misra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
Misra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
proposes -X- _ O
10 -X- _ O
- -X- _ O
fold -X- _ O
cross -X- _ O
- -X- _ O
validation -X- _ O
. -X- _ O
We -X- _ O
additionally -X- _ O
evaluate -X- _ O
in -X- _ O
a -X- _ O
cross -X- _ O
- -X- _ O
topic -X- _ O
scenario -X- _ O
: -X- _ O
Methods -X- _ O
are -X- _ O
trained -X- _ O
on -X- _ O
two -X- _ O
topics -X- _ O
, -X- _ O
and -X- _ O
are -X- _ O
evaluated -X- _ O
on -X- _ O
the -X- _ O
third -X- _ O
topic -X- _ O
. -X- _ O

10 -X- _ O
- -X- _ O
fold -X- _ O
Cross -X- _ O
- -X- _ O
Validation -X- _ O
SVR -X- _ O
( -X- _ O
Misra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
63.33 -X- _ O
- -X- _ O

Dor -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
use -X- _ O
Wikipedia -X- _ O
to -X- _ O
create -X- _ O
a -X- _ O
the- -X- _ O
matically -X- _ O
ﬁne -X- _ O
- -X- _ O
grained -X- _ O
train -X- _ O
, -X- _ O
dev -X- _ O
and -X- _ O
test -X- _ O
set -X- _ O
for -X- _ O
sentence -X- _ O
embeddings -X- _ O
methods -X- _ O
. -X- _ O
Wikipedia -X- _ B-DatasetName
arti- -X- _ I-DatasetName
cles -X- _ I-DatasetName
are -X- _ O
separated -X- _ O
into -X- _ O
distinct -X- _ O
sections -X- _ O
focusing -X- _ O
on -X- _ O
certain -X- _ O
aspects -X- _ O
. -X- _ O
Dor -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
assume -X- _ O
that -X- _ O
sen- -X- _ O

descriptive -X- _ O
, -X- _ O
while -X- _ O
AFS -X- _ B-DatasetName
data -X- _ O
are -X- _ O
argumentative -X- _ O
ex- -X- _ O
cerpts -X- _ O
from -X- _ O
dialogs -X- _ O
. -X- _ O
To -X- _ O
be -X- _ O
considered -X- _ O
similar -X- _ O
, -X- _ O
ar- -X- _ O
guments -X- _ O
must -X- _ O
not -X- _ O
only -X- _ O
make -X- _ O
similar -X- _ O
claims -X- _ O
, -X- _ O
but -X- _ O
also -X- _ O
provide -X- _ O
a -X- _ O
similar -X- _ O
reasoning -X- _ O
. -X- _ O
Further -X- _ O
, -X- _ O
the -X- _ O
lex- -X- _ O
ical -X- _ O
gap -X- _ O
between -X- _ O
the -X- _ O
sentences -X- _ O
in -X- _ O
AFS -X- _ B-DatasetName
is -X- _ O
much -X- _ O
larger -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
simple -X- _ O
unsupervised -X- _ O
methods -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
STS -X- _ B-TaskName
systems -X- _ O
perform -X- _ O
badly -X- _ O
on -X- _ O
this -X- _ O
dataset -X- _ O
( -X- _ O
Reimers -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
evaluate -X- _ O
SBERT -X- _ B-MethodName
on -X- _ O
this -X- _ O
dataset -X- _ O
in -X- _ O
two -X- _ O
sce- -X- _ O
narios -X- _ O
: -X- _ O
1 -X- _ O
) -X- _ O
As -X- _ O
proposed -X- _ O
by -X- _ O
Misra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
SBERT -X- _ B-MethodName
using -X- _ O
10 -X- _ O
- -X- _ O
fold -X- _ O
cross -X- _ O
- -X- _ O
validation -X- _ O
. -X- _ O
A -X- _ O
draw- -X- _ O
back -X- _ O
of -X- _ O
this -X- _ O
evaluation -X- _ O
setup -X- _ O
is -X- _ O
that -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
clear -X- _ O
how -X- _ O
well -X- _ O
approaches -X- _ O
generalize -X- _ O
to -X- _ O
different -X- _ O
top- -X- _ O
ics -X- _ O
. -X- _ O
Hence -X- _ O
, -X- _ O
2 -X- _ O
) -X- _ O
we -X- _ O
evaluate -X- _ O
SBERT -X- _ B-MethodName
in -X- _ O
a -X- _ O
cross -X- _ O
- -X- _ O
topic -X- _ O
setup -X- _ O
. -X- _ O
Two -X- _ O
topics -X- _ O
serve -X- _ O
for -X- _ O
training -X- _ O
and -X- _ O
the -X- _ O
ap- -X- _ O
proach -X- _ O
is -X- _ O
evaluated -X- _ O
on -X- _ O
the -X- _ O
left -X- _ O
- -X- _ O
out -X- _ O
topic -X- _ O
. -X- _ O
We -X- _ O
repeat -X- _ O
this -X- _ O
for -X- _ O
all -X- _ O
three -X- _ O
topics -X- _ O
and -X- _ O
average -X- _ O
the -X- _ O
results -X- _ O
. -X- _ O
SBERT -X- _ B-DatasetName
is -X- _ O
ﬁne -X- _ O
- -X- _ O
tuned -X- _ O
using -X- _ O
the -X- _ O
Regression -X- _ O
Ob- -X- _ O
jective -X- _ O
Function -X- _ O
. -X- _ O
The -X- _ O
similarity -X- _ O
score -X- _ O
is -X- _ O
computed -X- _ O
using -X- _ O
cosine -X- _ B-MetricName
- -X- _ I-MetricName
similarity -X- _ I-MetricName
based -X- _ O
on -X- _ O
the -X- _ O
sentence -X- _ O
em- -X- _ O
beddings -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
provide -X- _ O
the -X- _ O
Pearson -X- _ B-MetricName
correla- -X- _ I-MetricName
tion -X- _ I-MetricName
r -X- _ I-MetricName
to -X- _ O
make -X- _ O
the -X- _ O
results -X- _ O
comparable -X- _ O
to -X- _ O
Misra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
showed -X- _ O
( -X- _ O
Reimers -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
that -X- _ O
Pearson -X- _ B-MetricName
correlation -X- _ I-MetricName
has -X- _ O
some -X- _ O
serious -X- _ O
draw- -X- _ O
backs -X- _ O
and -X- _ O
should -X- _ O
be -X- _ O
avoided -X- _ O
for -X- _ O
comparing -X- _ O
STS -X- _ O
systems -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
depicted -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
. -X- _ O
Unsupervised -X- _ O
methods -X- _ O
like -X- _ O
tf -X- _ B-MethodName
- -X- _ I-MethodName
idf -X- _ I-MethodName
, -X- _ O
average -X- _ O
GloVe -X- _ B-MethodName
embeddings -X- _ O
or -X- _ O
InferSent -X- _ B-MethodName
perform -X- _ O
rather -X- _ O
badly -X- _ O
on -X- _ O
this -X- _ O
dataset -X- _ O
with -X- _ O
low -X- _ O
scores -X- _ O
. -X- _ O
Training -X- _ O
SBERT -X- _ B-MethodName
in -X- _ O
the -X- _ O
10 -X- _ O
- -X- _ O
fold -X- _ O
cross -X- _ O
- -X- _ O
validation -X- _ O
setup -X- _ O
gives -X- _ O
a -X- _ O
performance -X- _ O
that -X- _ O
is -X- _ O
nearly -X- _ O
on -X- _ O
- -X- _ O
par -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
However -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
topic -X- _ O
evaluation -X- _ O
, -X- _ O
we -X- _ O
ob- -X- _ O
serve -X- _ O
a -X- _ O
performance -X- _ O
drop -X- _ O
of -X- _ O
SBERT -X- _ B-MethodName
by -X- _ O
about -X- _ O
7 -X- _ B-MetricValue
points -X- _ O
Spearman -X- _ B-MetricName
correlation -X- _ I-MetricName
. -X- _ O
To -X- _ O
be -X- _ O
considered -X- _ O
similar -X- _ O
, -X- _ O
arguments -X- _ O
should -X- _ O
address -X- _ O
the -X- _ O
same -X- _ O
claims -X- _ O
and -X- _ O
provide -X- _ O
the -X- _ O
same -X- _ O
reasoning -X- _ O
. -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
able -X- _ O
to -X- _ O
use -X- _ O
attention -X- _ O
to -X- _ O
compare -X- _ O
directly -X- _ O
both -X- _ O
sentences -X- _ O
( -X- _ O
e.g. -X- _ O
word -X- _ O
- -X- _ O
by -X- _ O
- -X- _ O
word -X- _ O
comparison -X- _ O
) -X- _ O
, -X- _ O
while -X- _ O
SBERT -X- _ B-MethodName
must -X- _ O
map -X- _ O
individual -X- _ O
sentences -X- _ O
from -X- _ O
an -X- _ O
unseen -X- _ O
topic -X- _ O
to -X- _ O
a -X- _ O
vector -X- _ O
space -X- _ O
such -X- _ O
that -X- _ O
arguments -X- _ O
with -X- _ O
similar -X- _ O
claims -X- _ O
and -X- _ O
reasons -X- _ O
are -X- _ O
close -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
a -X- _ O
much -X- _ O
more -X- _ O
challenging -X- _ O
task -X- _ O
, -X- _ O
which -X- _ O
appears -X- _ O
to -X- _ O
re- -X- _ O
quire -X- _ O
more -X- _ O
than -X- _ O
just -X- _ O
two -X- _ O
topics -X- _ O
for -X- _ O
training -X- _ O
to -X- _ O
work -X- _ O
on -X- _ O
- -X- _ O
par -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
. -X- _ O

We -X- _ O
evaluate -X- _ O
SBERT -X- _ B-MethodName
on -X- _ O
the -X- _ O
Argument -X- _ B-DatasetName
Facet -X- _ I-DatasetName
Sim- -X- _ I-DatasetName
ilarity -X- _ I-DatasetName
( -X- _ O
AFS -X- _ B-DatasetName
) -X- _ O
corpus -X- _ O
by -X- _ O
Misra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
AFS -X- _ B-DatasetName
corpus -X- _ O
annotated -X- _ O
6,000 -X- _ O
sentential -X- _ O
argument -X- _ O
pairs -X- _ O
from -X- _ O
social -X- _ O
media -X- _ O
dialogs -X- _ O
on -X- _ O
three -X- _ O
contro- -X- _ O
versial -X- _ O
topics -X- _ O
: -X- _ O
gun -X- _ O
control -X- _ O
, -X- _ O
gay -X- _ O
marriage -X- _ O
, -X- _ O
and -X- _ O
death -X- _ O
penalty -X- _ O
. -X- _ O
The -X- _ O
data -X- _ O
was -X- _ O
annotated -X- _ O
on -X- _ O
a -X- _ O
scale -X- _ O
from -X- _ O
0 -X- _ O
( -X- _ O
“ -X- _ O
different -X- _ O
topic -X- _ O
” -X- _ O
) -X- _ O
to -X- _ O
5 -X- _ O
( -X- _ O
“ -X- _ O
completely -X- _ O
equiv- -X- _ O
alent -X- _ O
” -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
similarity -X- _ O
notion -X- _ O
in -X- _ O
the -X- _ O
AFS -X- _ B-DatasetName
corpus -X- _ O
is -X- _ O
fairly -X- _ O
different -X- _ O
to -X- _ O
the -X- _ O
similarity -X- _ O
notion -X- _ O
in -X- _ O
the -X- _ O
STS -X- _ B-DatasetName
datasets -X- _ O
from -X- _ O
SemEval -X- _ O
. -X- _ O
STS -X- _ B-DatasetName
data -X- _ O
is -X- _ O
usually -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
to -X- _ O
ﬁne -X- _ O
- -X- _ O
tune -X- _ O
SBERT -X- _ B-MethodName
us- -X- _ O
ing -X- _ O
the -X- _ O
regression -X- _ O
objective -X- _ O
function -X- _ O
. -X- _ O
At -X- _ O
predic- -X- _ O
tion -X- _ O
time -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
cosine -X- _ B-MetricName
- -X- _ I-MetricName
similarity -X- _ I-MetricName
be- -X- _ O
tween -X- _ O
the -X- _ O
sentence -X- _ O
embeddings -X- _ O
. -X- _ O
All -X- _ O
systems -X- _ O
are -X- _ O
trained -X- _ O
with -X- _ O
10 -X- _ O
random -X- _ O
seeds -X- _ O
to -X- _ O
counter -X- _ O
variances -X- _ O
( -X- _ O
Reimers -X- _ O
and -X- _ O
Gurevych -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
depicted -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
We -X- _ O
ex- -X- _ O
perimented -X- _ O
with -X- _ O
two -X- _ O
setups -X- _ O
: -X- _ O
Only -X- _ O
training -X- _ O
on -X- _ O
STSb -X- _ B-DatasetName
, -X- _ O
and -X- _ O
ﬁrst -X- _ O
training -X- _ O
on -X- _ O
NLI -X- _ B-DatasetName
, -X- _ O
then -X- _ O
training -X- _ O
on -X- _ O
STSb -X- _ B-DatasetName
. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
the -X- _ O
later -X- _ O
strategy -X- _ O
leads -X- _ O
to -X- _ O
a -X- _ O
slight -X- _ O
improvement -X- _ O
of -X- _ O
1 -X- _ B-MetricValue
- -X- _ O
2 -X- _ B-MetricValue
points -X- _ B-MetricName
. -X- _ O
This -X- _ O
two -X- _ O
- -X- _ O
step -X- _ O
approach -X- _ O
had -X- _ O
an -X- _ O
especially -X- _ O
large -X- _ O
impact -X- _ O
for -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
cross -X- _ O
- -X- _ O
encoder -X- _ O
, -X- _ O
which -X- _ O
improved -X- _ O
the -X- _ O
perfor- -X- _ O
mance -X- _ O
by -X- _ O
3 -X- _ B-MetricValue
- -X- _ O
4 -X- _ B-MetricValue
points -X- _ B-MetricName
. -X- _ O
We -X- _ O
do -X- _ O
not -X- _ O
observe -X- _ O
a -X- _ O
signiﬁ- -X- _ O
ca -X- _ O
nt -X- _ O
difference -X- _ O
between -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
RoBERTa -X- _ B-MethodName
. -X- _ O

The -X- _ O
STS -X- _ B-DatasetName
benchmark -X- _ O
( -X- _ O
STSb -X- _ O
) -X- _ O
( -X- _ O
Cer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
pro- -X- _ O
vides -X- _ O
is -X- _ O
a -X- _ O
popular -X- _ O
dataset -X- _ O
to -X- _ O
evaluate -X- _ O
supervised -X- _ O
STS -X- _ O
systems -X- _ O
. -X- _ O
The -X- _ O
data -X- _ O
includes -X- _ O
8,628 -X- _ O
sentence -X- _ O
pairs -X- _ O
from -X- _ O
the -X- _ O
three -X- _ O
categories -X- _ O
captions -X- _ O
, -X- _ O
news -X- _ O
, -X- _ O
and -X- _ O
forums -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
divided -X- _ O
into -X- _ O
train -X- _ O
( -X- _ O
5,749 -X- _ O
) -X- _ O
, -X- _ O
dev -X- _ O
( -X- _ O
1,500 -X- _ O
) -X- _ O
and -X- _ O
test -X- _ O
( -X- _ O
1,379 -X- _ O
) -X- _ O
. -X- _ O
BERT -X- _ B-MethodName
set -X- _ O
a -X- _ O
new -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
on -X- _ O
this -X- _ O
dataset -X- _ O
by -X- _ O
passing -X- _ O
both -X- _ O
sen- -X- _ O
tences -X- _ O
to -X- _ O
the -X- _ O
network -X- _ O
and -X- _ O
using -X- _ O
a -X- _ O
simple -X- _ O
regres- -X- _ O

STS -X- _ O
. -X- _ O
Instead -X- _ O
, -X- _ O
we -X- _ O
compute -X- _ O
the -X- _ O
Spearman -X- _ B-MetricName
’s -X- _ I-MetricName
rank -X- _ I-MetricName
correlation -X- _ I-MetricName
between -X- _ O
the -X- _ O
cosine -X- _ B-MetricName
- -X- _ I-MetricName
similarity -X- _ I-MetricName
of -X- _ O
the -X- _ O
sentence -X- _ O
embeddings -X- _ O
and -X- _ O
the -X- _ O
gold -X- _ O
labels -X- _ O
. -X- _ O
The -X- _ O
setup -X- _ O
for -X- _ O
the -X- _ O
other -X- _ O
sentence -X- _ O
embedding -X- _ O
methods -X- _ O
is -X- _ O
equivalent -X- _ O
, -X- _ O
the -X- _ O
similarity -X- _ O
is -X- _ O
computed -X- _ O
by -X- _ O
cosine- -X- _ B-MetricName
similarity -X- _ I-MetricName
. -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
depicted -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
shows -X- _ O
that -X- _ O
directly -X- _ O
using -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
leads -X- _ O
to -X- _ O
rather -X- _ O
poor -X- _ O
performances -X- _ O
. -X- _ O
Av- -X- _ O
eraging -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
embeddings -X- _ O
achieves -X- _ O
an -X- _ O
aver- -X- _ B-MetricName
age -X- _ I-MetricName
correlation -X- _ I-MetricName
of -X- _ O
only -X- _ O
54.81 -X- _ B-MetricValue
, -X- _ O
and -X- _ O
using -X- _ O
the -X- _ O
CLS- -X- _ O
token -X- _ O
output -X- _ O
only -X- _ O
achieves -X- _ O
an -X- _ O
average -X- _ B-MetricName
correlation -X- _ I-MetricName
of -X- _ O
29.19 -X- _ B-MetricValue
. -X- _ O
Both -X- _ O
are -X- _ O
worse -X- _ O
than -X- _ O
computing -X- _ O
average -X- _ O
GloVe -X- _ B-MethodName
embeddings -X- _ O
. -X- _ O
Using -X- _ O
the -X- _ O
described -X- _ O
siamese -X- _ O
network -X- _ O
structure -X- _ O
and -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
mechanism -X- _ O
substantially -X- _ O
improves -X- _ O
the -X- _ O
correlation -X- _ O
, -X- _ O
outperforming -X- _ O
both -X- _ O
InferSent -X- _ B-MethodName
and -X- _ O
Universal -X- _ B-MethodName
Sentence -X- _ I-MethodName
Encoder -X- _ I-MethodName
substantially -X- _ O
. -X- _ O
The -X- _ O
only -X- _ O
dataset -X- _ O
where -X- _ O
SBERT -X- _ B-MethodName
performs -X- _ O
worse -X- _ O
than -X- _ O
Universal -X- _ B-MethodName
Sentence -X- _ I-MethodName
Encoder -X- _ I-MethodName
is -X- _ O
SICK -X- _ B-DatasetName
- -X- _ I-DatasetName
R. -X- _ I-DatasetName
Universal -X- _ B-MethodName
Sentence -X- _ I-MethodName
Encoder -X- _ I-MethodName
was -X- _ O
trained -X- _ O
on -X- _ O
various -X- _ O
datasets -X- _ O
, -X- _ O
including -X- _ O
news -X- _ B-DatasetName
, -X- _ O
question -X- _ B-DatasetName
- -X- _ I-DatasetName
answer -X- _ I-DatasetName
pages -X- _ I-DatasetName
and -X- _ O
dis- -X- _ O
cussion -X- _ B-DatasetName
forums -X- _ I-DatasetName
, -X- _ O
which -X- _ O
appears -X- _ O
to -X- _ O
be -X- _ O
more -X- _ O
suitable -X- _ O
to -X- _ O
the -X- _ O
data -X- _ O
of -X- _ O
SICK -X- _ B-DatasetName
- -X- _ I-DatasetName
R. -X- _ I-DatasetName
In -X- _ O
contrast -X- _ O
, -X- _ O
SBERT -X- _ B-MethodName
was -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
only -X- _ O
on -X- _ O
Wikipedia -X- _ B-DatasetName
( -X- _ O
via -X- _ O
BERT -X- _ B-MethodName
) -X- _ O
and -X- _ O
on -X- _ O
NLI -X- _ B-DatasetName
data -X- _ I-DatasetName
. -X- _ O
While -X- _ O
RoBERTa -X- _ B-MethodName
was -X- _ O
able -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
per- -X- _ O
formance -X- _ O
for -X- _ O
several -X- _ O
supervised -X- _ O
tasks -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
observe -X- _ O
minor -X- _ O
difference -X- _ O
between -X- _ O
SBERT -X- _ B-MethodName
and -X- _ O
SRoBERTa -X- _ B-MethodName
for -X- _ O
generating -X- _ O
sentence -X- _ O
embeddings -X- _ O
. -X- _ O

We -X- _ O
evaluate -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
SBERT -X- _ B-MethodName
for -X- _ O
STS -X- _ B-TaskName
without -X- _ O
using -X- _ O
any -X- _ O
STS -X- _ O
speciﬁc -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
STS -X- _ O
tasks -X- _ O
2012 -X- _ O
- -X- _ O
2016 -X- _ O
( -X- _ O
Agirre -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2012 -X- _ O
, -X- _ O
2013 -X- _ O
, -X- _ O
2014 -X- _ O
, -X- _ O
2015 -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
STS -X- _ O
benchmark -X- _ O
( -X- _ O
Cer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
SICK -X- _ B-DatasetName
- -X- _ I-DatasetName
Relatedness -X- _ I-DatasetName
dataset -X- _ O
( -X- _ O
Marelli -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
datasets -X- _ O
provide -X- _ O
la- -X- _ O
bels -X- _ O
between -X- _ O
0 -X- _ O
and -X- _ O
5 -X- _ O
on -X- _ O
the -X- _ O
semantic -X- _ O
relatedness -X- _ O
of -X- _ O
sentence -X- _ O
pairs -X- _ O
. -X- _ O
We -X- _ O
showed -X- _ O
in -X- _ O
( -X- _ O
Reimers -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
that -X- _ O
Pearson -X- _ B-MetricName
correlation -X- _ I-MetricName
is -X- _ O
badly -X- _ O
suited -X- _ O
for -X- _ O

We -X- _ O
evaluate -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
SBERT -X- _ B-MethodName
for -X- _ O
com- -X- _ O
mon -X- _ O
Semantic -X- _ B-TaskName
Textual -X- _ I-TaskName
Similarity -X- _ I-TaskName
( -X- _ O
STS -X- _ B-TaskName
) -X- _ O
tasks -X- _ O
. -X- _ O
State -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
methods -X- _ O
often -X- _ O
learn -X- _ O
a -X- _ O
( -X- _ O
complex -X- _ O
) -X- _ O
regression -X- _ O
function -X- _ O
that -X- _ O
maps -X- _ O
sentence -X- _ O
embed- -X- _ O
dings -X- _ O
to -X- _ O
a -X- _ O
similarity -X- _ O
score -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
these -X- _ O
regres- -X- _ O
sion -X- _ O
functions -X- _ O
work -X- _ O
pair -X- _ O
- -X- _ O
wise -X- _ O
and -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
com- -X- _ O
binatorial -X- _ O
explosion -X- _ O
those -X- _ O
are -X- _ O
often -X- _ O
not -X- _ O
scalable -X- _ O
if -X- _ O
the -X- _ O
collection -X- _ O
of -X- _ O
sentences -X- _ O
reaches -X- _ O
a -X- _ O
certain -X- _ O
size -X- _ O
. -X- _ O
Instead -X- _ O
, -X- _ O
we -X- _ O
always -X- _ O
use -X- _ O
cosine -X- _ B-MetricName
- -X- _ I-MetricName
similarity -X- _ I-MetricName
to -X- _ O
com- -X- _ O
pare -X- _ O
the -X- _ O
similarity -X- _ O
between -X- _ O
two -X- _ O
sentence -X- _ O
embed- -X- _ O
dings -X- _ O
. -X- _ O
We -X- _ O
ran -X- _ O
our -X- _ O
experiments -X- _ O
also -X- _ O
with -X- _ O
nega- -X- _ B-MetricName
tive -X- _ I-MetricName
Manhatten -X- _ I-MetricName
and -X- _ O
negative -X- _ B-MetricName
Euclidean -X- _ I-MetricName
distances -X- _ O
as -X- _ O
similarity -X- _ O
measures -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
results -X- _ O
for -X- _ O
all -X- _ O
ap- -X- _ O
proaches -X- _ O
remained -X- _ O
roughly -X- _ O
the -X- _ O
same -X- _ O
. -X- _ O

( -X- _ O
Williams -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
dataset -X- _ O
. -X- _ O
The -X- _ O
SNLI -X- _ B-DatasetName
is -X- _ O
a -X- _ O
col- -X- _ O
lection -X- _ O
of -X- _ O
570,000 -X- _ O
sentence -X- _ O
pairs -X- _ O
annotated -X- _ O
with -X- _ O
the -X- _ O
labels -X- _ O
contradiction -X- _ O
, -X- _ O
eintailment -X- _ O
, -X- _ O
and -X- _ O
neu- -X- _ O
tral -X- _ O
. -X- _ O
MultiNLI -X- _ B-DatasetName
contains -X- _ O
430,000 -X- _ O
sentence -X- _ O
pairs -X- _ O
and -X- _ O
covers -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
genres -X- _ O
of -X- _ O
spoken -X- _ O
and -X- _ O
written -X- _ O
text -X- _ O
. -X- _ O
We -X- _ O
ﬁne -X- _ O
- -X- _ O
tune -X- _ O
SBERT -X- _ B-MethodName
with -X- _ O
a -X- _ O
3 -X- _ O
- -X- _ O
way -X- _ O
softmax- -X- _ O
classiﬁer -X- _ O
objective -X- _ O
function -X- _ O
for -X- _ O
one -X- _ O
epoch -X- _ O
. -X- _ O
We -X- _ O
used -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
16 -X- _ B-HyperparameterValue
, -X- _ O
Adam -X- _ B-HyperparameterValue
optimizer -X- _ B-HyperparameterName
with -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
2e−5 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
a -X- _ O
linear -X- _ O
learning -X- _ O
rate -X- _ O
warm -X- _ O
- -X- _ O
up -X- _ O
over -X- _ O
10 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
Our -X- _ O
de- -X- _ O
fault -X- _ O
pooling -X- _ O
strategy -X- _ O
is -X- _ O
MEAN -X- _ O
. -X- _ O

We -X- _ O
train -X- _ O
SBERT -X- _ B-MethodName
on -X- _ O
the -X- _ O
combination -X- _ O
of -X- _ O
the -X- _ O
SNLI -X- _ B-DatasetName
( -X- _ O
Bowman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
Multi -X- _ B-DatasetName
- -X- _ I-DatasetName
Genre -X- _ I-DatasetName
NLI -X- _ I-DatasetName

with -X- _ O
sx -X- _ O
the -X- _ O
sentence -X- _ O
embedding -X- _ O
for -X- _ O
a -X- _ O
/ -X- _ O
n -X- _ O
/ -X- _ O
p -X- _ O
, -X- _ O
|| -X- _ O
· -X- _ O
|| -X- _ O
a -X- _ O
distance -X- _ O
metric -X- _ O
and -X- _ O
margin -X- _ O
ϵ. -X- _ O
Margin -X- _ O
ϵ -X- _ O
ensures -X- _ O
that -X- _ O
sp -X- _ O
is -X- _ O
at -X- _ O
least -X- _ O
ϵ -X- _ O
closer -X- _ O
to -X- _ O
sa -X- _ O
than -X- _ O
sn -X- _ O
. -X- _ O
As -X- _ O
metric -X- _ O
we -X- _ O
use -X- _ O
Euclidean -X- _ O
distance -X- _ O
and -X- _ O
we -X- _ O
set -X- _ O
ϵ -X- _ O
= -X- _ O
1 -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
. -X- _ O

where -X- _ O
n -X- _ O
is -X- _ O
the -X- _ O
dimension -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
em- -X- _ O
beddings -X- _ O
and -X- _ O
k -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
labels -X- _ O
. -X- _ O
We -X- _ O
optimize -X- _ O
cross -X- _ B-MetricName
- -X- _ I-MetricName
entropy -X- _ I-MetricName
loss -X- _ I-MetricName
. -X- _ O
This -X- _ O
structure -X- _ O
is -X- _ O
depicted -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O
Regression -X- _ O
Objective -X- _ O
Function -X- _ O
. -X- _ O
The -X- _ O
cosine- -X- _ B-MetricName
similarity -X- _ I-MetricName
between -X- _ O
the -X- _ O
two -X- _ O
sentence -X- _ O
embeddings -X- _ O
u -X- _ O
and -X- _ O
v -X- _ O
is -X- _ O
computed -X- _ O
( -X- _ O
Figure -X- _ O
2 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
mean- -X- _ B-MetricName
squared -X- _ I-MetricName
- -X- _ I-MetricName
error -X- _ I-MetricName
loss -X- _ O
as -X- _ O
the -X- _ O
objective -X- _ O
function -X- _ O
. -X- _ O
Triplet -X- _ O
Objective -X- _ O
Function -X- _ O
. -X- _ O
Given -X- _ O
an -X- _ O
anchor -X- _ O
sentence -X- _ O
a -X- _ O
, -X- _ O
a -X- _ O
positive -X- _ O
sentence -X- _ O
p -X- _ O
, -X- _ O
and -X- _ O
a -X- _ O
negative -X- _ O
sentence -X- _ O
n -X- _ O
, -X- _ O
triplet -X- _ B-MetricName
loss -X- _ I-MetricName
tunes -X- _ O
the -X- _ O
network -X- _ O
such -X- _ O
that -X- _ O
the -X- _ O
distance -X- _ O
between -X- _ O
a -X- _ O
and -X- _ O
p -X- _ O
is -X- _ O
smaller -X- _ O
than -X- _ O
the -X- _ O
distance -X- _ O
between -X- _ O
a -X- _ O
and -X- _ O
n. -X- _ O
Mathematically -X- _ O
, -X- _ O
we -X- _ O
minimize -X- _ O
the -X- _ O
following -X- _ O
loss -X- _ O
function -X- _ O
: -X- _ O

training -X- _ O
data -X- _ O
. -X- _ O
We -X- _ O
experiment -X- _ O
with -X- _ O
the -X- _ O
following -X- _ O
structures -X- _ O
and -X- _ O
objective -X- _ O
functions -X- _ O
. -X- _ O
Classiﬁcation -X- _ O
Objective -X- _ O
Function -X- _ O
. -X- _ O
We -X- _ O
con- -X- _ O
catenate -X- _ O
the -X- _ O
sentence -X- _ O
embeddings -X- _ O
u -X- _ O
and -X- _ O
v -X- _ O
with -X- _ O
the -X- _ O
element -X- _ O
- -X- _ O
wise -X- _ O
difference -X- _ O
|u−v| -X- _ O
and -X- _ O
multiply -X- _ O
it -X- _ O
with -X- _ O
the -X- _ O
trainable -X- _ O
weight -X- _ O
Wt -X- _ O
∈ -X- _ O
R3n×k -X- _ O
: -X- _ O

SBERT -X- _ B-MethodName
adds -X- _ O
a -X- _ O
pooling -X- _ O
operation -X- _ O
to -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
/ -X- _ O
RoBERTa -X- _ B-MethodName
to -X- _ O
derive -X- _ O
a -X- _ O
ﬁxed -X- _ O
sized -X- _ O
sen- -X- _ O
tence -X- _ O
embedding -X- _ O
. -X- _ O
We -X- _ O
experiment -X- _ O
with -X- _ O
three -X- _ O
pool- -X- _ O
ing -X- _ O
strategies -X- _ O
: -X- _ O
Using -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
CLS -X- _ O
- -X- _ O
token -X- _ O
, -X- _ O
computing -X- _ O
the -X- _ O
mean -X- _ O
of -X- _ O
all -X- _ O
output -X- _ O
vectors -X- _ O
( -X- _ O
MEAN- -X- _ O
strategy -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
computing -X- _ O
a -X- _ O
max -X- _ O
- -X- _ O
over -X- _ O
- -X- _ O
time -X- _ O
of -X- _ O
the -X- _ O
output -X- _ O
vectors -X- _ O
( -X- _ O
MAX -X- _ O
- -X- _ O
strategy -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
default -X- _ O
conﬁg- -X- _ O
uration -X- _ O
is -X- _ O
MEAN -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
ﬁne -X- _ O
- -X- _ O
tune -X- _ O
BERT -X- _ B-MethodName
/ -X- _ O
RoBERTa -X- _ B-MethodName
, -X- _ O
we -X- _ O
cre- -X- _ O
ate -X- _ O
siamese -X- _ O
and -X- _ O
triplet -X- _ O
networks -X- _ O
( -X- _ O
Schroff -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
to -X- _ O
update -X- _ O
the -X- _ O
weights -X- _ O
such -X- _ O
that -X- _ O
the -X- _ O
produced -X- _ O
sentence -X- _ O
embeddings -X- _ O
are -X- _ O
semantically -X- _ O
meaningful -X- _ O
and -X- _ O
can -X- _ O
be -X- _ O
compared -X- _ O
with -X- _ O
cosine -X- _ B-MetricName
- -X- _ I-MetricName
similarity -X- _ I-MetricName
. -X- _ O
The -X- _ O
network -X- _ O
structure -X- _ O
depends -X- _ O
on -X- _ O
the -X- _ O
available -X- _ O

computed -X- _ O
candidate -X- _ O
embeddings -X- _ O
using -X- _ O
attention -X- _ O
. -X- _ O
This -X- _ O
idea -X- _ O
works -X- _ O
for -X- _ O
ﬁnding -X- _ O
the -X- _ O
highest -X- _ O
scoring -X- _ O
sentence -X- _ O
in -X- _ O
a -X- _ O
larger -X- _ O
collection -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
poly- -X- _ O
encoders -X- _ O
have -X- _ O
the -X- _ O
drawback -X- _ O
that -X- _ O
the -X- _ O
score -X- _ O
function -X- _ O
is -X- _ O
not -X- _ O
symmetric -X- _ O
and -X- _ O
the -X- _ O
computational -X- _ O
overhead -X- _ O
is -X- _ O
too -X- _ O
large -X- _ O
for -X- _ O
use -X- _ O
- -X- _ O
cases -X- _ O
like -X- _ O
clustering -X- _ B-TaskName
, -X- _ O
which -X- _ O
would -X- _ O
require -X- _ O
O(n2 -X- _ O
) -X- _ O
score -X- _ O
computations -X- _ O
. -X- _ O
Previous -X- _ O
neural -X- _ O
sentence -X- _ O
embedding -X- _ O
methods -X- _ O
started -X- _ O
the -X- _ O
training -X- _ O
from -X- _ O
a -X- _ O
random -X- _ O
initialization -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
publication -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
RoBERTa -X- _ B-MethodName
network -X- _ O
and -X- _ O
only -X- _ O
ﬁne -X- _ O
- -X- _ O
tune -X- _ O
it -X- _ O
to -X- _ O
yield -X- _ O
useful -X- _ O
sentence -X- _ O
embeddings -X- _ O
. -X- _ O
This -X- _ O
reduces -X- _ O
signiﬁcantly -X- _ O
the -X- _ O
needed -X- _ O
training -X- _ O
time -X- _ O
: -X- _ O
SBERT -X- _ B-MethodName
can -X- _ O
be -X- _ O
tuned -X- _ O
in -X- _ O
less -X- _ O
than -X- _ O
20 -X- _ O
minutes -X- _ O
, -X- _ O
while -X- _ O
yielding -X- _ O
better -X- _ O
results -X- _ O
than -X- _ O
comparable -X- _ O
sentence -X- _ O
embed- -X- _ O
ding -X- _ O
methods -X- _ O
. -X- _ O

Humeau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
addresses -X- _ O
the -X- _ O
run -X- _ O
- -X- _ O
time -X- _ O
overhead -X- _ O
of -X- _ O
the -X- _ O
cross -X- _ O
- -X- _ O
encoder -X- _ O
from -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
present -X- _ O
a -X- _ O
method -X- _ O
( -X- _ O
poly -X- _ O
- -X- _ O
encoders -X- _ O
) -X- _ O
to -X- _ O
compute -X- _ O
a -X- _ O
score -X- _ O
between -X- _ O
m -X- _ O
context -X- _ O
vectors -X- _ O
and -X- _ O
pre- -X- _ O

new -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
Semantic -X- _ B-TaskName
Textual -X- _ I-TaskName
Semilarity -X- _ I-TaskName
( -X- _ O
STS -X- _ B-TaskName
) -X- _ B-TaskName
benchmark -X- _ I-TaskName
( -X- _ I-TaskName
Cer -X- _ I-TaskName
et -X- _ I-TaskName
al -X- _ I-TaskName
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
RoBERTa -X- _ B-MethodName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
showed -X- _ O
, -X- _ O
that -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
can -X- _ O
further -X- _ O
improved -X- _ O
by -X- _ O
small -X- _ O
adaptations -X- _ O
to -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
process -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
tested -X- _ O
XLNet -X- _ B-MethodName
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
it -X- _ O
led -X- _ O
in -X- _ O
general -X- _ O
to -X- _ O
worse -X- _ O
results -X- _ O
than -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
A -X- _ O
large -X- _ O
disadvantage -X- _ O
of -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
network -X- _ O
structure -X- _ O
is -X- _ O
that -X- _ O
no -X- _ O
independent -X- _ O
sentence -X- _ O
embed- -X- _ O
dings -X- _ O
are -X- _ O
computed -X- _ O
, -X- _ O
which -X- _ O
makes -X- _ O
it -X- _ O
difﬁcult -X- _ O
to -X- _ O
de- -X- _ O
rive -X- _ O
sentence -X- _ O
embeddings -X- _ O
from -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
To -X- _ O
bypass -X- _ O
this -X- _ O
limitations -X- _ O
, -X- _ O
researchers -X- _ O
passed -X- _ O
single -X- _ O
sen- -X- _ O
tences -X- _ O
through -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
then -X- _ O
derive -X- _ O
a -X- _ O
ﬁxed -X- _ O
sized -X- _ O
vector -X- _ O
by -X- _ O
either -X- _ O
averaging -X- _ O
the -X- _ O
outputs -X- _ O
( -X- _ O
similar -X- _ O
to -X- _ O
average -X- _ O
word -X- _ O
embeddings -X- _ O
) -X- _ O
or -X- _ O
by -X- _ O
using -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
special -X- _ O
CLS -X- _ O
token -X- _ O
( -X- _ O
for -X- _ O
example -X- _ O
: -X- _ O
May -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
; -X- _ O
Qiao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
two -X- _ O
options -X- _ O
are -X- _ O
also -X- _ O
provided -X- _ O
by -X- _ O
the -X- _ O
popu- -X- _ O
lar -X- _ O
bert -X- _ O
- -X- _ O
as -X- _ O
- -X- _ O
a -X- _ O
- -X- _ O
service -X- _ O
- -X- _ O
repository3 -X- _ O
. -X- _ O
Up -X- _ O
to -X- _ O
our -X- _ O
knowl- -X- _ O
edge -X- _ O
, -X- _ O
there -X- _ O
is -X- _ O
so -X- _ O
far -X- _ O
no -X- _ O
evaluation -X- _ O
if -X- _ O
these -X- _ O
methods -X- _ O
lead -X- _ O
to -X- _ O
useful -X- _ O
sentence -X- _ O
embeddings -X- _ O
. -X- _ O
Sentence -X- _ O
embeddings -X- _ O
are -X- _ O
a -X- _ O
well -X- _ O
studied -X- _ O
area -X- _ O
with -X- _ O
dozens -X- _ O
of -X- _ O
proposed -X- _ O
methods -X- _ O
. -X- _ O
Skip -X- _ B-MethodName
- -X- _ I-MethodName
Thought -X- _ I-MethodName
( -X- _ O
Kiros -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
trains -X- _ O
an -X- _ O
encoder -X- _ O
- -X- _ O
decoder -X- _ O
ar- -X- _ O
chitecture -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
surrounding -X- _ O
sentences -X- _ O
. -X- _ O
InferSent -X- _ B-MethodName
( -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
uses -X- _ O
labeled -X- _ O
data -X- _ O
of -X- _ O
the -X- _ O
Stanford -X- _ B-DatasetName
Natural -X- _ I-DatasetName
Language -X- _ I-DatasetName
Inference -X- _ I-DatasetName
dataset -X- _ O
( -X- _ O
Bowman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
and -X- _ O
the -X- _ O
Multi- -X- _ B-DatasetName
Genre -X- _ I-DatasetName
NLI -X- _ I-DatasetName
dataset -X- _ O
( -X- _ O
Williams -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
siamese -X- _ O
BiLSTM -X- _ O
network -X- _ O
with -X- _ O
max -X- _ O
- -X- _ O
pooling -X- _ O
over -X- _ O
the -X- _ O
output -X- _ O
. -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
showed -X- _ O
, -X- _ O
that -X- _ O
InferSent -X- _ B-MethodName
consistently -X- _ O
outperforms -X- _ O
unsupervised -X- _ O
methods -X- _ O
like -X- _ O
SkipThought -X- _ B-MethodName
. -X- _ O
Universal -X- _ B-MethodName
Sentence -X- _ I-MethodName
Encoder -X- _ I-MethodName
( -X- _ O
Cer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
trains -X- _ O
a -X- _ O
transformer -X- _ O
network -X- _ O
and -X- _ O
augments -X- _ O
unsupervised -X- _ O
learning -X- _ O
with -X- _ O
training -X- _ O
on -X- _ O
SNLI -X- _ B-DatasetName
. -X- _ O
Hill -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
showed -X- _ O
, -X- _ O
that -X- _ O
the -X- _ O
task -X- _ O
on -X- _ O
which -X- _ O
sentence -X- _ O
embeddings -X- _ O
are -X- _ O
trained -X- _ O
signiﬁcantly -X- _ O
impacts -X- _ O
their -X- _ O
quality -X- _ O
. -X- _ O
Previous -X- _ O
work -X- _ O
( -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Cer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
found -X- _ O
that -X- _ O
the -X- _ O
SNLI -X- _ B-DatasetName
datasets -X- _ O
are -X- _ O
suitable -X- _ O
for -X- _ O
training -X- _ O
sen- -X- _ O
tence -X- _ O
embeddings -X- _ O
. -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
presented -X- _ O
a -X- _ O
method -X- _ O
to -X- _ O
train -X- _ O
on -X- _ O
conversations -X- _ O
from -X- _ O
Reddit -X- _ O
using -X- _ O
siamese -X- _ O
DAN -X- _ O
and -X- _ O
siamese -X- _ O
transformer -X- _ O
net- -X- _ O
works -X- _ O
, -X- _ O
which -X- _ O
yielded -X- _ O
good -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
STS -X- _ O
benchmark -X- _ O
dataset -X- _ O
. -X- _ O

We -X- _ O
ﬁrst -X- _ O
introduce -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
then -X- _ O
, -X- _ O
we -X- _ O
discuss -X- _ O
state- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
sentence -X- _ O
embedding -X- _ O
methods -X- _ O
. -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
transformer -X- _ O
network -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
set -X- _ O
for -X- _ O
various -X- _ O
NLP -X- _ O
tasks -X- _ O
new -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
re- -X- _ O
sults -X- _ O
, -X- _ O
including -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
, -X- _ O
sentence -X- _ B-TaskName
clas- -X- _ I-TaskName
siﬁcation -X- _ O
, -X- _ O
and -X- _ O
sentence -X- _ B-TaskName
- -X- _ I-TaskName
pair -X- _ I-TaskName
regression -X- _ I-TaskName
. -X- _ O
The -X- _ O
input -X- _ O
for -X- _ O
BERT -X- _ B-MethodName
for -X- _ O
sentence -X- _ B-TaskName
- -X- _ I-TaskName
pair -X- _ I-TaskName
regression -X- _ I-TaskName
consists -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
sentences -X- _ O
, -X- _ O
separated -X- _ O
by -X- _ O
a -X- _ O
special -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
token -X- _ O
. -X- _ O
Multi -X- _ O
- -X- _ O
head -X- _ O
attention -X- _ O
over -X- _ O
12 -X- _ B-HyperparameterValue
( -X- _ O
base -X- _ O
- -X- _ O
model -X- _ O
) -X- _ O
or -X- _ O
24 -X- _ B-HyperparameterValue
layers -X- _ B-HyperparameterName
( -X- _ O
large -X- _ O
- -X- _ O
model -X- _ O
) -X- _ O
is -X- _ O
applied -X- _ O
and -X- _ O
the -X- _ O
out- -X- _ O
put -X- _ O
is -X- _ O
passed -X- _ O
to -X- _ O
a -X- _ O
simple -X- _ O
regression -X- _ O
function -X- _ O
to -X- _ O
de- -X- _ O
rive -X- _ O
the -X- _ O
ﬁnal -X- _ O
label -X- _ O
. -X- _ O
Using -X- _ O
this -X- _ O
setup -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
set -X- _ O
a -X- _ O

most -X- _ O
similar -X- _ O
sentence -X- _ O
pair -X- _ O
in -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
10,000 -X- _ O
sentences -X- _ O
is -X- _ O
reduced -X- _ O
from -X- _ O
65 -X- _ O
hours -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
to -X- _ O
the -X- _ O
computation -X- _ O
of -X- _ O
10,000 -X- _ O
sentence -X- _ O
embeddings -X- _ O
( -X- _ O
~5 -X- _ O
seconds -X- _ O
with -X- _ O
SBERT -X- _ O
) -X- _ O
and -X- _ O
computing -X- _ O
cosine- -X- _ O
similarity -X- _ O
( -X- _ O
~0.01 -X- _ O
seconds -X- _ O
) -X- _ O
. -X- _ O
By -X- _ O
using -X- _ O
optimized -X- _ O
index -X- _ O
structures -X- _ O
, -X- _ O
ﬁnding -X- _ O
the -X- _ O
most -X- _ O
similar -X- _ O
Quora -X- _ O
question -X- _ O
can -X- _ O
be -X- _ O
reduced -X- _ O
from -X- _ O
50 -X- _ O
hours -X- _ O
to -X- _ O
a -X- _ O
few -X- _ O
milliseconds -X- _ O
( -X- _ O
Johnson -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
ﬁne -X- _ O
- -X- _ O
tune -X- _ O
SBERT -X- _ B-MethodName
on -X- _ O
NLI -X- _ B-DatasetName
data -X- _ I-DatasetName
, -X- _ O
which -X- _ O
cre- -X- _ O
ates -X- _ O
sentence -X- _ O
embeddings -X- _ O
that -X- _ O
signiﬁcantly -X- _ O
out- -X- _ O
perform -X- _ O
other -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
sentence -X- _ O
embedding -X- _ O
methods -X- _ O
like -X- _ O
InferSent -X- _ B-MethodName
( -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
Universal -X- _ B-MethodName
Sentence -X- _ I-MethodName
Encoder -X- _ I-MethodName
( -X- _ O
Cer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
On -X- _ O
seven -X- _ O
Semantic -X- _ B-TaskName
Textual -X- _ I-TaskName
Similarity -X- _ I-TaskName
( -X- _ O
STS -X- _ B-TaskName
) -X- _ O
tasks -X- _ O
, -X- _ O
SBERT -X- _ B-MethodName
achieves -X- _ O
an -X- _ O
improvement -X- _ O
of -X- _ O
11.7 -X- _ B-MetricValue
points -X- _ O
compared -X- _ O
to -X- _ O
InferSent -X- _ B-MethodName
and -X- _ O
5.5 -X- _ B-MetricValue
points -X- _ O
compared -X- _ O
to -X- _ O
Universal -X- _ B-MethodName
Sentence -X- _ I-MethodName
Encoder -X- _ I-MethodName
. -X- _ O
On -X- _ O
SentEval -X- _ B-DatasetName
( -X- _ O
Con- -X- _ O
neau -X- _ O
and -X- _ O
Kiela -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
an -X- _ O
evaluation -X- _ O
toolkit -X- _ O
for -X- _ O
sentence -X- _ O
embeddings -X- _ O
, -X- _ O
we -X- _ O
achieve -X- _ O
an -X- _ O
improvement -X- _ O
of -X- _ O
2.1 -X- _ B-MetricValue
and -X- _ O
2.6 -X- _ B-MetricValue
points -X- _ O
, -X- _ O
respectively -X- _ O
. -X- _ O
SBERT -X- _ B-MethodName
can -X- _ O
be -X- _ O
adapted -X- _ O
to -X- _ O
a -X- _ O
speciﬁc -X- _ O
task -X- _ O
. -X- _ O
It -X- _ O
sets -X- _ O
new -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
on -X- _ O
a -X- _ O
chal- -X- _ O
lenging -X- _ O
argument -X- _ B-DatasetName
similarity -X- _ I-DatasetName
dataset -X- _ I-DatasetName
( -X- _ O
Misra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
and -X- _ O
on -X- _ O
a -X- _ O
triplet -X- _ B-DatasetName
dataset -X- _ I-DatasetName
to -X- _ O
distinguish -X- _ O
sen- -X- _ O
tences -X- _ O
from -X- _ O
different -X- _ O
sections -X- _ O
of -X- _ O
a -X- _ O
Wikipedia -X- _ B-DatasetName
arti- -X- _ I-DatasetName
cle -X- _ I-DatasetName
( -X- _ O
Dor -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
paper -X- _ O
is -X- _ O
structured -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
way -X- _ O
: -X- _ O
Section -X- _ O
3 -X- _ O
presents -X- _ O
SBERT -X- _ B-MethodName
, -X- _ O
section -X- _ O
4 -X- _ O
evaluates -X- _ O
SBERT -X- _ B-MethodName
on -X- _ O
common -X- _ O
STS -X- _ B-TaskName
tasks -X- _ O
and -X- _ O
on -X- _ O
the -X- _ O
chal- -X- _ O
lenging -X- _ O
Argument -X- _ B-DatasetName
Facet -X- _ I-DatasetName
Similarity -X- _ I-DatasetName
( -X- _ O
AFS -X- _ O
) -X- _ O
corpus -X- _ O
( -X- _ O
Misra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
Section -X- _ O
5 -X- _ O
evaluates -X- _ O
SBERT -X- _ B-MethodName
on -X- _ O
SentEval -X- _ B-DatasetName
. -X- _ O
In -X- _ O
section -X- _ O
6 -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
an -X- _ O
ablation -X- _ O
study -X- _ O
to -X- _ O
test -X- _ O
some -X- _ O
design -X- _ O
aspect -X- _ O
of -X- _ O
SBERT -X- _ B-MethodName
. -X- _ O
In -X- _ O
sec- -X- _ O
tion -X- _ O
7 -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
the -X- _ O
computational -X- _ O
efﬁciency -X- _ O
of -X- _ O
SBERT -X- _ B-MethodName
sentence -X- _ O
embeddings -X- _ O
in -X- _ O
contrast -X- _ O
to -X- _ O
other -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
sentence -X- _ O
embedding -X- _ O
methods -X- _ O
. -X- _ O

tic -X- _ O
similarity -X- _ B-TaskName
comparison -X- _ I-TaskName
, -X- _ O
clustering -X- _ B-TaskName
, -X- _ O
and -X- _ O
informa- -X- _ B-TaskName
tion -X- _ I-TaskName
retrieval -X- _ I-TaskName
via -X- _ O
semantic -X- _ O
search -X- _ O
. -X- _ O
BERT -X- _ B-MethodName
set -X- _ O
new -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
on -X- _ O
various -X- _ O
sentence -X- _ B-TaskName
classiﬁcation -X- _ I-TaskName
and -X- _ O
sentence -X- _ B-TaskName
- -X- _ I-TaskName
pair -X- _ I-TaskName
regression -X- _ I-TaskName
tasks -X- _ O
. -X- _ O
BERT -X- _ B-MethodName
uses -X- _ O
a -X- _ O
cross -X- _ O
- -X- _ O
encoder -X- _ O
: -X- _ O
Two -X- _ O
sentences -X- _ O
are -X- _ O
passed -X- _ O
to -X- _ O
the -X- _ O
transformer -X- _ O
network -X- _ O
and -X- _ O
the -X- _ O
target -X- _ O
value -X- _ O
is -X- _ O
predicted -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
this -X- _ O
setup -X- _ O
is -X- _ O
unsuitable -X- _ O
for -X- _ O
various -X- _ O
pair -X- _ O
regression -X- _ O
tasks -X- _ O
due -X- _ O
to -X- _ O
too -X- _ O
many -X- _ O
possible -X- _ O
combinations -X- _ O
. -X- _ O
Finding -X- _ O
in -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
n -X- _ O
= -X- _ O
10 -X- _ O
000 -X- _ O
sentences -X- _ O
the -X- _ O
pair -X- _ O
with -X- _ O
the -X- _ O
highest -X- _ O
similarity -X- _ O
requires -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
n·(n−1)/2 -X- _ O
= -X- _ O
49 -X- _ O
995 -X- _ O
000 -X- _ O
inference -X- _ O
computations -X- _ O
. -X- _ O
On -X- _ O
a -X- _ O
modern -X- _ O
V100 -X- _ O
GPU -X- _ O
, -X- _ O
this -X- _ O
requires -X- _ O
about -X- _ O
65 -X- _ O
hours -X- _ O
. -X- _ O
Similar -X- _ O
, -X- _ O
ﬁnding -X- _ O
which -X- _ O
of -X- _ O
the -X- _ O
over -X- _ O
40 -X- _ O
mil- -X- _ O
lion -X- _ O
existent -X- _ O
questions -X- _ O
of -X- _ O
Quora -X- _ O
is -X- _ O
the -X- _ O
most -X- _ O
similar -X- _ O
for -X- _ O
a -X- _ O
new -X- _ O
question -X- _ O
could -X- _ O
be -X- _ O
modeled -X- _ O
as -X- _ O
a -X- _ O
pair -X- _ O
- -X- _ O
wise -X- _ O
comparison -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
however -X- _ O
, -X- _ O
answering -X- _ O
a -X- _ O
sin- -X- _ O
gle -X- _ O
query -X- _ O
would -X- _ O
require -X- _ O
over -X- _ O
50 -X- _ O
hours -X- _ O
. -X- _ O
A -X- _ O
common -X- _ O
method -X- _ O
to -X- _ O
address -X- _ O
clustering -X- _ B-TaskName
and -X- _ O
se- -X- _ B-TaskName
mantic -X- _ I-TaskName
search -X- _ I-TaskName
is -X- _ O
to -X- _ O
map -X- _ O
each -X- _ O
sentence -X- _ O
to -X- _ O
a -X- _ O
vec- -X- _ O
tor -X- _ O
space -X- _ O
such -X- _ O
that -X- _ O
semantically -X- _ O
similar -X- _ O
sentences -X- _ O
are -X- _ O
close -X- _ O
. -X- _ O
Researchers -X- _ O
have -X- _ O
started -X- _ O
to -X- _ O
input -X- _ O
indi- -X- _ O
vidual -X- _ O
sentences -X- _ O
into -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
to -X- _ O
derive -X- _ O
ﬁxed- -X- _ O
size -X- _ O
sentence -X- _ O
embeddings -X- _ O
. -X- _ O
The -X- _ O
most -X- _ O
commonly -X- _ O
used -X- _ O
approach -X- _ O
is -X- _ O
to -X- _ O
average -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
output -X- _ O
layer -X- _ O
( -X- _ O
known -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
embeddings -X- _ O
) -X- _ O
or -X- _ O
by -X- _ O
using -X- _ O
the -X- _ O
out- -X- _ O
put -X- _ O
of -X- _ O
the -X- _ O
ﬁrst -X- _ O
token -X- _ O
( -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
) -X- _ O
. -X- _ O
As -X- _ O
we -X- _ O
will -X- _ O
show -X- _ O
, -X- _ O
this -X- _ O
common -X- _ O
practice -X- _ O
yields -X- _ O
rather -X- _ O
bad -X- _ O
sentence -X- _ O
embeddings -X- _ O
, -X- _ O
often -X- _ O
worse -X- _ O
than -X- _ O
averaging -X- _ O
GloVe -X- _ B-MethodName
embeddings -X- _ O
( -X- _ O
Pennington -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
alleviate -X- _ O
this -X- _ O
issue -X- _ O
, -X- _ O
we -X- _ O
developed -X- _ O
SBERT -X- _ B-MethodName
. -X- _ O
The -X- _ O
siamese -X- _ O
network -X- _ O
architecture -X- _ O
enables -X- _ O
that -X- _ O
ﬁxed -X- _ O
- -X- _ O
sized -X- _ O
vectors -X- _ O
for -X- _ O
input -X- _ O
sentences -X- _ O
can -X- _ O
be -X- _ O
de- -X- _ O
rived -X- _ O
. -X- _ O
Using -X- _ O
a -X- _ O
similarity -X- _ O
measure -X- _ O
like -X- _ O
cosine- -X- _ B-MetricName
similarity -X- _ I-MetricName
or -X- _ O
Manhatten -X- _ B-MetricName
/ -X- _ O
Euclidean -X- _ B-MetricName
distance -X- _ I-MetricName
, -X- _ O
se- -X- _ O
mantically -X- _ O
similar -X- _ O
sentences -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
. -X- _ O
These -X- _ O
similarity -X- _ O
measures -X- _ O
can -X- _ O
be -X- _ O
performed -X- _ O
extremely -X- _ O
efﬁcient -X- _ O
on -X- _ O
modern -X- _ O
hardware -X- _ O
, -X- _ O
allowing -X- _ O
SBERT -X- _ B-MethodName
to -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
semantic -X- _ B-TaskName
similarity -X- _ I-TaskName
search -X- _ I-TaskName
as -X- _ O
well -X- _ O
as -X- _ O
for -X- _ O
clustering -X- _ O
. -X- _ O
The -X- _ O
complexity -X- _ O
for -X- _ O
ﬁnding -X- _ O
the -X- _ O

In -X- _ O
this -X- _ O
publication -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
Sentence -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
( -X- _ O
SBERT -X- _ B-MethodName
) -X- _ O
, -X- _ O
a -X- _ O
modiﬁcation -X- _ O
of -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
network -X- _ O
us- -X- _ O
ing -X- _ O
siamese -X- _ O
and -X- _ O
triplet -X- _ O
networks -X- _ O
that -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
derive -X- _ O
semantically -X- _ O
meaningful -X- _ O
sentence -X- _ O
embed- -X- _ O
dings2 -X- _ O
. -X- _ O
This -X- _ O
enables -X- _ O
BERT -X- _ B-MethodName
to -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
certain -X- _ O
new -X- _ O
tasks -X- _ O
, -X- _ O
which -X- _ O
up -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
now -X- _ O
were -X- _ O
not -X- _ O
applicable -X- _ O
for -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
These -X- _ O
tasks -X- _ O
include -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
seman- -X- _ O

BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
RoBERTa -X- _ B-MethodName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
has -X- _ O
set -X- _ O
a -X- _ O
new -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
on -X- _ O
sentence -X- _ O
- -X- _ O
pair -X- _ O
regression -X- _ O
tasks -X- _ O
like -X- _ O
semantic -X- _ B-TaskName
textual -X- _ I-TaskName
similarity -X- _ I-TaskName
( -X- _ O
STS -X- _ B-TaskName
) -X- _ O
. -X- _ O
How- -X- _ O
ever -X- _ O
, -X- _ O
it -X- _ O
requires -X- _ O
that -X- _ O
both -X- _ O
sentences -X- _ O
are -X- _ O
fed -X- _ O
into -X- _ O
the -X- _ O
network -X- _ O
, -X- _ O
which -X- _ O
causes -X- _ O
a -X- _ O
massive -X- _ O
com- -X- _ O
putational -X- _ O
overhead -X- _ O
: -X- _ O
Finding -X- _ O
the -X- _ O
most -X- _ O
sim- -X- _ O
ilar -X- _ O
pair -X- _ O
in -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
10,000 -X- _ O
sentences -X- _ O
requires -X- _ O
about -X- _ O
50 -X- _ O
million -X- _ O
inference -X- _ O
computa- -X- _ O
tions -X- _ O
( -X- _ O
~65 -X- _ O
hours -X- _ O
) -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
The -X- _ O
construction -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
makes -X- _ O
it -X- _ O
unsuitable -X- _ O
for -X- _ O
semantic -X- _ O
sim- -X- _ O
ilarity -X- _ O
search -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
for -X- _ O
unsupervised -X- _ O
tasks -X- _ O
like -X- _ O
clustering -X- _ B-TaskName
. -X- _ O

In -X- _ O
this -X- _ O
publication -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
Sentence -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
( -X- _ O
SBERT -X- _ B-MethodName
) -X- _ O
, -X- _ O
a -X- _ O
modiﬁcation -X- _ O
of -X- _ O
the -X- _ O
pretrained -X- _ O
BERT -X- _ B-MethodName
network -X- _ O
that -X- _ O
use -X- _ O
siamese -X- _ O
and -X- _ O
triplet -X- _ O
net- -X- _ O
work -X- _ O
structures -X- _ O
to -X- _ O
derive -X- _ O
semantically -X- _ O
mean- -X- _ O
ingful -X- _ O
sentence -X- _ O
embeddings -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
com- -X- _ O
pared -X- _ O
using -X- _ O
cosine -X- _ B-MetricName
- -X- _ I-MetricName
similarity -X- _ I-MetricName
. -X- _ O
This -X- _ O
reduces -X- _ O
the -X- _ O
effort -X- _ O
for -X- _ O
ﬁnding -X- _ O
the -X- _ O
most -X- _ O
similar -X- _ O
pair -X- _ O
from -X- _ O
65 -X- _ O
hours -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
/ -X- _ O
RoBERTa -X- _ B-MethodName
to -X- _ O
about -X- _ O
5 -X- _ O
sec- -X- _ O
onds -X- _ O
with -X- _ O
SBERT -X- _ B-MethodName
, -X- _ O
while -X- _ O
maintaining -X- _ O
the -X- _ O
ac- -X- _ B-MetricName
curacy -X- _ I-MetricName
from -X- _ O
BERT -X- _ B-MethodName
. -X- _ O

Sentence -X- _ B-MethodName
- -X- _ I-MethodName
BERT -X- _ I-MethodName
: -X- _ O
Sentence -X- _ O
Embeddings -X- _ O
using -X- _ O
Siamese -X- _ O
BERT -X- _ O
- -X- _ O
Networks -X- _ O

