-DOCSTART- -X- O
The -X- _ O
results -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
8 -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
table -X- _ O
, -X- _ O
MASK -X- _ O
means -X- _ O
that -X- _ O
we -X- _ O
replace -X- _ O
the -X- _ O
target -X- _ O
token -X- _ O
with -X- _ O
the -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
symbol -X- _ O
for -X- _ O
MLM -X- _ B-MethodName
; -X- _ O
SAME -X- _ O
means -X- _ O
that -X- _ O
we -X- _ O
keep -X- _ O
the -X- _ O
target -X- _ O
token -X- _ O
as -X- _ O
is -X- _ O
; -X- _ O
RND -X- _ O
means -X- _ O
that -X- _ O
we -X- _ O
replace -X- _ O
the -X- _ O
target -X- _ O
token -X- _ O
with -X- _ O
another -X- _ O
random -X- _ O
token -X- _ O
. -X- _ O
The -X- _ O
numbers -X- _ O
in -X- _ O
the -X- _ O
left -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
table -X- _ O
repre- -X- _ O
sent -X- _ O
the -X- _ O
probabilities -X- _ O
of -X- _ O
the -X- _ O
speciﬁc -X- _ O
strategies -X- _ O
used -X- _ O
during -X- _ O
MLM -X- _ B-MethodName
pre -X- _ O
- -X- _ O
training -X- _ O
( -X- _ O
BERT -X- _ B-MethodName
uses -X- _ O
80 -X- _ O
% -X- _ O
, -X- _ O
10 -X- _ O
% -X- _ O
, -X- _ O
10 -X- _ O
% -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
right -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
paper -X- _ O
represents -X- _ O
the -X- _ O
Dev -X- _ O
set -X- _ O
results -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
feature -X- _ O
- -X- _ O
based -X- _ O
approach -X- _ O
, -X- _ O
we -X- _ O
concatenate -X- _ O
the -X- _ O
last -X- _ O
4 -X- _ O
layers -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
as -X- _ O
the -X- _ O
features -X- _ O
, -X- _ O
which -X- _ O
was -X- _ O
shown -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
best -X- _ O
approach -X- _ O
in -X- _ O
Section -X- _ O
5.3 -X- _ O
. -X- _ O
From -X- _ O
the -X- _ O
table -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
that -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
is -X- _ O
surprisingly -X- _ O
robust -X- _ O
to -X- _ O
different -X- _ O
masking -X- _ O
strategies -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
as -X- _ O
expected -X- _ O
, -X- _ O
using -X- _ O
only -X- _ O
the -X- _ O
MASK -X- _ O
strat- -X- _ O
egy -X- _ O
was -X- _ O
problematic -X- _ O
when -X- _ O
applying -X- _ O
the -X- _ O
feature- -X- _ O
based -X- _ O
approach -X- _ O
to -X- _ O
NER -X- _ B-TaskName
. -X- _ O
Interestingly -X- _ O
, -X- _ O
using -X- _ O
only -X- _ O
the -X- _ O
RND -X- _ O
strategy -X- _ O
performs -X- _ O
much -X- _ O
worse -X- _ O
than -X- _ O
our -X- _ O
strategy -X- _ O
as -X- _ O
well -X- _ O
. -X- _ O

MASK -X- _ O
SAME -X- _ O
RND -X- _ O
MNLI -X- _ B-TaskName
NER -X- _ B-TaskName
Fine -X- _ O
- -X- _ O
tune -X- _ O
Fine -X- _ O
- -X- _ O
tune -X- _ O
Feature -X- _ O
- -X- _ O
based -X- _ O

Note -X- _ O
that -X- _ O
the -X- _ O
purpose -X- _ O
of -X- _ O
the -X- _ O
masking -X- _ O
strategies -X- _ O
is -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
mismatch -X- _ O
between -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
as -X- _ O
the -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
symbol -X- _ O
never -X- _ O
ap- -X- _ O
pears -X- _ O
during -X- _ O
the -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
stage -X- _ O
. -X- _ O
We -X- _ O
report -X- _ O
the -X- _ O
Dev -X- _ O
results -X- _ O
for -X- _ O
both -X- _ O
MNLI -X- _ B-TaskName
and -X- _ O
NER -X- _ B-TaskName
. -X- _ O
For -X- _ O
NER -X- _ B-TaskName
, -X- _ O
we -X- _ O
report -X- _ O
both -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
and -X- _ O
feature -X- _ O
- -X- _ O
based -X- _ O
ap- -X- _ O
proaches -X- _ O
, -X- _ O
as -X- _ O
we -X- _ O
expect -X- _ O
the -X- _ O
mismatch -X- _ O
will -X- _ O
be -X- _ O
am- -X- _ O
pliﬁed -X- _ O
for -X- _ O
the -X- _ O
feature -X- _ O
- -X- _ O
based -X- _ O
approach -X- _ O
as -X- _ O
the -X- _ O
model -X- _ O
will -X- _ O
not -X- _ O
have -X- _ O
the -X- _ O
chance -X- _ O
to -X- _ O
adjust -X- _ O
the -X- _ O
representa- -X- _ O
tions -X- _ O
. -X- _ O

Figure -X- _ O
5 -X- _ O
: -X- _ O
Ablation -X- _ O
over -X- _ O
number -X- _ O
of -X- _ O
training -X- _ O
steps -X- _ O
. -X- _ O
This -X- _ O
shows -X- _ O
the -X- _ O
MNLI -X- _ B-TaskName
accuracy -X- _ O
after -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
starting -X- _ O
from -X- _ O
model -X- _ O
parameters -X- _ O
that -X- _ O
have -X- _ O
been -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
for -X- _ O
k -X- _ O
steps -X- _ O
. -X- _ O
The -X- _ O
x -X- _ O
- -X- _ O
axis -X- _ O
is -X- _ O
the -X- _ O
value -X- _ O
of -X- _ O
k. -X- _ O

In -X- _ O
Section -X- _ O
3.1 -X- _ O
, -X- _ O
we -X- _ O
mention -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
uses -X- _ O
a -X- _ O
mixed -X- _ O
strategy -X- _ O
for -X- _ O
masking -X- _ O
the -X- _ O
target -X- _ O
tokens -X- _ O
when -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
with -X- _ O
the -X- _ O
masked -X- _ B-MethodName
language -X- _ I-MethodName
model -X- _ I-MethodName
( -X- _ O
MLM -X- _ B-MethodName
) -X- _ O
objective -X- _ O
. -X- _ O
The -X- _ O
following -X- _ O
is -X- _ O
an -X- _ O
ablation -X- _ O
study -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
different -X- _ O
masking -X- _ O
strategies -X- _ O
. -X- _ O

2 -X- _ O
. -X- _ O
Question -X- _ O
: -X- _ O
Does -X- _ O
MLM -X- _ B-MethodName
pre -X- _ O
- -X- _ O
training -X- _ O
converge -X- _ O
slower -X- _ O
than -X- _ O
LTR -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
since -X- _ O
only -X- _ O
15 -X- _ O
% -X- _ O
of -X- _ O
words -X- _ O
are -X- _ O
predicted -X- _ O
in -X- _ O
each -X- _ O
batch -X- _ O
rather -X- _ O
than -X- _ O
every -X- _ O
word -X- _ O
? -X- _ O
Answer -X- _ O
: -X- _ O
The -X- _ O
MLM -X- _ B-MethodName
model -X- _ O
does -X- _ O
converge -X- _ O
slightly -X- _ O
slower -X- _ O
than -X- _ O
the -X- _ O
LTR -X- _ O
model -X- _ O
. -X- _ O
How- -X- _ O
ever -X- _ O
, -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
absolute -X- _ O
accuracy -X- _ O
the -X- _ O
MLM -X- _ B-MethodName
model -X- _ O
begins -X- _ O
to -X- _ O
outperform -X- _ O
the -X- _ O
LTR -X- _ O
model -X- _ O
almost -X- _ O
immediately -X- _ O
. -X- _ O

1 -X- _ O
. -X- _ O
Question -X- _ O
: -X- _ O
Does -X- _ O
BERT -X- _ B-MethodName
really -X- _ O
need -X- _ O
such -X- _ O
a -X- _ O
large -X- _ O
amount -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
( -X- _ O
128,000 -X- _ O
words -X- _ O
/ -X- _ O
batch -X- _ O
* -X- _ O
1,000,000 -X- _ O
steps -X- _ O
) -X- _ O
to -X- _ O
achieve -X- _ O
high -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
accuracy -X- _ O
? -X- _ O
Answer -X- _ O
: -X- _ O
Yes -X- _ O
, -X- _ O
BERTBASE -X- _ B-MethodName
achieves -X- _ O
almost -X- _ O
1.0 -X- _ O
% -X- _ O
additional -X- _ O
accuracy -X- _ O
on -X- _ O
MNLI -X- _ B-TaskName
when -X- _ O
trained -X- _ O
on -X- _ O
1 -X- _ O
M -X- _ O
steps -X- _ O
compared -X- _ O
to -X- _ O
500k -X- _ O
steps -X- _ O
. -X- _ O

Figure -X- _ O
5 -X- _ O
presents -X- _ O
MNLI -X- _ B-TaskName
Dev -X- _ O
accuracy -X- _ O
after -X- _ O
ﬁne- -X- _ O
tuning -X- _ O
from -X- _ O
a -X- _ O
checkpoint -X- _ O
that -X- _ O
has -X- _ O
been -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
for -X- _ O
k -X- _ O
steps -X- _ O
. -X- _ O
This -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
answer -X- _ O
the -X- _ O
following -X- _ O
questions -X- _ O
: -X- _ O

14Note -X- _ O
that -X- _ O
we -X- _ O
only -X- _ O
report -X- _ O
single -X- _ O
- -X- _ O
task -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
results -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
. -X- _ O
A -X- _ O
multitask -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
approach -X- _ O
could -X- _ O
poten- -X- _ O
tially -X- _ O
push -X- _ O
the -X- _ O
performance -X- _ O
even -X- _ O
further -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
we -X- _ O
did -X- _ O
observe -X- _ O
substantial -X- _ O
improvements -X- _ O
on -X- _ O
RTE -X- _ O
from -X- _ O
multi- -X- _ O
task -X- _ O
training -X- _ O
with -X- _ O
MNLI -X- _ B-TaskName
. -X- _ O
15https://gluebenchmark.com/faq -X- _ O

WNLI -X- _ B-TaskName
Winograd -X- _ B-TaskName
NLI -X- _ I-TaskName
is -X- _ O
a -X- _ O
small -X- _ O
natural -X- _ B-TaskName
lan- -X- _ I-TaskName
guage -X- _ I-TaskName
inference -X- _ I-TaskName
dataset -X- _ O
( -X- _ O
Levesque -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
GLUE -X- _ B-MetricName
webpage -X- _ O
notes -X- _ O
that -X- _ O
there -X- _ O
are -X- _ O
issues -X- _ O
with -X- _ O
the -X- _ O
construction -X- _ O
of -X- _ O
this -X- _ O
dataset -X- _ O
, -X- _ O
15 -X- _ O
and -X- _ O
every -X- _ O
trained -X- _ O
system -X- _ O
that -X- _ O
’s -X- _ O
been -X- _ O
submitted -X- _ O
to -X- _ O
GLUE -X- _ B-MetricName
has -X- _ O
performed -X- _ O
worse -X- _ O
than -X- _ O
the -X- _ O
65.1 -X- _ B-MetricValue
baseline -X- _ B-MetricName
accuracy -X- _ I-MetricName
of -X- _ O
predicting -X- _ O
the -X- _ O
majority -X- _ O
class -X- _ O
. -X- _ O
We -X- _ O
therefore -X- _ O
ex- -X- _ O
clude -X- _ O
this -X- _ O
set -X- _ O
to -X- _ O
be -X- _ O
fair -X- _ O
to -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
. -X- _ O
For -X- _ O
our -X- _ O
GLUE -X- _ B-MetricName
submission -X- _ O
, -X- _ O
we -X- _ O
always -X- _ O
predicted -X- _ O
the -X- _ O
ma- -X- _ O

STS -X- _ B-MetricName
- -X- _ I-MetricName
B -X- _ I-MetricName
The -X- _ O
Semantic -X- _ B-MetricName
Textual -X- _ I-MetricName
Similarity -X- _ I-MetricName
Bench- -X- _ I-MetricName
mark -X- _ I-MetricName
is -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
sentence -X- _ O
pairs -X- _ O
drawn -X- _ O
from -X- _ O
news -X- _ O
headlines -X- _ O
and -X- _ O
other -X- _ O
sources -X- _ O
( -X- _ O
Cer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
They -X- _ O
were -X- _ O
annotated -X- _ O
with -X- _ O
a -X- _ O
score -X- _ O
from -X- _ O
1 -X- _ O
to -X- _ O
5 -X- _ O
denoting -X- _ O
how -X- _ O
similar -X- _ O
the -X- _ O
two -X- _ O
sentences -X- _ O
are -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
semantic -X- _ O
meaning -X- _ O
. -X- _ O

RTE -X- _ B-TaskName
Recognizing -X- _ B-TaskName
Textual -X- _ I-TaskName
Entailment -X- _ I-TaskName
is -X- _ O
a -X- _ O
bi- -X- _ O
nary -X- _ O
entailment -X- _ O
task -X- _ O
similar -X- _ O
to -X- _ O
MNLI -X- _ B-TaskName
, -X- _ O
but -X- _ O
with -X- _ O
much -X- _ O
less -X- _ O
training -X- _ O
data -X- _ O
( -X- _ O
Bentivogli -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2009).14 -X- _ O

for -X- _ O
whether -X- _ O
the -X- _ O
sentences -X- _ O
in -X- _ O
the -X- _ O
pair -X- _ O
are -X- _ O
semanti- -X- _ O
cally -X- _ O
equivalent -X- _ O
( -X- _ O
Dolan -X- _ O
and -X- _ O
Brockett -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
. -X- _ O

MRPC -X- _ B-DatasetName
Microsoft -X- _ B-DatasetName
Research -X- _ I-DatasetName
Paraphrase -X- _ I-DatasetName
Corpus -X- _ I-DatasetName
consists -X- _ O
of -X- _ O
sentence -X- _ O
pairs -X- _ O
automatically -X- _ O
extracted -X- _ O
from -X- _ O
online -X- _ O
news -X- _ O
sources -X- _ O
, -X- _ O
with -X- _ O
human -X- _ O
annotations -X- _ O

CoLA -X- _ B-TaskName
The -X- _ O
Corpus -X- _ B-TaskName
of -X- _ I-TaskName
Linguistic -X- _ I-TaskName
Acceptability -X- _ I-TaskName
is -X- _ O
a -X- _ O
binary -X- _ O
single -X- _ O
- -X- _ O
sentence -X- _ O
classiﬁcation -X- _ O
task -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
whether -X- _ O
an -X- _ O
English -X- _ O
sentence -X- _ O
is -X- _ O
linguistically -X- _ O
“ -X- _ O
acceptable -X- _ O
” -X- _ O
or -X- _ O
not -X- _ O
( -X- _ O
Warstadt -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

SST-2 -X- _ B-DatasetName
The -X- _ O
Stanford -X- _ B-DatasetName
Sentiment -X- _ I-DatasetName
Treebank -X- _ I-DatasetName
is -X- _ O
a -X- _ O
binary -X- _ O
single -X- _ O
- -X- _ O
sentence -X- _ O
classiﬁcation -X- _ O
task -X- _ O
consist- -X- _ O
ing -X- _ O
of -X- _ O
sentences -X- _ O
extracted -X- _ O
from -X- _ O
movie -X- _ O
reviews -X- _ O
with -X- _ O
human -X- _ O
annotations -X- _ O
of -X- _ O
their -X- _ O
sentiment -X- _ O
( -X- _ O
Socher -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O

Figure -X- _ O
4 -X- _ O
: -X- _ O
Illustrations -X- _ O
of -X- _ O
Fine -X- _ O
- -X- _ O
tuning -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
Different -X- _ O
Tasks -X- _ O
. -X- _ O

Tok -X- _ O
1 -X- _ O
Tok -X- _ O
2 -X- _ O
Tok -X- _ O
N -X- _ O
... -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
Tok -X- _ O
1 -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
Tok -X- _ O

QNLI -X- _ B-TaskName
Question -X- _ B-TaskName
Natural -X- _ I-TaskName
Language -X- _ I-TaskName
Inference -X- _ O
is -X- _ O
a -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
Stanford -X- _ B-DatasetName
Question -X- _ I-DatasetName
Answering -X- _ I-DatasetName
Dataset -X- _ I-DatasetName
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
which -X- _ O
has -X- _ O
been -X- _ O
converted -X- _ O
to -X- _ O
a -X- _ O
binary -X- _ B-TaskName
classiﬁcation -X- _ I-TaskName
task -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
positive -X- _ O
examples -X- _ O
are -X- _ O
( -X- _ O
ques- -X- _ O
tion -X- _ O
, -X- _ O
sentence -X- _ O
) -X- _ O
pairs -X- _ O
which -X- _ O
do -X- _ O
contain -X- _ O
the -X- _ O
correct -X- _ O
answer -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
negative -X- _ O
examples -X- _ O
are -X- _ O
( -X- _ O
question -X- _ O
, -X- _ O
sentence -X- _ O
) -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
paragraph -X- _ O
which -X- _ O
do -X- _ O
not -X- _ O
contain -X- _ O
the -X- _ O
answer -X- _ O
. -X- _ O

QQP -X- _ B-TaskName
Quora -X- _ B-TaskName
Question -X- _ I-TaskName
Pairs -X- _ I-TaskName
is -X- _ O
a -X- _ O
binary -X- _ B-TaskName
classiﬁ- -X- _ I-TaskName
cation -X- _ I-TaskName
task -X- _ O
where -X- _ O
the -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
determine -X- _ O
if -X- _ O
two -X- _ O
questions -X- _ O
asked -X- _ O
on -X- _ O
Quora -X- _ O
are -X- _ O
semantically -X- _ O
equiv- -X- _ O
alent -X- _ O
( -X- _ O
Chen -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

MNLI -X- _ B-TaskName
Multi -X- _ B-TaskName
- -X- _ I-TaskName
Genre -X- _ I-TaskName
Natural -X- _ I-TaskName
Language -X- _ I-TaskName
Inference -X- _ I-TaskName
is -X- _ O
a -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
, -X- _ O
crowdsourced -X- _ O
entailment -X- _ O
classiﬁ- -X- _ B-TaskName
cation -X- _ I-TaskName
task -X- _ O
( -X- _ O
Williams -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Given -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
sentences -X- _ O
, -X- _ O
the -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
whether -X- _ O
the -X- _ O
sec- -X- _ O
ond -X- _ O
sentence -X- _ O
is -X- _ O
an -X- _ O
entailment -X- _ O
, -X- _ O
contradiction -X- _ O
, -X- _ O
or -X- _ O
neutral -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
ﬁrst -X- _ O
one -X- _ O
. -X- _ O

Our -X- _ O
GLUE -X- _ B-MetricName
results -X- _ O
in -X- _ O
Table1 -X- _ O
are -X- _ O
obtained -X- _ O
from -X- _ O
https://gluebenchmark.com/ -X- _ O
leaderboard -X- _ O
and -X- _ O
https://blog -X- _ O
. -X- _ O
openai.com/language-unsupervised -X- _ O
. -X- _ O
The -X- _ O
GLUE -X- _ B-MetricName
benchmark -X- _ O
includes -X- _ O
the -X- _ O
following -X- _ O
datasets -X- _ O
, -X- _ O
the -X- _ O
descriptions -X- _ O
of -X- _ O
which -X- _ O
were -X- _ O
originally -X- _ O
summarized -X- _ O
in -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018a -X- _ O
): -X- _ O

B.1 -X- _ O
Detailed -X- _ O
Descriptions -X- _ O
for -X- _ O
the -X- _ O
GLUE -X- _ B-MetricName
Benchmark -X- _ O
Experiments -X- _ O
. -X- _ O

The -X- _ O
illustration -X- _ O
of -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
different -X- _ O
tasks -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
in -X- _ O
Figure -X- _ O
4 -X- _ O
. -X- _ O
Our -X- _ O
task -X- _ O
- -X- _ O
speciﬁc -X- _ O
models -X- _ O
are -X- _ O
formed -X- _ O
by -X- _ O
incorporating -X- _ O
BERT -X- _ B-MethodName
with -X- _ O
one -X- _ O
additional -X- _ O
output -X- _ O
layer -X- _ O
, -X- _ O
so -X- _ O
a -X- _ O
minimal -X- _ O
num- -X- _ O
ber -X- _ O
of -X- _ O
parameters -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
learned -X- _ O
from -X- _ O
scratch -X- _ O
. -X- _ O
Among -X- _ O
the -X- _ O
tasks -X- _ O
, -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
are -X- _ O
sequence -X- _ O
- -X- _ O
level -X- _ O
tasks -X- _ O
while -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
and -X- _ O
( -X- _ O
d -X- _ O
) -X- _ O
are -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
tasks -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
ﬁgure -X- _ O
, -X- _ O
E -X- _ O
represents -X- _ O
the -X- _ O
input -X- _ O
embedding -X- _ O
, -X- _ O
Ti -X- _ O
represents -X- _ O
the -X- _ O
contextual -X- _ O
representation -X- _ O
of -X- _ O
token -X- _ O
i -X- _ O
, -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
is -X- _ O
the -X- _ O
special -X- _ O
symbol -X- _ O
for -X- _ O
classiﬁcation -X- _ O
out- -X- _ O
put -X- _ O
, -X- _ O
and -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
is -X- _ O
the -X- _ O
special -X- _ O
symbol -X- _ O
to -X- _ O
separate -X- _ O
non -X- _ O
- -X- _ O
consecutive -X- _ O
token -X- _ O
sequences -X- _ O
. -X- _ O

To -X- _ O
isolate -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
these -X- _ O
differences -X- _ O
, -X- _ O
we -X- _ O
per- -X- _ O
form -X- _ O
ablation -X- _ O
experiments -X- _ O
in -X- _ O
Section -X- _ O
5.1 -X- _ O
which -X- _ O
demonstrate -X- _ O
that -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
the -X- _ O
improvements -X- _ O
are -X- _ O
in -X- _ O
fact -X- _ O
coming -X- _ O
from -X- _ O
the -X- _ O
two -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
tasks -X- _ O
and -X- _ O
the -X- _ O
bidirectionality -X- _ O
they -X- _ O
enable -X- _ O
. -X- _ O

• -X- _ O
GPT -X- _ B-MethodName
used -X- _ O
the -X- _ O
same -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
5e-5 -X- _ B-HyperparameterValue
for -X- _ O
all -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
experiments -X- _ O
; -X- _ O
BERT -X- _ B-MethodName
chooses -X- _ O
a -X- _ O
task -X- _ O
- -X- _ O
speciﬁc -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
which -X- _ O
performs -X- _ O
the -X- _ O
best -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
. -X- _ O

• -X- _ O
GPT -X- _ B-MethodName
was -X- _ O
trained -X- _ O
for -X- _ O
1 -X- _ O
M -X- _ O
steps -X- _ O
with -X- _ O
a -X- _ O
batch -X- _ O
size -X- _ O
of -X- _ O
32,000 -X- _ O
words -X- _ O
; -X- _ O
BERT -X- _ B-MethodName
was -X- _ O
trained -X- _ O
for -X- _ O
1 -X- _ O
M -X- _ O
steps -X- _ O
with -X- _ O
a -X- _ O
batch -X- _ O
size -X- _ O
of -X- _ O
128,000 -X- _ O
words -X- _ O
. -X- _ O

• -X- _ O
GPT -X- _ B-MethodName
uses -X- _ O
a -X- _ O
sentence -X- _ O
separator -X- _ O
( -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
) -X- _ O
and -X- _ O
classiﬁer -X- _ O
token -X- _ O
( -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
) -X- _ O
which -X- _ O
are -X- _ O
only -X- _ O
in- -X- _ O
troduced -X- _ O
at -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
time -X- _ O
; -X- _ O
BERT -X- _ B-MethodName
learns -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
, -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
and -X- _ O
sentence -X- _ O
A -X- _ O
/ -X- _ O
B -X- _ O
embed- -X- _ O
dings -X- _ O
during -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O

• -X- _ O
GPT -X- _ B-MethodName
is -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
BooksCorpus -X- _ B-DatasetName
( -X- _ O
800 -X- _ O
M -X- _ O
words -X- _ O
) -X- _ O
; -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
BooksCor- -X- _ B-DatasetName
pus -X- _ I-DatasetName
( -X- _ O
800 -X- _ O
M -X- _ O
words -X- _ O
) -X- _ O
and -X- _ O
Wikipedia -X- _ B-DatasetName
( -X- _ O
2,500 -X- _ O
M -X- _ O
words -X- _ O
) -X- _ O
. -X- _ O

Here -X- _ O
we -X- _ O
studies -X- _ O
the -X- _ O
differences -X- _ O
in -X- _ O
recent -X- _ O
popular -X- _ O
representation -X- _ O
learning -X- _ O
models -X- _ O
including -X- _ O
ELMo -X- _ B-MethodName
, -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
and -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
The -X- _ O
comparisons -X- _ O
be- -X- _ O
tween -X- _ O
the -X- _ O
model -X- _ O
architectures -X- _ O
are -X- _ O
shown -X- _ O
visually -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
architec- -X- _ O
ture -X- _ O
differences -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
are -X- _ O
ﬁne- -X- _ O
tuning -X- _ O
approaches -X- _ O
, -X- _ O
while -X- _ O
ELMo -X- _ B-MethodName
is -X- _ O
a -X- _ O
feature -X- _ O
- -X- _ O
based -X- _ O
approach -X- _ O
. -X- _ O
The -X- _ O
most -X- _ O
comparable -X- _ O
existing -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
method -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
, -X- _ O
which -X- _ O
trains -X- _ O
a -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
Transformer -X- _ O
LM -X- _ B-MethodName
on -X- _ O
a -X- _ O
large -X- _ O
text -X- _ O
cor- -X- _ O
pus -X- _ O
. -X- _ O
In -X- _ O
fact -X- _ O
, -X- _ O
many -X- _ O
of -X- _ O
the -X- _ O
design -X- _ O
decisions -X- _ O
in -X- _ O
BERT -X- _ B-MethodName
were -X- _ O
intentionally -X- _ O
made -X- _ O
to -X- _ O
make -X- _ O
it -X- _ O
as -X- _ O
close -X- _ O
to -X- _ O
GPT -X- _ B-MethodName
as -X- _ O
possible -X- _ O
so -X- _ O
that -X- _ O
the -X- _ O
two -X- _ O
methods -X- _ O
could -X- _ O
be -X- _ O
minimally -X- _ O
compared -X- _ O
. -X- _ O
The -X- _ O
core -X- _ O
argument -X- _ O
of -X- _ O
this -X- _ O
work -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
bi -X- _ O
- -X- _ O
directionality -X- _ O
and -X- _ O
the -X- _ O
two -X- _ O
pre- -X- _ O
training -X- _ O
tasks -X- _ O
presented -X- _ O
in -X- _ O
Section -X- _ O
3.1 -X- _ O
account -X- _ O
for -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
the -X- _ O
empirical -X- _ O
improvements -X- _ O
, -X- _ O
but -X- _ O
we -X- _ O
do -X- _ O
note -X- _ O
that -X- _ O
there -X- _ O
are -X- _ O
several -X- _ O
other -X- _ O
differences -X- _ O
between -X- _ O
how -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
GPT -X- _ B-MethodName
were -X- _ O
trained -X- _ O
: -X- _ O

We -X- _ O
also -X- _ O
observed -X- _ O
that -X- _ O
large -X- _ O
data -X- _ O
sets -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
100k+ -X- _ O
labeled -X- _ O
training -X- _ O
examples -X- _ O
) -X- _ O
were -X- _ O
far -X- _ O
less -X- _ O
sensitive -X- _ O
to -X- _ O
hyperparameter -X- _ O
choice -X- _ O
than -X- _ O
small -X- _ O
data -X- _ O
sets -X- _ O
. -X- _ O
Fine -X- _ O
- -X- _ O
tuning -X- _ O
is -X- _ O
typically -X- _ O
very -X- _ O
fast -X- _ O
, -X- _ O
so -X- _ O
it -X- _ O
is -X- _ O
rea- -X- _ O
sonable -X- _ O
to -X- _ O
simply -X- _ O
run -X- _ O
an -X- _ O
exhaustive -X- _ O
search -X- _ O
over -X- _ O
the -X- _ O
above -X- _ O
parameters -X- _ O
and -X- _ O
choose -X- _ O
the -X- _ O
model -X- _ O
that -X- _ O
performs -X- _ O
best -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
. -X- _ O

• -X- _ O
Learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
( -X- _ O
Adam -X- _ B-HyperparameterName
): -X- _ O
5e-5 -X- _ B-HyperparameterValue
, -X- _ O
3e-5 -X- _ B-HyperparameterValue
, -X- _ O
2e-5 -X- _ B-HyperparameterValue
• -X- _ O
Number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
epochs -X- _ I-HyperparameterName
: -X- _ O
2 -X- _ B-HyperparameterValue
, -X- _ O
3 -X- _ B-HyperparameterValue
, -X- _ O
4 -X- _ B-HyperparameterValue

13https://cloudplatform.googleblog.com/2018/06/Cloud- -X- _ O
TPU -X- _ O
- -X- _ O
now -X- _ O
- -X- _ O
offers -X- _ O
- -X- _ O
preemptible -X- _ O
- -X- _ O
pricing -X- _ O
- -X- _ O
and -X- _ O
- -X- _ O
global- -X- _ O
availability.html -X- _ O

For -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
most -X- _ O
model -X- _ O
hyperparameters -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
in -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
exception -X- _ O
of -X- _ O
the -X- _ O
batch -X- _ O
size -X- _ O
, -X- _ O
learning -X- _ O
rate -X- _ O
, -X- _ O
and -X- _ O
number -X- _ O
of -X- _ O
train- -X- _ O
ing -X- _ O
epochs -X- _ O
. -X- _ O
The -X- _ O
dropout -X- _ B-HyperparameterName
probability -X- _ I-HyperparameterName
was -X- _ O
always -X- _ O
kept -X- _ O
at -X- _ O
0.1 -X- _ B-HyperparameterValue
. -X- _ O
The -X- _ O
optimal -X- _ O
hyperparameter -X- _ O
values -X- _ O
are -X- _ O
task -X- _ O
- -X- _ O
speciﬁc -X- _ O
, -X- _ O
but -X- _ O
we -X- _ O
found -X- _ O
the -X- _ O
following -X- _ O
range -X- _ O
of -X- _ O
possible -X- _ O
values -X- _ O
to -X- _ O
work -X- _ O
well -X- _ O
across -X- _ O
all -X- _ O
tasks -X- _ O
: -X- _ O

epochs -X- _ O
over -X- _ O
the -X- _ O
3.3 -X- _ O
billion -X- _ O
word -X- _ O
corpus -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
Adam -X- _ O
with -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
1e-4 -X- _ B-HyperparameterValue
, -X- _ O
β1 -X- _ B-HyperparameterName
= -X- _ O
0.9 -X- _ B-HyperparameterValue
, -X- _ O
β2 -X- _ B-HyperparameterName
= -X- _ O
0.999 -X- _ B-HyperparameterValue
, -X- _ O
L2 -X- _ B-HyperparameterName
weight -X- _ B-HyperparameterName
decay -X- _ I-HyperparameterName
of -X- _ O
0.01 -X- _ B-HyperparameterValue
, -X- _ O
learning -X- _ O
rate -X- _ O
warmup -X- _ O
over -X- _ O
the -X- _ O
ﬁrst -X- _ O
10,000 -X- _ O
steps -X- _ O
, -X- _ O
and -X- _ O
linear -X- _ O
decay -X- _ O
of -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
dropout -X- _ B-HyperparameterName
prob- -X- _ I-HyperparameterName
ability -X- _ I-HyperparameterName
of -X- _ O
0.1 -X- _ B-HyperparameterValue
on -X- _ O
all -X- _ O
layers -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
gelu -X- _ O
acti- -X- _ O
vation -X- _ O
( -X- _ O
Hendrycks -X- _ O
and -X- _ O
Gimpel -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
rather -X- _ O
than -X- _ O
the -X- _ O
standard -X- _ O
relu -X- _ O
, -X- _ O
following -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
. -X- _ O
The -X- _ O
training -X- _ O
loss -X- _ O
is -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
the -X- _ O
mean -X- _ O
masked -X- _ B-MethodName
LM -X- _ I-MethodName
likelihood -X- _ O
and -X- _ O
the -X- _ O
mean -X- _ O
next -X- _ B-TaskName
sentence -X- _ I-TaskName
prediction -X- _ I-TaskName
likelihood -X- _ O
. -X- _ O
Training -X- _ O
of -X- _ O
BERTBASE -X- _ B-MethodName
was -X- _ O
performed -X- _ O
on -X- _ O
4 -X- _ O
Cloud -X- _ O
TPUs -X- _ O
in -X- _ O
Pod -X- _ O
conﬁguration -X- _ O
( -X- _ O
16 -X- _ O
TPU -X- _ O
chips -X- _ O
total).13 -X- _ O
Training -X- _ O
of -X- _ O
BERTLARGE -X- _ B-MethodName
was -X- _ O
performed -X- _ O
on -X- _ O
16 -X- _ O
Cloud -X- _ O
TPUs -X- _ O
( -X- _ O
64 -X- _ O
TPU -X- _ O
chips -X- _ O
total -X- _ O
) -X- _ O
. -X- _ O
Each -X- _ O
pre- -X- _ O
training -X- _ O
took -X- _ O
4 -X- _ O
days -X- _ O
to -X- _ O
complete -X- _ O
. -X- _ O
Longer -X- _ O
sequences -X- _ O
are -X- _ O
disproportionately -X- _ O
expen- -X- _ O
sive -X- _ O
because -X- _ O
attention -X- _ O
is -X- _ O
quadratic -X- _ O
to -X- _ O
the -X- _ O
sequence -X- _ O
length -X- _ O
. -X- _ O
To -X- _ O
speed -X- _ O
up -X- _ O
pretraing -X- _ O
in -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
sequence -X- _ O
length -X- _ O
of -X- _ O
128 -X- _ O
for -X- _ O
90 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
steps -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
rest -X- _ O
10 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
steps -X- _ O
of -X- _ O
sequence -X- _ O
of -X- _ O
512 -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
positional -X- _ O
embeddings -X- _ O
. -X- _ O

To -X- _ O
generate -X- _ O
each -X- _ O
training -X- _ O
input -X- _ O
sequence -X- _ O
, -X- _ O
we -X- _ O
sam- -X- _ O
ple -X- _ O
two -X- _ O
spans -X- _ O
of -X- _ O
text -X- _ O
from -X- _ O
the -X- _ O
corpus -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
refer -X- _ O
to -X- _ O
as -X- _ O
“ -X- _ O
sentences -X- _ O
” -X- _ O
even -X- _ O
though -X- _ O
they -X- _ O
are -X- _ O
typ- -X- _ O
ically -X- _ O
much -X- _ O
longer -X- _ O
than -X- _ O
single -X- _ O
sentences -X- _ O
( -X- _ O
but -X- _ O
can -X- _ O
be -X- _ O
shorter -X- _ O
also -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
ﬁrst -X- _ O
sentence -X- _ O
receives -X- _ O
the -X- _ O
A -X- _ O
embedding -X- _ O
and -X- _ O
the -X- _ O
second -X- _ O
receives -X- _ O
the -X- _ O
B -X- _ O
embed- -X- _ O
ding -X- _ O
. -X- _ O
50 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
B -X- _ O
is -X- _ O
the -X- _ O
actual -X- _ O
next -X- _ O
sentence -X- _ O
that -X- _ O
follows -X- _ O
A -X- _ O
and -X- _ O
50 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
it -X- _ O
is -X- _ O
a -X- _ O
random -X- _ O
sentence -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
done -X- _ O
for -X- _ O
the -X- _ O
“ -X- _ O
next -X- _ B-TaskName
sentence -X- _ I-TaskName
pre- -X- _ I-TaskName
diction -X- _ I-TaskName
” -X- _ O
task -X- _ O
. -X- _ O
They -X- _ O
are -X- _ O
sampled -X- _ O
such -X- _ O
that -X- _ O
the -X- _ O
com- -X- _ O
bined -X- _ O
length -X- _ O
is -X- _ O
≤ -X- _ O
512 -X- _ O
tokens -X- _ O
. -X- _ O
The -X- _ O
LM -X- _ B-MethodName
masking -X- _ O
is -X- _ O
applied -X- _ O
after -X- _ O
WordPiece -X- _ O
tokenization -X- _ O
with -X- _ O
a -X- _ O
uni- -X- _ O
form -X- _ O
masking -X- _ O
rate -X- _ O
of -X- _ O
15 -X- _ O
% -X- _ O
, -X- _ O
and -X- _ O
no -X- _ O
special -X- _ O
consid- -X- _ O
eration -X- _ O
given -X- _ O
to -X- _ O
partial -X- _ O
word -X- _ O
pieces -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
with -X- _ O
batch -X- _ O
size -X- _ O
of -X- _ O
256 -X- _ O
sequences -X- _ O
( -X- _ O
256 -X- _ O
sequences -X- _ O
* -X- _ O
512 -X- _ O
tokens -X- _ O
= -X- _ O
128,000 -X- _ O
tokens -X- _ O
/ -X- _ O
batch -X- _ O
) -X- _ O
for -X- _ O
1,000,000 -X- _ O
steps -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
approximately -X- _ O
40 -X- _ O

Next -X- _ B-TaskName
Sentence -X- _ I-TaskName
Prediction -X- _ I-TaskName
The -X- _ O
next -X- _ O
sentence -X- _ O
prediction -X- _ O
task -X- _ O
can -X- _ O
be -X- _ O
illustrated -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
examples -X- _ O
. -X- _ O

to -X- _ O
converge -X- _ O
. -X- _ O
In -X- _ O
Section -X- _ O
C.1 -X- _ O
we -X- _ O
demonstrate -X- _ O
that -X- _ O
MLM -X- _ B-MethodName
does -X- _ O
converge -X- _ O
marginally -X- _ O
slower -X- _ O
than -X- _ O
a -X- _ O
left- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
model -X- _ O
( -X- _ O
which -X- _ O
predicts -X- _ O
every -X- _ O
token -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
empirical -X- _ O
improvements -X- _ O
of -X- _ O
the -X- _ O
MLM -X- _ B-MethodName
model -X- _ O
far -X- _ O
outweigh -X- _ O
the -X- _ O
increased -X- _ O
training -X- _ O
cost -X- _ O
. -X- _ O

Figure -X- _ O
3 -X- _ O
: -X- _ O
Differences -X- _ O
in -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
model -X- _ O
architectures -X- _ O
. -X- _ O
BERT -X- _ B-MethodName
uses -X- _ O
a -X- _ O
bidirectional -X- _ O
Transformer -X- _ O
. -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
uses -X- _ O
a -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
Transformer -X- _ O
. -X- _ O
ELMo -X- _ B-MethodName
uses -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
independently -X- _ O
trained -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
and -X- _ O
right -X- _ O
- -X- _ O
to- -X- _ O
left -X- _ O
LSTMs -X- _ B-MethodName
to -X- _ O
generate -X- _ O
features -X- _ O
for -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
Among -X- _ O
the -X- _ O
three -X- _ O
, -X- _ O
only -X- _ O
BERT -X- _ B-MethodName
representations -X- _ O
are -X- _ O
jointly -X- _ O
conditioned -X- _ O
on -X- _ O
both -X- _ O
left -X- _ O
and -X- _ O
right -X- _ O
context -X- _ O
in -X- _ O
all -X- _ O
layers -X- _ O
. -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
architecture -X- _ O
differences -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
are -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
approaches -X- _ O
, -X- _ O
while -X- _ O
ELMo -X- _ B-MethodName
is -X- _ O
a -X- _ O
feature -X- _ O
- -X- _ O
based -X- _ O
approach -X- _ O
. -X- _ O

The -X- _ O
advantage -X- _ O
of -X- _ O
this -X- _ O
procedure -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
Transformer -X- _ B-MethodName
encoder -X- _ O
does -X- _ O
not -X- _ O
know -X- _ O
which -X- _ O
words -X- _ O
it -X- _ O
will -X- _ O
be -X- _ O
asked -X- _ O
to -X- _ O
predict -X- _ O
or -X- _ O
which -X- _ O
have -X- _ O
been -X- _ O
re- -X- _ O
placed -X- _ O
by -X- _ O
random -X- _ O
words -X- _ O
, -X- _ O
so -X- _ O
it -X- _ O
is -X- _ O
forced -X- _ O
to -X- _ O
keep -X- _ O
a -X- _ O
distributional -X- _ O
contextual -X- _ O
representation -X- _ O
of -X- _ O
ev- -X- _ O
ery -X- _ O
input -X- _ O
token -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
because -X- _ O
random -X- _ O
replacement -X- _ O
only -X- _ O
occurs -X- _ O
for -X- _ O
1.5 -X- _ O
% -X- _ O
of -X- _ O
all -X- _ O
tokens -X- _ O
( -X- _ O
i.e. -X- _ O
, -X- _ O
10 -X- _ O
% -X- _ O
of -X- _ O
15 -X- _ O
% -X- _ O
) -X- _ O
, -X- _ O
this -X- _ O
does -X- _ O
not -X- _ O
seem -X- _ O
to -X- _ O
harm -X- _ O
the -X- _ O
model -X- _ O
’s -X- _ O
language -X- _ O
understanding -X- _ O
capability -X- _ O
. -X- _ O
In -X- _ O
Section -X- _ O
C.2 -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
impact -X- _ O
this -X- _ O
proce- -X- _ O
dure -X- _ O
. -X- _ O
Compared -X- _ O
to -X- _ O
standard -X- _ O
langauge -X- _ O
model -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
masked -X- _ B-MethodName
LM -X- _ I-MethodName
only -X- _ O
make -X- _ O
predictions -X- _ O
on -X- _ O
15 -X- _ O
% -X- _ O
of -X- _ O
tokens -X- _ O
in -X- _ O
each -X- _ O
batch -X- _ O
, -X- _ O
which -X- _ O
suggests -X- _ O
that -X- _ O
more -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
steps -X- _ O
may -X- _ O
be -X- _ O
required -X- _ O
for -X- _ O
the -X- _ O
model -X- _ O

is -X- _ O
hairy -X- _ O
. -X- _ O
The -X- _ O
purpose -X- _ O
of -X- _ O
this -X- _ O
is -X- _ O
to -X- _ O
bias -X- _ O
the -X- _ O
representation -X- _ O
towards -X- _ O
the -X- _ O
actual -X- _ O
observed -X- _ O
word -X- _ O
. -X- _ O

• -X- _ O
10 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
: -X- _ O
Keep -X- _ O
the -X- _ O
word -X- _ O
un- -X- _ O
changed -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
my -X- _ O
dog -X- _ O
is -X- _ O
hairy -X- _ O
→ -X- _ O
my -X- _ O
dog -X- _ O

• -X- _ O
10 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
: -X- _ O
Replace -X- _ O
the -X- _ O
word -X- _ O
with -X- _ O
a -X- _ O
random -X- _ O
word -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
my -X- _ O
dog -X- _ O
is -X- _ O
hairy -X- _ O
→ -X- _ O
my -X- _ O

• -X- _ O
80 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
: -X- _ O
Replace -X- _ O
the -X- _ O
word -X- _ O
with -X- _ O
the -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
token -X- _ O
, -X- _ O
e.g. -X- _ O
, -X- _ O
my -X- _ O
dog -X- _ O
is -X- _ O
hairy -X- _ O
→ -X- _ O

hairy -X- _ O
) -X- _ O
, -X- _ O
our -X- _ O
masking -X- _ O
procedure -X- _ O
can -X- _ O
be -X- _ O
further -X- _ O
il- -X- _ O
lustrated -X- _ O
by -X- _ O

hairy -X- _ O
, -X- _ O
and -X- _ O
during -X- _ O
the -X- _ O
random -X- _ O
masking -X- _ O
procedure -X- _ O
we -X- _ O
chose -X- _ O
the -X- _ O
4 -X- _ O
- -X- _ O
th -X- _ O
token -X- _ O
( -X- _ O
which -X- _ O
corresponding -X- _ O
to -X- _ O

Masked -X- _ B-MethodName
LM -X- _ I-MethodName
and -X- _ O
the -X- _ O
Masking -X- _ O
Procedure -X- _ O
As- -X- _ O
suming -X- _ O
the -X- _ O
unlabeled -X- _ O
sentence -X- _ O
is -X- _ O
my -X- _ O
dog -X- _ O
is -X- _ O

We -X- _ O
provide -X- _ O
examples -X- _ O
of -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
tasks -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
. -X- _ O

– -X- _ O
Effect -X- _ O
of -X- _ O
Number -X- _ O
of -X- _ O
Training -X- _ O
Steps -X- _ O
; -X- _ O
and -X- _ O
– -X- _ O
Ablation -X- _ O
for -X- _ O
Different -X- _ O
Masking -X- _ O
Proce- -X- _ O
dures -X- _ O
. -X- _ O

Yacine -X- _ O
Jernite -X- _ O
, -X- _ O
Samuel -X- _ O
R. -X- _ O
Bowman -X- _ O
, -X- _ O
and -X- _ O
David -X- _ O
Son- -X- _ O
tag -X- _ O
. -X- _ O
2017 -X- _ O
. -X- _ O
Discourse -X- _ O
- -X- _ O
based -X- _ O
objectives -X- _ O
for -X- _ O
fast -X- _ O
un- -X- _ O
supervised -X- _ O
sentence -X- _ O
representation -X- _ O
learning -X- _ O
. -X- _ O
CoRR -X- _ O
, -X- _ O
abs/1705.00557 -X- _ O
. -X- _ O

Minghao -X- _ O
Hu -X- _ O
, -X- _ O
Yuxing -X- _ O
Peng -X- _ O
, -X- _ O
Zhen -X- _ O
Huang -X- _ O
, -X- _ O
Xipeng -X- _ O
Qiu -X- _ O
, -X- _ O
Furu -X- _ O
Wei -X- _ O
, -X- _ O
and -X- _ O
Ming -X- _ O
Zhou -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O
Reinforced -X- _ O
mnemonic -X- _ O
reader -X- _ O
for -X- _ O
machine -X- _ O
reading -X- _ O
comprehen- -X- _ O
sion -X- _ O
. -X- _ O
In -X- _ O
IJCAI -X- _ O
. -X- _ O

Jeremy -X- _ O
Howard -X- _ O
and -X- _ O
Sebastian -X- _ O
Ruder -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O
Universal -X- _ O
language -X- _ O
model -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
for -X- _ O
text -X- _ B-TaskName
classiﬁcation -X- _ I-TaskName
. -X- _ O
In -X- _ O
ACL -X- _ O
. -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Felix -X- _ O
Hill -X- _ O
, -X- _ O
Kyunghyun -X- _ O
Cho -X- _ O
, -X- _ O
and -X- _ O
Anna -X- _ O
Korhonen -X- _ O
. -X- _ O
2016 -X- _ O
. -X- _ O
Learning -X- _ O
distributed -X- _ O
representations -X- _ O
of -X- _ O
sentences -X- _ O
from -X- _ O
unlabelled -X- _ O
data -X- _ O
. -X- _ O
In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2016 -X- _ O
Conference -X- _ O
of -X- _ O
the -X- _ O
North -X- _ O
American -X- _ O
Chapter -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
: -X- _ O
Human -X- _ O
Language -X- _ O
Technologies -X- _ O
. -X- _ O
Association -X- _ O
for -X- _ O
Computa- -X- _ O
tional -X- _ O
Linguistics -X- _ O
. -X- _ O

Dan -X- _ O
Hendrycks -X- _ O
and -X- _ O
Kevin -X- _ O
Gimpel -X- _ O
. -X- _ O
2016 -X- _ O
. -X- _ O
Bridging -X- _ O
nonlinearities -X- _ O
and -X- _ O
stochastic -X- _ O
regularizers -X- _ O
with -X- _ O
gaus- -X- _ O
sian -X- _ O
error -X- _ O
linear -X- _ O
units -X- _ O
. -X- _ O
CoRR -X- _ O
, -X- _ O
abs/1606.08415 -X- _ O
. -X- _ O

William -X- _ O
Fedus -X- _ O
, -X- _ O
Ian -X- _ O
Goodfellow -X- _ O
, -X- _ O
and -X- _ O
Andrew -X- _ O
M -X- _ O
Dai -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O
Maskgan -X- _ B-MethodName
: -X- _ O
Better -X- _ O
text -X- _ O
generation -X- _ O
via -X- _ O
ﬁlling -X- _ O
in -X- _ O
the -X- _ O
. -X- _ O
arXiv -X- _ O
preprint -X- _ O
arXiv:1801.07736 -X- _ O
. -X- _ O

William -X- _ O
B -X- _ O
Dolan -X- _ O
and -X- _ O
Chris -X- _ O
Brockett -X- _ O
. -X- _ O
2005 -X- _ O
. -X- _ O
Automati- -X- _ O
cally -X- _ O
constructing -X- _ O
a -X- _ O
corpus -X- _ O
of -X- _ O
sentential -X- _ O
paraphrases -X- _ O
. -X- _ O
In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
Third -X- _ O
International -X- _ O
Workshop -X- _ O
on -X- _ O
Paraphrasing -X- _ O
( -X- _ O
IWP2005 -X- _ O
) -X- _ O
. -X- _ O

J. -X- _ O
Deng -X- _ O
, -X- _ O
W. -X- _ O
Dong -X- _ O
, -X- _ O
R. -X- _ O
Socher -X- _ O
, -X- _ O
L.-J. -X- _ O
Li -X- _ O
, -X- _ O
K. -X- _ O
Li -X- _ O
, -X- _ O
and -X- _ O
L. -X- _ O
Fei- -X- _ O
Fei -X- _ O
. -X- _ O
2009 -X- _ O
. -X- _ O
ImageNet -X- _ B-DatasetName
: -X- _ O
A -X- _ O
Large -X- _ O
- -X- _ O
Scale -X- _ O
Hierarchical -X- _ O
Image -X- _ O
Database -X- _ O
. -X- _ O
In -X- _ O
CVPR09 -X- _ O
. -X- _ O

Andrew -X- _ O
M -X- _ O
Dai -X- _ O
and -X- _ O
Quoc -X- _ O
V -X- _ O
Le -X- _ O
. -X- _ O
2015 -X- _ O
. -X- _ O
Semi -X- _ O
- -X- _ O
supervised -X- _ O
sequence -X- _ O
learning -X- _ O
. -X- _ O
In -X- _ O
Advances -X- _ O
in -X- _ O
neural -X- _ O
informa- -X- _ O
tion -X- _ O
processing -X- _ O
systems -X- _ O
, -X- _ O
pages -X- _ O
3079–3087 -X- _ O
. -X- _ O

Alexis -X- _ O
Conneau -X- _ O
, -X- _ O
Douwe -X- _ O
Kiela -X- _ O
, -X- _ O
Holger -X- _ O
Schwenk -X- _ O
, -X- _ O
Lo¨ıc -X- _ O
Barrault -X- _ O
, -X- _ O
and -X- _ O
Antoine -X- _ O
Bordes -X- _ O
. -X- _ O
2017 -X- _ O
. -X- _ O
Supervised -X- _ O
learning -X- _ O
of -X- _ O
universal -X- _ O
sentence -X- _ O
representations -X- _ O
from -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
inference -X- _ I-TaskName
data -X- _ O
. -X- _ O
In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2017 -X- _ O
Conference -X- _ O
on -X- _ O
Empirical -X- _ O
Methods -X- _ O
in -X- _ O
Nat- -X- _ B-TaskName
ural -X- _ I-TaskName
Language -X- _ I-TaskName
Processing -X- _ I-TaskName
, -X- _ O
pages -X- _ O
670–680 -X- _ O
, -X- _ O
Copen- -X- _ O
hagen -X- _ O
, -X- _ O
Denmark -X- _ O
. -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
. -X- _ O

Ronan -X- _ O
Collobert -X- _ O
and -X- _ O
Jason -X- _ O
Weston -X- _ O
. -X- _ O
2008 -X- _ O
. -X- _ O
A -X- _ O
uniﬁed -X- _ O
architecture -X- _ O
for -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
processing -X- _ I-TaskName
: -X- _ O
Deep -X- _ O
neural -X- _ O
networks -X- _ O
with -X- _ O
multitask -X- _ O
learning -X- _ O
. -X- _ O
In -X- _ O
Pro- -X- _ O
ceedings -X- _ O
of -X- _ O
the -X- _ O
25th -X- _ O
international -X- _ O
conference -X- _ O
on -X- _ O
Machine -X- _ O
learning -X- _ O
, -X- _ O
pages -X- _ O
160–167 -X- _ O
. -X- _ O
ACM -X- _ O
. -X- _ O

Kevin -X- _ O
Clark -X- _ O
, -X- _ O
Minh -X- _ O
- -X- _ O
Thang -X- _ O
Luong -X- _ O
, -X- _ O
Christopher -X- _ O
D -X- _ O
Man- -X- _ O
ning -X- _ O
, -X- _ O
and -X- _ O
Quoc -X- _ O
Le -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O
Semi -X- _ O
- -X- _ O
supervised -X- _ O
se- -X- _ O
quence -X- _ O
modeling -X- _ O
with -X- _ O
cross -X- _ O
- -X- _ O
view -X- _ O
training -X- _ O
. -X- _ O
In -X- _ O
Pro- -X- _ O
ceedings -X- _ O
of -X- _ O
the -X- _ O
2018 -X- _ O
Conference -X- _ O
on -X- _ O
Empirical -X- _ O
Meth- -X- _ O
ods -X- _ O
in -X- _ O
Natural -X- _ B-TaskName
Language -X- _ I-TaskName
Processing -X- _ I-TaskName
, -X- _ O
pages -X- _ O
1914 -X- _ O
– -X- _ O
1925 -X- _ O
. -X- _ O

Christopher -X- _ O
Clark -X- _ O
and -X- _ O
Matt -X- _ O
Gardner -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O
Simple -X- _ O
and -X- _ O
effective -X- _ O
multi -X- _ O
- -X- _ O
paragraph -X- _ O
reading -X- _ O
comprehen- -X- _ O
sion -X- _ O
. -X- _ O
In -X- _ O
ACL -X- _ O
. -X- _ O

Ciprian -X- _ O
Chelba -X- _ O
, -X- _ O
Tomas -X- _ O
Mikolov -X- _ O
, -X- _ O
Mike -X- _ O
Schuster -X- _ O
, -X- _ O
Qi -X- _ O
Ge -X- _ O
, -X- _ O
Thorsten -X- _ O
Brants -X- _ O
, -X- _ O
Phillipp -X- _ O
Koehn -X- _ O
, -X- _ O
and -X- _ O
Tony -X- _ O
Robin- -X- _ O
son -X- _ O
. -X- _ O
2013 -X- _ O
. -X- _ O
One -X- _ O
billion -X- _ O
word -X- _ O
benchmark -X- _ O
for -X- _ O
measur- -X- _ O
ing -X- _ O
progress -X- _ O
in -X- _ O
statistical -X- _ O
language -X- _ O
modeling -X- _ O
. -X- _ O
arXiv -X- _ O
preprint -X- _ O
arXiv:1312.3005 -X- _ O
. -X- _ O

Daniel -X- _ O
Cer -X- _ O
, -X- _ O
Mona -X- _ O
Diab -X- _ O
, -X- _ O
Eneko -X- _ O
Agirre -X- _ O
, -X- _ O
Inigo -X- _ O
Lopez- -X- _ O
Gazpio -X- _ O
, -X- _ O
and -X- _ O
Lucia -X- _ O
Specia -X- _ O
. -X- _ O
2017 -X- _ O
. -X- _ O
Semeval-2017 -X- _ O
task -X- _ O
1 -X- _ O
: -X- _ O
Semantic -X- _ O
textual -X- _ O
similarity -X- _ O
multilingual -X- _ O
and -X- _ O
crosslingual -X- _ O
focused -X- _ O
evaluation -X- _ O
. -X- _ O
In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
11th -X- _ O
International -X- _ O
Workshop -X- _ O
on -X- _ O
Semantic -X- _ O
Evaluation -X- _ O
( -X- _ O
SemEval-2017 -X- _ O
) -X- _ O
, -X- _ O
pages -X- _ O
1–14 -X- _ O
, -X- _ O
Vancou- -X- _ O
ver -X- _ O
, -X- _ O
Canada -X- _ O
. -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Lin- -X- _ O
guistics -X- _ O
. -X- _ O

Peter -X- _ O
F -X- _ O
Brown -X- _ O
, -X- _ O
Peter -X- _ O
V -X- _ O
Desouza -X- _ O
, -X- _ O
Robert -X- _ O
L -X- _ O
Mercer -X- _ O
, -X- _ O
Vincent -X- _ O
J -X- _ O
Della -X- _ O
Pietra -X- _ O
, -X- _ O
and -X- _ O
Jenifer -X- _ O
C -X- _ O
Lai -X- _ O
. -X- _ O
1992 -X- _ O
. -X- _ O
Class -X- _ O
- -X- _ O
based -X- _ O
n -X- _ O
- -X- _ O
gram -X- _ O
models -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
. -X- _ O
Computational -X- _ O
linguistics -X- _ O
, -X- _ O
18(4):467–479 -X- _ O
. -X- _ O

Samuel -X- _ O
R. -X- _ O
Bowman -X- _ O
, -X- _ O
Gabor -X- _ O
Angeli -X- _ O
, -X- _ O
Christopher -X- _ O
Potts -X- _ O
, -X- _ O
and -X- _ O
Christopher -X- _ O
D. -X- _ O
Manning -X- _ O
. -X- _ O
2015 -X- _ O
. -X- _ O
A -X- _ O
large -X- _ O
anno- -X- _ O
tated -X- _ O
corpus -X- _ O
for -X- _ O
learning -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
inference -X- _ I-TaskName
. -X- _ O
In -X- _ O
EMNLP -X- _ B-TaskName
. -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Linguis- -X- _ O
tics -X- _ O
. -X- _ O

John -X- _ O
Blitzer -X- _ O
, -X- _ O
Ryan -X- _ O
McDonald -X- _ O
, -X- _ O
and -X- _ O
Fernando -X- _ O
Pereira -X- _ O
. -X- _ O
2006 -X- _ O
. -X- _ O
Domain -X- _ O
adaptation -X- _ O
with -X- _ O
structural -X- _ O
correspon- -X- _ O
dence -X- _ O
learning -X- _ O
. -X- _ O
In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2006 -X- _ O
confer- -X- _ O
ence -X- _ O
on -X- _ O
empirical -X- _ O
methods -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
pro- -X- _ O
cessing -X- _ O
, -X- _ O
pages -X- _ O
120–128 -X- _ O
. -X- _ O
Association -X- _ O
for -X- _ O
Computa- -X- _ O
tional -X- _ O
Linguistics -X- _ O
. -X- _ O

Luisa -X- _ O
Bentivogli -X- _ O
, -X- _ O
Bernardo -X- _ O
Magnini -X- _ O
, -X- _ O
Ido -X- _ O
Dagan -X- _ O
, -X- _ O
Hoa -X- _ O
Trang -X- _ O
Dang -X- _ O
, -X- _ O
and -X- _ O
Danilo -X- _ O
Giampiccolo -X- _ O
. -X- _ O
2009 -X- _ O
. -X- _ O
The -X- _ O
ﬁfth -X- _ O
PASCAL -X- _ O
recognizing -X- _ O
textual -X- _ O
entailment -X- _ O
challenge -X- _ O
. -X- _ O
In -X- _ O
TAC -X- _ O
. -X- _ O
NIST -X- _ O
. -X- _ O

Rie -X- _ O
Kubota -X- _ O
Ando -X- _ O
and -X- _ O
Tong -X- _ O
Zhang -X- _ O
. -X- _ O
2005 -X- _ O
. -X- _ O
A -X- _ O
framework -X- _ O
for -X- _ O
learning -X- _ O
predictive -X- _ O
structures -X- _ O
from -X- _ O
multiple -X- _ O
tasks -X- _ O
and -X- _ O
unlabeled -X- _ O
data -X- _ O
. -X- _ O
Journal -X- _ O
of -X- _ O
Machine -X- _ O
Learning -X- _ O
Research -X- _ O
, -X- _ O
6(Nov):1817–1853 -X- _ O
. -X- _ O

Rami -X- _ O
Al -X- _ O
- -X- _ O
Rfou -X- _ O
, -X- _ O
Dokook -X- _ O
Choe -X- _ O
, -X- _ O
Noah -X- _ O
Constant -X- _ O
, -X- _ O
Mandy -X- _ O
Guo -X- _ O
, -X- _ O
and -X- _ O
Llion -X- _ O
Jones -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O
Character -X- _ O
- -X- _ O
level -X- _ O
lan- -X- _ O
guage -X- _ O
modeling -X- _ O
with -X- _ O
deeper -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
. -X- _ O
arXiv -X- _ O
preprint -X- _ O
arXiv:1808.04444 -X- _ O
. -X- _ O

Alan -X- _ O
Akbik -X- _ O
, -X- _ O
Duncan -X- _ O
Blythe -X- _ O
, -X- _ O
and -X- _ O
Roland -X- _ O
Vollgraf -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O
Contextual -X- _ O
string -X- _ O
embeddings -X- _ O
for -X- _ O
sequence -X- _ O
labeling -X- _ O
. -X- _ O
In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
27th -X- _ O
International -X- _ O
Conference -X- _ O
on -X- _ O
Computational -X- _ O
Linguistics -X- _ O
, -X- _ O
pages -X- _ O
1638–1649 -X- _ O
. -X- _ O

Recent -X- _ O
empirical -X- _ O
improvements -X- _ O
due -X- _ O
to -X- _ O
transfer -X- _ O
learning -X- _ O
with -X- _ O
language -X- _ O
models -X- _ O
have -X- _ O
demonstrated -X- _ O
that -X- _ O
rich -X- _ O
, -X- _ O
unsupervised -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
is -X- _ O
an -X- _ O
integral -X- _ O
part -X- _ O
of -X- _ O
many -X- _ O
language -X- _ O
understanding -X- _ O
systems -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
these -X- _ O
results -X- _ O
enable -X- _ O
even -X- _ O
low -X- _ O
- -X- _ O
resource -X- _ O
tasks -X- _ O
to -X- _ O
beneﬁt -X- _ O
from -X- _ O
deep -X- _ O
unidirectional -X- _ O
architec- -X- _ O
tures -X- _ O
. -X- _ O
Our -X- _ O
major -X- _ O
contribution -X- _ O
is -X- _ O
further -X- _ O
general- -X- _ O
izing -X- _ O
these -X- _ O
ﬁndings -X- _ O
to -X- _ O
deep -X- _ O
bidirectional -X- _ O
architec- -X- _ O
tures -X- _ O
, -X- _ O
allowing -X- _ O
the -X- _ O
same -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
to -X- _ O
suc- -X- _ O
cessfully -X- _ O
tackle -X- _ O
a -X- _ O
broad -X- _ O
set -X- _ O
of -X- _ O
NLP -X- _ B-TaskName
tasks -X- _ O
. -X- _ O

Results -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
7 -X- _ O
. -X- _ O
BERTLARGE -X- _ B-MethodName
performs -X- _ O
competitively -X- _ O
with -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
meth- -X- _ O
ods -X- _ O
. -X- _ O
The -X- _ O
best -X- _ O
performing -X- _ O
method -X- _ O
concatenates -X- _ O
the -X- _ O
token -X- _ O
representations -X- _ O
from -X- _ O
the -X- _ O
top -X- _ O
four -X- _ O
hidden -X- _ O
lay- -X- _ O
ers -X- _ O
of -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
Transformer -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
only -X- _ O
0.3 -X- _ B-MetricValue
F1 -X- _ B-MetricName
behind -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
the -X- _ O
entire -X- _ O
model -X- _ O
. -X- _ O
This -X- _ O
demonstrates -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
effective -X- _ O
for -X- _ O
both -X- _ O
ﬁne- -X- _ O
tuning -X- _ O
and -X- _ O
feature -X- _ O
- -X- _ O
based -X- _ O
approaches -X- _ O
. -X- _ O

To -X- _ O
ablate -X- _ O
the -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
approach -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
the -X- _ O
feature -X- _ O
- -X- _ O
based -X- _ O
approach -X- _ O
by -X- _ O
extracting -X- _ O
the -X- _ O
activa- -X- _ O
tions -X- _ O
from -X- _ O
one -X- _ O
or -X- _ O
more -X- _ O
layers -X- _ O
without -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
any -X- _ O
parameters -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
These -X- _ O
contextual -X- _ O
em- -X- _ O
beddings -X- _ O
are -X- _ O
used -X- _ O
as -X- _ O
input -X- _ O
to -X- _ O
a -X- _ O
randomly -X- _ O
initial- -X- _ O
ized -X- _ O
two -X- _ O
- -X- _ O
layer -X- _ O
768 -X- _ O
- -X- _ O
dimensional -X- _ O
BiLSTM -X- _ B-MethodName
before -X- _ O
the -X- _ O
classiﬁcation -X- _ O
layer -X- _ O
. -X- _ O

layer -X- _ O
in -X- _ O
the -X- _ O
output -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
ﬁrst -X- _ O
sub -X- _ O
- -X- _ O
token -X- _ O
as -X- _ O
the -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
classiﬁer -X- _ O
over -X- _ O
the -X- _ O
NER -X- _ B-TaskName
label -X- _ O
set -X- _ O
. -X- _ O

Table -X- _ O
7 -X- _ O
: -X- _ O
CoNLL-2003 -X- _ O
Named -X- _ B-TaskName
Entity -X- _ I-TaskName
Recognition -X- _ I-TaskName
re- -X- _ O
sults -X- _ O
. -X- _ O
Hyperparameters -X- _ O
were -X- _ O
selected -X- _ O
using -X- _ O
the -X- _ O
Dev -X- _ O
set -X- _ O
. -X- _ O
The -X- _ O
reported -X- _ O
Dev -X- _ O
and -X- _ O
Test -X- _ O
scores -X- _ O
are -X- _ O
averaged -X- _ O
over -X- _ O
5 -X- _ O
random -X- _ O
restarts -X- _ O
using -X- _ O
those -X- _ O
hyperparameters -X- _ O
. -X- _ O

Feature -X- _ O
- -X- _ O
based -X- _ O
approach -X- _ O
( -X- _ O
BERTBASE -X- _ B-MethodName
) -X- _ O
Embeddings -X- _ O
91.0 -X- _ O
- -X- _ O
Second -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
Last -X- _ O
Hidden -X- _ O
95.6 -X- _ O
- -X- _ O
Last -X- _ O
Hidden -X- _ O
94.9 -X- _ O
- -X- _ O
Weighted -X- _ O
Sum -X- _ O
Last -X- _ O
Four -X- _ O
Hidden -X- _ O
95.9 -X- _ O
- -X- _ O
Concat -X- _ O
Last -X- _ O
Four -X- _ O
Hidden -X- _ O
96.1 -X- _ O
- -X- _ O
Weighted -X- _ O
Sum -X- _ O
All -X- _ O
12 -X- _ O
Layers -X- _ O
95.5 -X- _ O
- -X- _ O

Fine -X- _ O
- -X- _ O
tuning -X- _ O
approach -X- _ O
BERTLARGE -X- _ B-MethodName
96.6 -X- _ O
92.8 -X- _ O
BERTBASE -X- _ B-MethodName
96.4 -X- _ O
92.4 -X- _ O

ELMo -X- _ B-MethodName
( -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
95.7 -X- _ O
92.2 -X- _ O
CVT -X- _ B-MethodName
( -X- _ O
Clark -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
- -X- _ O
92.6 -X- _ O
CSE -X- _ B-MethodName
( -X- _ O
Akbik -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
- -X- _ O
93.1 -X- _ O

3 -X- _ O
768 -X- _ O
12 -X- _ O
5.84 -X- _ O
77.9 -X- _ O
79.8 -X- _ O
88.4 -X- _ O
6 -X- _ O
768 -X- _ O
3 -X- _ O
5.24 -X- _ O
80.6 -X- _ O
82.2 -X- _ O
90.7 -X- _ O
6 -X- _ O
768 -X- _ O
12 -X- _ O
4.68 -X- _ O
81.9 -X- _ O
84.8 -X- _ O
91.3 -X- _ O
12 -X- _ O
768 -X- _ O
12 -X- _ O
3.99 -X- _ O
84.4 -X- _ O
86.7 -X- _ O
92.9 -X- _ O
12 -X- _ O
1024 -X- _ O
16 -X- _ O
3.54 -X- _ O
85.7 -X- _ O
86.9 -X- _ O
93.3 -X- _ O
24 -X- _ O
1024 -X- _ O
16 -X- _ O
3.23 -X- _ O
86.6 -X- _ O
87.8 -X- _ O
93.7 -X- _ O

All -X- _ O
of -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
results -X- _ O
presented -X- _ O
so -X- _ O
far -X- _ O
have -X- _ O
used -X- _ O
the -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
approach -X- _ O
, -X- _ O
where -X- _ O
a -X- _ O
simple -X- _ O
classiﬁ- -X- _ O
cation -X- _ O
layer -X- _ O
is -X- _ O
added -X- _ O
to -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
all -X- _ O
parameters -X- _ O
are -X- _ O
jointly -X- _ O
ﬁne -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
a -X- _ O
down- -X- _ O
stream -X- _ O
task -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
the -X- _ O
feature -X- _ O
- -X- _ O
based -X- _ O
approach -X- _ O
, -X- _ O
where -X- _ O
ﬁxed -X- _ O
features -X- _ O
are -X- _ O
extracted -X- _ O
from -X- _ O
the -X- _ O
pre- -X- _ O
trained -X- _ O
model -X- _ O
, -X- _ O
has -X- _ O
certain -X- _ O
advantages -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
not -X- _ O
all -X- _ O
tasks -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
represented -X- _ O
by -X- _ O
a -X- _ O
Trans- -X- _ O
former -X- _ O
encoder -X- _ O
architecture -X- _ O
, -X- _ O
and -X- _ O
therefore -X- _ O
require -X- _ O
a -X- _ O
task -X- _ O
- -X- _ O
speciﬁc -X- _ O
model -X- _ O
architecture -X- _ O
to -X- _ O
be -X- _ O
added -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
major -X- _ O
computational -X- _ O
beneﬁts -X- _ O
to -X- _ O
pre -X- _ O
- -X- _ O
compute -X- _ O
an -X- _ O
expensive -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
once -X- _ O
and -X- _ O
then -X- _ O
run -X- _ O
many -X- _ O
experiments -X- _ O
with -X- _ O
cheaper -X- _ O
models -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
this -X- _ O
representation -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
the -X- _ O
two -X- _ O
approaches -X- _ O
by -X- _ O
applying -X- _ O
BERT -X- _ B-MethodName
to -X- _ O
the -X- _ O
CoNLL-2003 -X- _ O
Named -X- _ B-TaskName
Entity -X- _ I-TaskName
Recognition -X- _ I-TaskName
( -X- _ O
NER -X- _ B-MethodName
) -X- _ O
task -X- _ O
( -X- _ O
Tjong -X- _ O
Kim -X- _ O
Sang -X- _ O
and -X- _ O
De -X- _ O
Meulder -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
the -X- _ O
input -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
case -X- _ O
- -X- _ O
preserving -X- _ O
WordPiece -X- _ O
model -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
include -X- _ O
the -X- _ O
maximal -X- _ O
document -X- _ O
context -X- _ O
provided -X- _ O
by -X- _ O
the -X- _ O
data -X- _ O
. -X- _ O
Following -X- _ O
standard -X- _ O
practice -X- _ O
, -X- _ O
we -X- _ O
for- -X- _ O
mulate -X- _ O
this -X- _ O
as -X- _ O
a -X- _ O
tagging -X- _ O
task -X- _ O
but -X- _ O
do -X- _ O
not -X- _ O
use -X- _ O
a -X- _ O
CRF -X- _ O

mixed -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
downstream -X- _ O
task -X- _ O
impact -X- _ O
of -X- _ O
increasing -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
bi -X- _ O
- -X- _ O
LM -X- _ B-MethodName
size -X- _ O
from -X- _ O
two -X- _ O
to -X- _ O
four -X- _ O
layers -X- _ O
and -X- _ O
Melamud -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
men- -X- _ O
tioned -X- _ O
in -X- _ O
passing -X- _ O
that -X- _ O
increasing -X- _ O
hidden -X- _ O
dimen- -X- _ O
sion -X- _ O
size -X- _ O
from -X- _ O
200 -X- _ O
to -X- _ O
600 -X- _ O
helped -X- _ O
, -X- _ O
but -X- _ O
increasing -X- _ O
further -X- _ O
to -X- _ O
1,000 -X- _ O
did -X- _ O
not -X- _ O
bring -X- _ O
further -X- _ O
improve- -X- _ O
ments -X- _ O
. -X- _ O
Both -X- _ O
of -X- _ O
these -X- _ O
prior -X- _ O
works -X- _ O
used -X- _ O
a -X- _ O
feature- -X- _ O
based -X- _ O
approach -X- _ O
— -X- _ O
we -X- _ O
hypothesize -X- _ O
that -X- _ O
when -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
ﬁne -X- _ O
- -X- _ O
tuned -X- _ O
directly -X- _ O
on -X- _ O
the -X- _ O
downstream -X- _ O
tasks -X- _ O
and -X- _ O
uses -X- _ O
only -X- _ O
a -X- _ O
very -X- _ O
small -X- _ O
number -X- _ O
of -X- _ O
ran- -X- _ O
domly -X- _ O
initialized -X- _ O
additional -X- _ O
parameters -X- _ O
, -X- _ O
the -X- _ O
task- -X- _ O
speciﬁc -X- _ O
models -X- _ O
can -X- _ O
beneﬁt -X- _ O
from -X- _ O
the -X- _ O
larger -X- _ O
, -X- _ O
more -X- _ O
expressive -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
representations -X- _ O
even -X- _ O
when -X- _ O
downstream -X- _ O
task -X- _ O
data -X- _ O
is -X- _ O
very -X- _ O
small -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
explore -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
model -X- _ O
size -X- _ O
on -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
task -X- _ O
accuracy -X- _ O
. -X- _ O
We -X- _ O
trained -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
models -X- _ O
with -X- _ O
a -X- _ O
differing -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
, -X- _ O
hidden -X- _ B-HyperparameterName
units -X- _ I-HyperparameterName
, -X- _ O
and -X- _ O
attention -X- _ B-HyperparameterName
heads -X- _ I-HyperparameterName
, -X- _ O
while -X- _ O
otherwise -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
hyperparameters -X- _ O
and -X- _ O
training -X- _ O
pro- -X- _ O
cedure -X- _ O
as -X- _ O
described -X- _ O
previously -X- _ O
. -X- _ O
Results -X- _ O
on -X- _ O
selected -X- _ O
GLUE -X- _ B-TaskName
tasks -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
table -X- _ O
, -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
average -X- _ O
Dev -X- _ O
Set -X- _ O
accuracy -X- _ O
from -X- _ O
5 -X- _ O
random -X- _ O
restarts -X- _ O
of -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O
We -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
larger -X- _ O
models -X- _ O
lead -X- _ O
to -X- _ O
a -X- _ O
strict -X- _ O
ac- -X- _ O
curacy -X- _ O
improvement -X- _ O
across -X- _ O
all -X- _ O
four -X- _ O
datasets -X- _ O
, -X- _ O
even -X- _ O
for -X- _ O
MRPC -X- _ B-DatasetName
which -X- _ O
only -X- _ O
has -X- _ O
3,600 -X- _ O
labeled -X- _ O
train- -X- _ O
ing -X- _ O
examples -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
substantially -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
tasks -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
also -X- _ O
perhaps -X- _ O
surpris- -X- _ O
ing -X- _ O
that -X- _ O
we -X- _ O
are -X- _ O
able -X- _ O
to -X- _ O
achieve -X- _ O
such -X- _ O
signiﬁcant -X- _ O
improvements -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
models -X- _ O
which -X- _ O
are -X- _ O
al- -X- _ O
ready -X- _ O
quite -X- _ O
large -X- _ O
relative -X- _ O
to -X- _ O
the -X- _ O
existing -X- _ O
literature -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
largest -X- _ O
Transformer -X- _ O
explored -X- _ O
in -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
is -X- _ O
( -X- _ O
L=6 -X- _ B-HyperparameterName
, -X- _ O
H=1024 -X- _ B-HyperparameterName
, -X- _ O
A=16 -X- _ B-HyperparameterName
) -X- _ O
with -X- _ O
100 -X- _ O
M -X- _ O
parameters -X- _ O
for -X- _ O
the -X- _ O
encoder -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
largest -X- _ O
Transformer -X- _ O
we -X- _ O
have -X- _ O
found -X- _ O
in -X- _ O
the -X- _ O
literature -X- _ O
is -X- _ O
( -X- _ O
L=64 -X- _ B-HyperparameterName
, -X- _ O
H=512 -X- _ B-HyperparameterName
, -X- _ O
A=2 -X- _ B-HyperparameterName
) -X- _ O
with -X- _ O
235 -X- _ O
M -X- _ O
parameters -X- _ O
( -X- _ O
Al -X- _ O
- -X- _ O
Rfou -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
By -X- _ O
contrast -X- _ O
, -X- _ O
BERTBASE -X- _ B-MethodName
contains -X- _ O
110 -X- _ O
M -X- _ O
parameters -X- _ O
and -X- _ O
BERTLARGE -X- _ B-MethodName
con- -X- _ O
tains -X- _ O
340 -X- _ O
M -X- _ O
parameters -X- _ O
. -X- _ O
It -X- _ O
has -X- _ O
long -X- _ O
been -X- _ O
known -X- _ O
that -X- _ O
increasing -X- _ O
the -X- _ O
model -X- _ O
size -X- _ O
will -X- _ O
lead -X- _ O
to -X- _ O
continual -X- _ O
improvements -X- _ O
on -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
machine -X- _ O
translation -X- _ O
and -X- _ O
language -X- _ O
modeling -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
demonstrated -X- _ O
by -X- _ O
the -X- _ O
LM -X- _ B-MethodName
perplexity -X- _ O
of -X- _ O
held -X- _ O
- -X- _ O
out -X- _ O
training -X- _ O
data -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
believe -X- _ O
that -X- _ O
this -X- _ O
is -X- _ O
the -X- _ O
ﬁrst -X- _ O
work -X- _ O
to -X- _ O
demonstrate -X- _ O
convinc- -X- _ O
ingly -X- _ O
that -X- _ O
scaling -X- _ O
to -X- _ O
extreme -X- _ O
model -X- _ O
sizes -X- _ O
also -X- _ O
leads -X- _ O
to -X- _ O
large -X- _ O
improvements -X- _ O
on -X- _ O
very -X- _ O
small -X- _ O
scale -X- _ O
tasks -X- _ O
, -X- _ O
provided -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
has -X- _ O
been -X- _ O
sufﬁ- -X- _ O
ciently -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
. -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018b -X- _ O
) -X- _ O
presented -X- _ O

results -X- _ O
are -X- _ O
still -X- _ O
far -X- _ O
worse -X- _ O
than -X- _ O
those -X- _ O
of -X- _ O
the -X- _ O
pre- -X- _ O
trained -X- _ O
bidirectional -X- _ O
models -X- _ O
. -X- _ O
The -X- _ O
BiLSTM -X- _ B-MethodName
hurts -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
GLUE -X- _ B-TaskName
tasks -X- _ O
. -X- _ O
We -X- _ O
recognize -X- _ O
that -X- _ O
it -X- _ O
would -X- _ O
also -X- _ O
be -X- _ O
possible -X- _ O
to -X- _ O
train -X- _ O
separate -X- _ O
LTR -X- _ O
and -X- _ O
RTL -X- _ O
models -X- _ O
and -X- _ O
represent -X- _ O
each -X- _ O
token -X- _ O
as -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
mod- -X- _ O
els -X- _ O
, -X- _ O
as -X- _ O
ELMo -X- _ B-MethodName
does -X- _ O
. -X- _ O
However -X- _ O
: -X- _ O
( -X- _ O
a -X- _ O
) -X- _ O
this -X- _ O
is -X- _ O
twice -X- _ O
as -X- _ O
expensive -X- _ O
as -X- _ O
a -X- _ O
single -X- _ O
bidirectional -X- _ O
model -X- _ O
; -X- _ O
( -X- _ O
b -X- _ O
) -X- _ O
this -X- _ O
is -X- _ O
non -X- _ O
- -X- _ O
intuitive -X- _ O
for -X- _ O
tasks -X- _ O
like -X- _ O
QA -X- _ B-TaskName
, -X- _ O
since -X- _ O
the -X- _ O
RTL -X- _ O
model -X- _ O
would -X- _ O
not -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
condition -X- _ O
the -X- _ O
answer -X- _ O
on -X- _ O
the -X- _ O
question -X- _ O
; -X- _ O
( -X- _ O
c -X- _ O
) -X- _ O
this -X- _ O
it -X- _ O
is -X- _ O
strictly -X- _ O
less -X- _ O
powerful -X- _ O
than -X- _ O
a -X- _ O
deep -X- _ O
bidirectional -X- _ O
model -X- _ O
, -X- _ O
since -X- _ O
it -X- _ O
can -X- _ O
use -X- _ O
both -X- _ O
left -X- _ O
and -X- _ O
right -X- _ O
context -X- _ O
at -X- _ O
every -X- _ O
layer -X- _ O
. -X- _ O

No -X- _ O
NSP -X- _ B-TaskName
: -X- _ O
A -X- _ O
bidirectional -X- _ O
model -X- _ O
which -X- _ O
is -X- _ O
trained -X- _ O
using -X- _ O
the -X- _ O
“ -X- _ O
masked -X- _ B-MethodName
LM -X- _ I-MethodName
” -X- _ O
( -X- _ O
MLM -X- _ B-MethodName
) -X- _ O
but -X- _ O
without -X- _ O
the -X- _ O
“ -X- _ O
next -X- _ B-TaskName
sentence -X- _ I-TaskName
prediction -X- _ I-TaskName
” -X- _ O
( -X- _ O
NSP -X- _ B-TaskName
) -X- _ O
task -X- _ O
. -X- _ O
LTR -X- _ O
& -X- _ O
No -X- _ O
NSP -X- _ B-TaskName
: -X- _ O
A -X- _ O
left -X- _ O
- -X- _ O
context -X- _ O
- -X- _ O
only -X- _ O
model -X- _ O
which -X- _ O
is -X- _ O
trained -X- _ O
using -X- _ O
a -X- _ O
standard -X- _ O
Left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
Right -X- _ O
( -X- _ O
LTR -X- _ O
) -X- _ O
LM -X- _ B-MethodName
, -X- _ O
rather -X- _ O
than -X- _ O
an -X- _ O
MLM -X- _ B-MethodName
. -X- _ O
The -X- _ O
left -X- _ O
- -X- _ O
only -X- _ O
constraint -X- _ O
was -X- _ O
also -X- _ O
applied -X- _ O
at -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
because -X- _ O
removing -X- _ O
it -X- _ O
introduced -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
train/ﬁne -X- _ O
- -X- _ O
tune -X- _ O
mismatch -X- _ O
that -X- _ O
degraded -X- _ O
downstream -X- _ O
performance -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
this -X- _ O
model -X- _ O
was -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
without -X- _ O
the -X- _ O
NSP -X- _ B-TaskName
task -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
directly -X- _ O
comparable -X- _ O
to -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
, -X- _ O
but -X- _ O
using -X- _ O
our -X- _ O
larger -X- _ O
training -X- _ O
dataset -X- _ O
, -X- _ O
our -X- _ O
input -X- _ O
repre- -X- _ O
sentation -X- _ O
, -X- _ O
and -X- _ O
our -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
scheme -X- _ O
. -X- _ O
We -X- _ O
ﬁrst -X- _ O
examine -X- _ O
the -X- _ O
impact -X- _ O
brought -X- _ O
by -X- _ O
the -X- _ O
NSP -X- _ B-TaskName
task -X- _ O
. -X- _ O
In -X- _ O
Table -X- _ O
5 -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
removing -X- _ O
NSP -X- _ B-TaskName
hurts -X- _ O
performance -X- _ O
signiﬁcantly -X- _ O
on -X- _ O
QNLI -X- _ B-TaskName
, -X- _ O
MNLI -X- _ B-TaskName
, -X- _ O
and -X- _ O
SQuAD -X- _ B-DatasetName
1.1 -X- _ I-DatasetName
. -X- _ O
Next -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
training -X- _ O
bidirectional -X- _ O
representations -X- _ O
by -X- _ O
com- -X- _ O
paring -X- _ O
“ -X- _ O
No -X- _ O
NSP -X- _ B-DatasetName
” -X- _ O
to -X- _ O
“ -X- _ O
LTR -X- _ O
& -X- _ O
No -X- _ O
NSP -X- _ B-TaskName
” -X- _ O
. -X- _ O
The -X- _ O
LTR -X- _ O
model -X- _ O
performs -X- _ O
worse -X- _ O
than -X- _ O
the -X- _ O
MLM -X- _ O
model -X- _ O
on -X- _ O
all -X- _ O
tasks -X- _ O
, -X- _ O
with -X- _ O
large -X- _ O
drops -X- _ O
on -X- _ O
MRPC -X- _ O
and -X- _ O
SQuAD -X- _ B-DatasetName
. -X- _ O
For -X- _ O
SQuAD -X- _ B-DatasetName
it -X- _ O
is -X- _ O
intuitively -X- _ O
clear -X- _ O
that -X- _ O
a -X- _ O
LTR -X- _ O
model -X- _ O
will -X- _ O
perform -X- _ O
poorly -X- _ O
at -X- _ O
token -X- _ O
predictions -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
hidden -X- _ O
states -X- _ O
have -X- _ O
no -X- _ O
right- -X- _ O
side -X- _ O
context -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
make -X- _ O
a -X- _ O
good -X- _ O
faith -X- _ O
at- -X- _ O
tempt -X- _ O
at -X- _ O
strengthening -X- _ O
the -X- _ O
LTR -X- _ O
system -X- _ O
, -X- _ O
we -X- _ O
added -X- _ O
a -X- _ O
randomly -X- _ O
initialized -X- _ O
BiLSTM -X- _ B-MethodName
on -X- _ O
top -X- _ O
. -X- _ O
This -X- _ O
does -X- _ O
signiﬁcantly -X- _ O
improve -X- _ O
results -X- _ O
on -X- _ O
SQuAD -X- _ B-DatasetName
, -X- _ O
but -X- _ O
the -X- _ O

We -X- _ O
demonstrate -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
the -X- _ O
deep -X- _ O
bidi- -X- _ O
rectionality -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
by -X- _ O
evaluating -X- _ O
two -X- _ O
pre- -X- _ O
training -X- _ O
objectives -X- _ O
using -X- _ O
exactly -X- _ O
the -X- _ O
same -X- _ O
pre- -X- _ O
training -X- _ O
data -X- _ O
, -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
scheme -X- _ O
, -X- _ O
and -X- _ O
hyperpa- -X- _ O
rameters -X- _ O
as -X- _ O
BERTBASE -X- _ B-MethodName
: -X- _ O

Table -X- _ O
5 -X- _ O
: -X- _ O
Ablation -X- _ O
over -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
tasks -X- _ O
using -X- _ O
the -X- _ O
BERTBASE -X- _ B-MethodName
architecture -X- _ O
. -X- _ O
“ -X- _ O
No -X- _ O
NSP -X- _ B-TaskName
” -X- _ O
is -X- _ O
trained -X- _ O
without -X- _ O
the -X- _ O
next -X- _ O
sentence -X- _ O
prediction -X- _ O
task -X- _ O
. -X- _ O
“ -X- _ O
LTR -X- _ B-TaskName
& -X- _ O
No -X- _ O
NSP -X- _ O
” -X- _ O
is -X- _ O
trained -X- _ O
as -X- _ O
a -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
LM -X- _ O
without -X- _ O
the -X- _ O
next -X- _ O
sentence -X- _ O
prediction -X- _ O
, -X- _ O
like -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
. -X- _ O
“ -X- _ O
+ -X- _ O
BiLSTM -X- _ B-MethodName
” -X- _ O
adds -X- _ O
a -X- _ O
ran- -X- _ O
domly -X- _ O
initialized -X- _ O
BiLSTM -X- _ B-MethodName
on -X- _ O
top -X- _ O
of -X- _ O
the -X- _ O
“ -X- _ O
LTR -X- _ B-TaskName
+ -X- _ O
No -X- _ O
NSP -X- _ B-TaskName
” -X- _ O
model -X- _ O
during -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O

BERTBASE -X- _ B-MethodName
84.4 -X- _ O
88.4 -X- _ O
86.7 -X- _ O
92.7 -X- _ O
88.5 -X- _ O
No -X- _ O
NSP -X- _ B-TaskName
83.9 -X- _ O
84.9 -X- _ O
86.5 -X- _ O
92.6 -X- _ O
87.9 -X- _ O
LTR -X- _ O
& -X- _ O
No -X- _ O
NSP -X- _ B-TaskName
82.1 -X- _ O
84.3 -X- _ O
77.5 -X- _ O
92.1 -X- _ O
77.8 -X- _ O
+ -X- _ O
BiLSTM -X- _ B-MethodName
82.1 -X- _ O
84.1 -X- _ O
75.7 -X- _ O
91.6 -X- _ O
84.9 -X- _ O

Dev -X- _ O
Set -X- _ O
Tasks -X- _ O
MNLI -X- _ B-DatasetName
- -X- _ I-DatasetName
m -X- _ I-DatasetName
QNLI -X- _ B-DatasetName
MRPC -X- _ B-DatasetName
SST-2 -X- _ B-DatasetName
SQuAD -X- _ B-DatasetName
( -X- _ O
Acc -X- _ B-MetricName
) -X- _ O
( -X- _ O
Acc -X- _ B-MetricName
) -X- _ O
( -X- _ O
Acc -X- _ B-MetricName
) -X- _ O
( -X- _ O
Acc -X- _ B-MetricName
) -X- _ O
( -X- _ O
F1 -X- _ B-MetricName
) -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
perform -X- _ O
ablation -X- _ O
experiments -X- _ O
over -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
facets -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
in -X- _ O
order -X- _ O
to -X- _ O
better -X- _ O
understand -X- _ O
their -X- _ O
relative -X- _ O
importance -X- _ O
. -X- _ O
Additional -X- _ O

The -X- _ O
Situations -X- _ B-DatasetName
With -X- _ I-DatasetName
Adversarial -X- _ I-DatasetName
Generations -X- _ I-DatasetName
( -X- _ O
SWAG -X- _ B-DatasetName
) -X- _ O
dataset -X- _ O
contains -X- _ O
113k -X- _ O
sentence -X- _ O
- -X- _ O
pair -X- _ O
com- -X- _ O
pletion -X- _ O
examples -X- _ O
that -X- _ O
evaluate -X- _ O
grounded -X- _ O
common- -X- _ O
sense -X- _ O
inference -X- _ O
( -X- _ O
Zellers -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Given -X- _ O
a -X- _ O
sen- -X- _ O
tence -X- _ O
, -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
choose -X- _ O
the -X- _ O
most -X- _ O
plausible -X- _ O
con- -X- _ O
tinuation -X- _ O
among -X- _ O
four -X- _ O
choices -X- _ O
. -X- _ O
When -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
the -X- _ O
SWAG -X- _ B-DatasetName
dataset -X- _ O
, -X- _ O
we -X- _ O
construct -X- _ O
four -X- _ O
input -X- _ O
sequences -X- _ O
, -X- _ O
each -X- _ O
containing -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
the -X- _ O
given -X- _ O
sentence -X- _ O
( -X- _ O
sentence -X- _ O
A -X- _ O
) -X- _ O
and -X- _ O
a -X- _ O
possible -X- _ O
continuation -X- _ O
( -X- _ O
sentence -X- _ O
B -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
only -X- _ O
task -X- _ O
- -X- _ O
speciﬁc -X- _ O
parameters -X- _ O
introduced -X- _ O
is -X- _ O
a -X- _ O
vec- -X- _ O
tor -X- _ O
whose -X- _ O
dot -X- _ O
product -X- _ O
with -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
rep- -X- _ O
resentation -X- _ O
C -X- _ O
denotes -X- _ O
a -X- _ O
score -X- _ O
for -X- _ O
each -X- _ O
choice -X- _ O
which -X- _ O
is -X- _ O
normalized -X- _ O
with -X- _ O
a -X- _ O
softmax -X- _ O
layer -X- _ O
. -X- _ O
We -X- _ O
ﬁne -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
model -X- _ O
for -X- _ O
3 -X- _ O
epochs -X- _ O
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
2e-5 -X- _ B-HyperparameterValue
and -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
16 -X- _ B-HyperparameterValue
. -X- _ O
Re- -X- _ O
sults -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O
BERTLARGE -X- _ B-MethodName
out- -X- _ O
performs -X- _ O
the -X- _ O
authors -X- _ O
’ -X- _ O
baseline -X- _ O
ESIM+ELMo -X- _ B-MethodName
sys- -X- _ O
tem -X- _ O
by -X- _ O
+27.1 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
by -X- _ O
8.3 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O

ˆ -X- _ O
si -X- _ O
, -X- _ O
j -X- _ O
= -X- _ O
maxj≥iS·Ti -X- _ O
+ -X- _ O
E·Tj -X- _ O
. -X- _ O
We -X- _ O
predict -X- _ O
a -X- _ O
non -X- _ O
- -X- _ O
null -X- _ O
answer -X- _ O
when -X- _ O
ˆ -X- _ O
si -X- _ O
, -X- _ O
j -X- _ O
> -X- _ O
snull -X- _ O
+ -X- _ O
τ -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
thresh- -X- _ O
old -X- _ O
τ -X- _ O
is -X- _ O
selected -X- _ O
on -X- _ O
the -X- _ O
dev -X- _ O
set -X- _ O
to -X- _ O
maximize -X- _ O
F1 -X- _ B-MetricName
. -X- _ O
We -X- _ O
did -X- _ O
not -X- _ O
use -X- _ O
TriviaQA -X- _ B-DatasetName
data -X- _ O
for -X- _ O
this -X- _ O
model -X- _ O
. -X- _ O
We -X- _ O
ﬁne -X- _ O
- -X- _ O
tuned -X- _ O
for -X- _ O
2 -X- _ B-MetricValue
epochs -X- _ B-MetricName
with -X- _ O
a -X- _ O
learning -X- _ B-MetricName
rate -X- _ I-MetricName
of -X- _ O
5e-5 -X- _ B-MetricValue
and -X- _ O
a -X- _ O
batch -X- _ B-MetricName
size -X- _ I-MetricName
of -X- _ O
48 -X- _ B-MetricValue
. -X- _ O
The -X- _ O
results -X- _ O
compared -X- _ O
to -X- _ O
prior -X- _ O
leaderboard -X- _ O
en- -X- _ O
tries -X- _ O
and -X- _ O
top -X- _ O
published -X- _ O
work -X- _ O
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018b -X- _ O
) -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
3 -X- _ O
, -X- _ O
exclud- -X- _ O
ing -X- _ O
systems -X- _ O
that -X- _ O
use -X- _ O
BERT -X- _ B-MethodName
as -X- _ O
one -X- _ O
of -X- _ O
their -X- _ O
com- -X- _ O
ponents -X- _ O
. -X- _ O
We -X- _ O
observe -X- _ O
a -X- _ O
+5.1 -X- _ B-MetricValue
F1 -X- _ B-MetricName
improvement -X- _ O
over -X- _ O
the -X- _ O
previous -X- _ O
best -X- _ O
system -X- _ O
. -X- _ O

Table -X- _ O
4 -X- _ O
: -X- _ O
SWAG -X- _ B-DatasetName
Dev -X- _ O
and -X- _ O
Test -X- _ O
accuracies -X- _ O
. -X- _ O
†Human -X- _ O
per- -X- _ O
formance -X- _ O
is -X- _ O
measured -X- _ O
with -X- _ O
100 -X- _ O
samples -X- _ O
, -X- _ O
as -X- _ O
reported -X- _ O
in -X- _ O
the -X- _ O
SWAG -X- _ B-DatasetName
paper -X- _ O
. -X- _ O

12The -X- _ O
TriviaQA -X- _ B-DatasetName
data -X- _ O
we -X- _ O
used -X- _ O
consists -X- _ O
of -X- _ O
paragraphs -X- _ O
from -X- _ O
TriviaQA -X- _ B-DatasetName
- -X- _ O
Wiki -X- _ B-DatasetName
formed -X- _ O
of -X- _ O
the -X- _ O
ﬁrst -X- _ O
400 -X- _ O
tokens -X- _ O
in -X- _ O
documents -X- _ O
, -X- _ O
that -X- _ O
contain -X- _ O
at -X- _ O
least -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
provided -X- _ O
possible -X- _ O
answers -X- _ O
. -X- _ O

The -X- _ O
SQuAD -X- _ B-DatasetName
2.0 -X- _ I-DatasetName
task -X- _ O
extends -X- _ O
the -X- _ O
SQuAD -X- _ B-DatasetName
1.1 -X- _ I-DatasetName
problem -X- _ O
deﬁnition -X- _ O
by -X- _ O
allowing -X- _ O
for -X- _ O
the -X- _ O
possibility -X- _ O
that -X- _ O
no -X- _ O
short -X- _ O
answer -X- _ O
exists -X- _ O
in -X- _ O
the -X- _ O
provided -X- _ O
para- -X- _ O
graph -X- _ O
, -X- _ O
making -X- _ O
the -X- _ O
problem -X- _ O
more -X- _ O
realistic -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
simple -X- _ O
approach -X- _ O
to -X- _ O
extend -X- _ O
the -X- _ O
SQuAD -X- _ B-DatasetName
v1.1 -X- _ I-DatasetName
BERT -X- _ B-MethodName
model -X- _ O
for -X- _ O
this -X- _ O
task -X- _ O
. -X- _ O
We -X- _ O
treat -X- _ O
ques- -X- _ O
tions -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
an -X- _ O
answer -X- _ O
as -X- _ O
having -X- _ O
an -X- _ O
an- -X- _ O
swer -X- _ O
span -X- _ O
with -X- _ O
start -X- _ O
and -X- _ O
end -X- _ O
at -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
to- -X- _ O
ken -X- _ O
. -X- _ O
The -X- _ O
probability -X- _ O
space -X- _ O
for -X- _ O
the -X- _ O
start -X- _ O
and -X- _ O
end -X- _ O
answer -X- _ O
span -X- _ O
positions -X- _ O
is -X- _ O
extended -X- _ O
to -X- _ O
include -X- _ O
the -X- _ O
position -X- _ O
of -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
. -X- _ O
For -X- _ O
prediction -X- _ O
, -X- _ O
we -X- _ O
compare -X- _ O
the -X- _ O
score -X- _ O
of -X- _ O
the -X- _ O
no -X- _ O
- -X- _ O
answer -X- _ O
span -X- _ O
: -X- _ O
snull -X- _ O
= -X- _ O
S·C -X- _ O
+ -X- _ O
E·C -X- _ O
to -X- _ O
the -X- _ O
score -X- _ O
of -X- _ O
the -X- _ O
best -X- _ O
non -X- _ O
- -X- _ O
null -X- _ O
span -X- _ O

tuning -X- _ O
data -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
lose -X- _ O
0.1 -X- _ B-MetricValue
- -X- _ I-MetricValue
0.4 -X- _ I-MetricValue
F1 -X- _ B-MetricName
, -X- _ O
still -X- _ O
outper- -X- _ O
forming -X- _ O
all -X- _ O
existing -X- _ O
systems -X- _ O
by -X- _ O
a -X- _ O
wide -X- _ O
margin.12 -X- _ O

Table -X- _ O
3 -X- _ O
: -X- _ O
SQuAD -X- _ B-DatasetName
2.0 -X- _ I-DatasetName
results -X- _ O
. -X- _ O
We -X- _ O
exclude -X- _ O
entries -X- _ O
that -X- _ O
use -X- _ O
BERT -X- _ B-MethodName
as -X- _ O
one -X- _ O
of -X- _ O
their -X- _ O
components -X- _ O
. -X- _ O

Published -X- _ O
unet -X- _ O
( -X- _ O
Ensemble -X- _ O
) -X- _ O
- -X- _ O
- -X- _ O
71.4 -X- _ O
74.9 -X- _ O
SLQA+ -X- _ O
( -X- _ O
Single -X- _ O
) -X- _ O
- -X- _ O
71.4 -X- _ O
74.4 -X- _ O

Top -X- _ O
Leaderboard -X- _ O
Systems -X- _ O
( -X- _ O
Dec -X- _ O
10th -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
Human -X- _ O
86.3 -X- _ O
89.0 -X- _ O
86.9 -X- _ O
89.5 -X- _ O
# -X- _ O
1 -X- _ O
Single -X- _ O
- -X- _ O
MIR -X- _ O
- -X- _ O
MRC -X- _ O
( -X- _ O
F -X- _ O
- -X- _ O
Net -X- _ O
) -X- _ O
- -X- _ O
- -X- _ O
74.8 -X- _ O
78.0 -X- _ O
# -X- _ O
2 -X- _ O
Single -X- _ O
- -X- _ O
nlnet -X- _ O
- -X- _ O
- -X- _ O
74.2 -X- _ O
77.1 -X- _ O

Table -X- _ O
2 -X- _ O
: -X- _ O
SQuAD -X- _ B-DatasetName
1.1 -X- _ O
results -X- _ O
. -X- _ O
The -X- _ O
BERT -X- _ B-MethodName
ensemble -X- _ O
is -X- _ O
7x -X- _ O
systems -X- _ O
which -X- _ O
use -X- _ O
different -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
check- -X- _ O
points -X- _ O
and -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
seeds -X- _ O
. -X- _ O

Ours -X- _ O
BERTBASE -X- _ B-MethodName
( -X- _ O
Single -X- _ O
) -X- _ O
80.8 -X- _ O
88.5 -X- _ O
- -X- _ O
- -X- _ O
BERTLARGE -X- _ B-MethodName
( -X- _ O
Single -X- _ O
) -X- _ O
84.1 -X- _ O
90.9 -X- _ O
- -X- _ O
- -X- _ O
BERTLARGE -X- _ B-MethodName
( -X- _ O
Ensemble -X- _ O
) -X- _ O
85.8 -X- _ O
91.8 -X- _ O
- -X- _ O
- -X- _ O
BERTLARGE -X- _ B-MethodName
( -X- _ O
Sgl.+TriviaQA -X- _ B-DatasetName
) -X- _ O
84.2 -X- _ O
91.1 -X- _ O
85.1 -X- _ O
91.8 -X- _ O
BERTLARGE -X- _ B-MethodName
( -X- _ O
Ens.+TriviaQA -X- _ B-DatasetName
) -X- _ O
86.2 -X- _ O
92.2 -X- _ O
87.4 -X- _ O
93.2 -X- _ O

Published -X- _ O
BiDAF+ELMo -X- _ B-MethodName
( -X- _ O
Single -X- _ O
) -X- _ O
- -X- _ O
85.6 -X- _ O
- -X- _ O
85.8 -X- _ O
R.M. -X- _ O
Reader -X- _ O
( -X- _ O
Ensemble -X- _ O
) -X- _ O
81.2 -X- _ O
87.9 -X- _ O
82.3 -X- _ O
88.5 -X- _ O

Top -X- _ O
Leaderboard -X- _ O
Systems -X- _ O
( -X- _ O
Dec -X- _ O
10th -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
Human -X- _ O
- -X- _ O
- -X- _ O
82.3 -X- _ O
91.2 -X- _ O
# -X- _ O
1 -X- _ O
Ensemble -X- _ O
- -X- _ O
nlnet -X- _ B-DatasetName
- -X- _ O
- -X- _ O
86.0 -X- _ O
91.7 -X- _ O
# -X- _ O
2 -X- _ O
Ensemble -X- _ O
- -X- _ O
QANet -X- _ B-DatasetName
- -X- _ O
- -X- _ O
84.5 -X- _ O
90.5 -X- _ O

11QANet -X- _ B-DatasetName
is -X- _ O
described -X- _ O
in -X- _ O
Yu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
but -X- _ O
the -X- _ O
system -X- _ O
has -X- _ O
improved -X- _ O
substantially -X- _ O
after -X- _ O
publication -X- _ O
. -X- _ O

The -X- _ O
analogous -X- _ O
formula -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
the -X- _ O
answer -X- _ O
span -X- _ O
. -X- _ O
The -X- _ O
score -X- _ O
of -X- _ O
a -X- _ O
candidate -X- _ O
span -X- _ O
from -X- _ O
position -X- _ O
i -X- _ O
to -X- _ O
position -X- _ O
j -X- _ O
is -X- _ O
deﬁned -X- _ O
as -X- _ O
S·Ti -X- _ O
+ -X- _ O
E·Tj -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
maximum -X- _ O
scoring -X- _ O
span -X- _ O
where -X- _ O
j -X- _ O
≥ -X- _ O
i -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
prediction -X- _ O
. -X- _ O
The -X- _ O
training -X- _ O
objective -X- _ O
is -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
the -X- _ O
log -X- _ O
- -X- _ O
likelihoods -X- _ O
of -X- _ O
the -X- _ O
correct -X- _ O
start -X- _ O
and -X- _ O
end -X- _ O
positions -X- _ O
. -X- _ O
We -X- _ O
ﬁne -X- _ O
- -X- _ O
tune -X- _ O
for -X- _ O
3 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
5e-5 -X- _ B-HyperparameterValue
and -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
32 -X- _ B-HyperparameterValue
. -X- _ O
Table -X- _ O
2 -X- _ O
shows -X- _ O
top -X- _ O
leaderboard -X- _ O
entries -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
results -X- _ O
from -X- _ O
top -X- _ O
published -X- _ O
systems -X- _ O
( -X- _ O
Seo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Clark -X- _ O
and -X- _ O
Gardner -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
; -X- _ O
Hu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
top -X- _ O
results -X- _ O
from -X- _ O
the -X- _ O
SQuAD -X- _ B-DatasetName
leaderboard -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
up -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
date -X- _ O
public -X- _ O
system -X- _ O
descriptions -X- _ O
available,11 -X- _ O
and -X- _ O
are -X- _ O
allowed -X- _ O
to -X- _ O
use -X- _ O
any -X- _ O
public -X- _ O
data -X- _ O
when -X- _ O
training -X- _ O
their -X- _ O
systems -X- _ O
. -X- _ O
We -X- _ O
therefore -X- _ O
use -X- _ O
modest -X- _ O
data -X- _ O
augmentation -X- _ O
in -X- _ O
our -X- _ O
system -X- _ O
by -X- _ O
ﬁrst -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
TriviaQA -X- _ B-DatasetName
( -X- _ O
Joshi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
befor -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
SQuAD -X- _ B-DatasetName
. -X- _ O
Our -X- _ O
best -X- _ O
performing -X- _ O
system -X- _ O
outperforms -X- _ O
the -X- _ O
top -X- _ O
leaderboard -X- _ O
system -X- _ O
by -X- _ O
+1.5 -X- _ B-MetricValue
F1 -X- _ B-MetricName
in -X- _ O
ensembling -X- _ O
and -X- _ O
+1.3 -X- _ B-MetricValue
F1 -X- _ B-MetricName
as -X- _ O
a -X- _ O
single -X- _ O
system -X- _ O
. -X- _ O
In -X- _ O
fact -X- _ O
, -X- _ O
our -X- _ O
single -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
outperforms -X- _ O
the -X- _ O
top -X- _ O
ensemble -X- _ O
sys- -X- _ O
tem -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
F1 -X- _ B-HyperparameterValue
score -X- _ I-HyperparameterValue
. -X- _ O
Without -X- _ O
TriviaQA -X- _ B-DatasetName
ﬁne- -X- _ O

Wikipedia -X- _ B-DatasetName
containing -X- _ O
the -X- _ O
answer -X- _ O
, -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
answer -X- _ O
text -X- _ O
span -X- _ O
in -X- _ O
the -X- _ O
passage -X- _ O
. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
in -X- _ O
the -X- _ O
question -X- _ B-TaskName
answer- -X- _ I-TaskName
ing -X- _ I-TaskName
task -X- _ O
, -X- _ O
we -X- _ O
represent -X- _ O
the -X- _ O
input -X- _ O
question -X- _ O
and -X- _ O
pas- -X- _ O
sage -X- _ O
as -X- _ O
a -X- _ O
single -X- _ O
packed -X- _ O
sequence -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
ques- -X- _ O
tion -X- _ O
using -X- _ O
the -X- _ O
A -X- _ O
embedding -X- _ O
and -X- _ O
the -X- _ O
passage -X- _ O
using -X- _ O
the -X- _ O
B -X- _ O
embedding -X- _ O
. -X- _ O
We -X- _ O
only -X- _ O
introduce -X- _ O
a -X- _ O
start -X- _ O
vec- -X- _ O
tor -X- _ O
S -X- _ O
∈ -X- _ O
RH -X- _ O
and -X- _ O
an -X- _ O
end -X- _ O
vector -X- _ O
E -X- _ O
∈ -X- _ O
RH -X- _ O
during -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O
The -X- _ O
probability -X- _ O
of -X- _ O
word -X- _ O
i -X- _ O
being -X- _ O
the -X- _ O
start -X- _ O
of -X- _ O
the -X- _ O
answer -X- _ O
span -X- _ O
is -X- _ O
computed -X- _ O
as -X- _ O
a -X- _ O
dot -X- _ O
prod- -X- _ O
uct -X- _ O
between -X- _ O
Ti -X- _ O
and -X- _ O
S -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
softmax -X- _ O
over -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
paragraph -X- _ O
: -X- _ O
Pi -X- _ O
= -X- _ O
eS·Ti -X- _ O
� -X- _ O
j -X- _ O
eS·Tj -X- _ O
. -X- _ O

9The -X- _ O
GLUE -X- _ B-DatasetName
data -X- _ O
set -X- _ O
distribution -X- _ O
does -X- _ O
not -X- _ O
include -X- _ O
the -X- _ O
Test -X- _ O
labels -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
only -X- _ O
made -X- _ O
a -X- _ O
single -X- _ O
GLUE -X- _ B-MetricName
evaluation -X- _ O
server -X- _ O
submission -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
BERTBASE -X- _ B-MethodName
and -X- _ O
BERTLARGE -X- _ B-MethodName
. -X- _ O
10https://gluebenchmark.com/leaderboard -X- _ O

The -X- _ O
Stanford -X- _ B-DatasetName
Question -X- _ I-DatasetName
Answering -X- _ I-DatasetName
Dataset -X- _ I-DatasetName
( -X- _ O
SQuAD -X- _ B-DatasetName
v1.1 -X- _ I-DatasetName
) -X- _ O
is -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
100k -X- _ O
crowd- -X- _ O
sourced -X- _ O
question -X- _ O
/ -X- _ O
answer -X- _ O
pairs -X- _ O
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
Given -X- _ O
a -X- _ O
question -X- _ O
and -X- _ O
a -X- _ O
passage -X- _ O
from -X- _ O

Results -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
Both -X- _ O
BERTBASE -X- _ B-MethodName
and -X- _ O
BERTLARGE -X- _ B-MethodName
outperform -X- _ O
all -X- _ O
sys- -X- _ O
tems -X- _ O
on -X- _ O
all -X- _ O
tasks -X- _ O
by -X- _ O
a -X- _ O
substantial -X- _ O
margin -X- _ O
, -X- _ O
obtaining -X- _ O
4.5 -X- _ B-MetricValue
% -X- _ I-MetricValue
and -X- _ O
7.0 -X- _ B-MetricValue
% -X- _ I-MetricValue
respective -X- _ O
average -X- _ B-MetricName
accuracy -X- _ I-MetricName
im- -X- _ O
provement -X- _ O
over -X- _ O
the -X- _ O
prior -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
BERTBASE -X- _ B-MethodName
and -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
are -X- _ O
nearly -X- _ O
identical -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
model -X- _ O
architecture -X- _ O
apart -X- _ O
from -X- _ O
the -X- _ O
at- -X- _ O
tention -X- _ O
masking -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
largest -X- _ O
and -X- _ O
most -X- _ O
widely -X- _ O
reported -X- _ O
GLUE -X- _ B-TaskName
task -X- _ O
, -X- _ O
MNLI -X- _ B-TaskName
, -X- _ O
BERT -X- _ B-MethodName
obtains -X- _ O
a -X- _ O
4.6 -X- _ B-MetricValue
% -X- _ I-MetricValue
absolute -X- _ B-MetricName
accuracy -X- _ I-MetricName
improvement -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
ofﬁcial -X- _ O
GLUE -X- _ B-MetricName
leaderboard10 -X- _ O
, -X- _ O
BERTLARGE -X- _ B-MethodName
obtains -X- _ O
a -X- _ O
score -X- _ O
of -X- _ O
80.5 -X- _ B-MetricValue
, -X- _ O
compared -X- _ O
to -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
, -X- _ O
which -X- _ O
obtains -X- _ O
72.8 -X- _ B-MetricValue
as -X- _ O
of -X- _ O
the -X- _ O
date -X- _ O
of -X- _ O
writing -X- _ O
. -X- _ O
We -X- _ O
ﬁnd -X- _ O
that -X- _ O
BERTLARGE -X- _ B-MethodName
signiﬁcantly -X- _ O
outper- -X- _ O
forms -X- _ O
BERTBASE -X- _ B-MethodName
across -X- _ O
all -X- _ O
tasks -X- _ O
, -X- _ O
especially -X- _ O
those -X- _ O
with -X- _ O
very -X- _ O
little -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
The -X- _ O
effect -X- _ O
of -X- _ O
model -X- _ O
size -X- _ O
is -X- _ O
explored -X- _ O
more -X- _ O
thoroughly -X- _ O
in -X- _ O
Section -X- _ O
5.2 -X- _ O
. -X- _ O

We -X- _ O
use -X- _ O
a -X- _ O
batch -X- _ O
size -X- _ O
of -X- _ O
32 -X- _ O
and -X- _ O
ﬁne -X- _ O
- -X- _ O
tune -X- _ O
for -X- _ O
3 -X- _ O
epochs -X- _ O
over -X- _ O
the -X- _ O
data -X- _ O
for -X- _ O
all -X- _ O
GLUE -X- _ B-MetricName
tasks -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
selected -X- _ O
the -X- _ O
best -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
( -X- _ O
among -X- _ O
5e-5 -X- _ B-HyperparameterValue
, -X- _ O
4e-5 -X- _ B-HyperparameterValue
, -X- _ O
3e-5 -X- _ B-HyperparameterValue
, -X- _ O
and -X- _ O
2e-5 -X- _ B-HyperparameterValue
) -X- _ O
on -X- _ O
the -X- _ O
Dev -X- _ O
set -X- _ O
. -X- _ O
Additionally -X- _ O
, -X- _ O
for -X- _ O
BERTLARGE -X- _ B-MethodName
we -X- _ O
found -X- _ O
that -X- _ O
ﬁne- -X- _ O
tuning -X- _ O
was -X- _ O
sometimes -X- _ O
unstable -X- _ O
on -X- _ O
small -X- _ O
datasets -X- _ O
, -X- _ O
so -X- _ O
we -X- _ O
ran -X- _ O
several -X- _ O
random -X- _ O
restarts -X- _ O
and -X- _ O
selected -X- _ O
the -X- _ O
best -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
Dev -X- _ O
set -X- _ O
. -X- _ O
With -X- _ O
random -X- _ O
restarts -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
checkpoint -X- _ O
but -X- _ O
per- -X- _ O
form -X- _ O
different -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
data -X- _ O
shufﬂing -X- _ O
and -X- _ O
clas- -X- _ O
siﬁer -X- _ O
layer -X- _ O
initialization.9 -X- _ O

Table -X- _ O
1 -X- _ O
: -X- _ O
GLUE -X- _ B-MetricName
Test -X- _ O
results -X- _ O
, -X- _ O
scored -X- _ O
by -X- _ O
the -X- _ O
evaluation -X- _ O
server -X- _ O
( -X- _ O
https://gluebenchmark.com/leaderboard -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
number -X- _ O
below -X- _ O
each -X- _ O
task -X- _ O
denotes -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
training -X- _ O
examples -X- _ O
. -X- _ O
The -X- _ O
“ -X- _ O
Average -X- _ B-MetricName
” -X- _ O
column -X- _ O
is -X- _ O
slightly -X- _ O
different -X- _ O
than -X- _ O
the -X- _ O
ofﬁcial -X- _ O
GLUE -X- _ B-MetricName
score -X- _ I-MetricName
, -X- _ O
since -X- _ O
we -X- _ O
exclude -X- _ O
the -X- _ O
problematic -X- _ O
WNLI -X- _ B-DatasetName
set.8 -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
are -X- _ O
single- -X- _ O
model -X- _ O
, -X- _ O
single -X- _ O
task -X- _ O
. -X- _ O
F1 -X- _ B-MetricName
scores -X- _ I-MetricName
are -X- _ O
reported -X- _ O
for -X- _ O
QQP -X- _ B-DatasetName
and -X- _ O
MRPC -X- _ B-DatasetName
, -X- _ O
Spearman -X- _ B-MetricName
correlations -X- _ I-MetricName
are -X- _ O
reported -X- _ O
for -X- _ O
STS -X- _ B-DatasetName
- -X- _ I-DatasetName
B -X- _ I-DatasetName
, -X- _ O
and -X- _ O
accuracy -X- _ B-MetricName
scores -X- _ O
are -X- _ O
reported -X- _ O
for -X- _ O
the -X- _ O
other -X- _ O
tasks -X- _ O
. -X- _ O
We -X- _ O
exclude -X- _ O
entries -X- _ O
that -X- _ O
use -X- _ O
BERT -X- _ B-MethodName
as -X- _ O
one -X- _ O
of -X- _ O
their -X- _ O
components -X- _ O
. -X- _ O

BERTBASE -X- _ B-MethodName
84.6/83.4 -X- _ O
71.2 -X- _ O
90.5 -X- _ O
93.5 -X- _ O
52.1 -X- _ O
85.8 -X- _ O
88.9 -X- _ O
66.4 -X- _ O
79.6 -X- _ O
BERTLARGE -X- _ B-MethodName
86.7/85.9 -X- _ O
72.1 -X- _ O
92.7 -X- _ O
94.9 -X- _ O
60.5 -X- _ O
86.5 -X- _ O
89.3 -X- _ O
70.1 -X- _ O
82.1 -X- _ O

Pre -X- _ O
- -X- _ O
OpenAI -X- _ B-MethodName
SOTA -X- _ O
80.6/80.1 -X- _ O
66.1 -X- _ O
82.3 -X- _ O
93.2 -X- _ O
35.0 -X- _ O
81.0 -X- _ O
86.0 -X- _ O
61.7 -X- _ O
74.0 -X- _ O
BiLSTM+ELMo+Attn -X- _ B-MethodName
76.4/76.1 -X- _ O
64.8 -X- _ O
79.8 -X- _ O
90.4 -X- _ O
36.0 -X- _ O
73.3 -X- _ O
84.9 -X- _ O
56.8 -X- _ O
71.0 -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
82.1/81.4 -X- _ O
70.3 -X- _ O
87.4 -X- _ O
91.3 -X- _ O
45.4 -X- _ O
80.0 -X- _ O
82.3 -X- _ O
56.0 -X- _ O
75.1 -X- _ O

System -X- _ O
MNLI-(m -X- _ B-DatasetName
/ -X- _ I-DatasetName
mm -X- _ I-DatasetName
) -X- _ I-DatasetName
QQP -X- _ B-DatasetName
QNLI -X- _ B-DatasetName
SST-2 -X- _ B-DatasetName
CoLA -X- _ B-DatasetName
STS -X- _ B-DatasetName
- -X- _ I-DatasetName
B -X- _ I-DatasetName
MRPC -X- _ B-DatasetName
RTE -X- _ B-DatasetName
Average -X- _ B-MetricName
392k -X- _ O
363k -X- _ O
108k -X- _ O
67k -X- _ O
8.5k -X- _ O
5.7k -X- _ O
3.5k -X- _ O
2.5k -X- _ O
- -X- _ O

7For -X- _ O
example -X- _ O
, -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
SQuAD -X- _ B-DatasetName
model -X- _ O
can -X- _ O
be -X- _ O
trained -X- _ O
in -X- _ O
around -X- _ O
30 -X- _ O
minutes -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
Cloud -X- _ O
TPU -X- _ O
to -X- _ O
achieve -X- _ O
a -X- _ O
Dev -X- _ O
F1 -X- _ B-MetricName
score -X- _ O
of -X- _ O
91.0 -X- _ B-MetricValue
% -X- _ I-MetricValue
. -X- _ O
8See -X- _ O
( -X- _ O
10 -X- _ O
) -X- _ O
in -X- _ O
https://gluebenchmark.com/faq -X- _ O
. -X- _ O

The -X- _ O
General -X- _ B-MetricName
Language -X- _ I-MetricName
Understanding -X- _ I-MetricName
Evaluation -X- _ I-MetricName
( -X- _ O
GLUE -X- _ B-MetricName
) -X- _ O
benchmark -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
col- -X- _ O
lection -X- _ O
of -X- _ O
diverse -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
tasks -X- _ I-TaskName
. -X- _ O
Detailed -X- _ O
descriptions -X- _ O
of -X- _ O
GLUE -X- _ O
datasets -X- _ O
are -X- _ O
included -X- _ O
in -X- _ O
Appendix -X- _ O
B.1 -X- _ O
. -X- _ O
To -X- _ O
ﬁne -X- _ O
- -X- _ O
tune -X- _ O
on -X- _ O
GLUE -X- _ B-MetricName
, -X- _ O
we -X- _ O
represent -X- _ O
the -X- _ O
input -X- _ O
sequence -X- _ O
( -X- _ O
for -X- _ O
single -X- _ O
sentence -X- _ O
or -X- _ O
sentence -X- _ O
pairs -X- _ O
) -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
3 -X- _ O
, -X- _ O
and -X- _ O
use -X- _ O
the -X- _ O
ﬁnal -X- _ O
hid- -X- _ O
den -X- _ O
vector -X- _ O
C -X- _ O
∈ -X- _ O
RH -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
ﬁrst -X- _ O
input -X- _ O
token -X- _ O
( -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
) -X- _ O
as -X- _ O
the -X- _ O
aggregate -X- _ O
representa- -X- _ O
tion -X- _ O
. -X- _ O
The -X- _ O
only -X- _ O
new -X- _ O
parameters -X- _ O
introduced -X- _ O
during -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
are -X- _ O
classiﬁcation -X- _ O
layer -X- _ O
weights -X- _ O
W -X- _ O
∈ -X- _ O
RK×H -X- _ O
, -X- _ O
where -X- _ O
K -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
labels -X- _ O
. -X- _ O
We -X- _ O
com- -X- _ O
pute -X- _ O
a -X- _ O
standard -X- _ O
classiﬁcation -X- _ B-MetricName
loss -X- _ I-MetricName
with -X- _ O
C -X- _ O
and -X- _ O
W -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
log(softmax(CW -X- _ O
T -X- _ O
) -X- _ O
) -X- _ O
. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
, -X- _ O
we -X- _ O
present -X- _ O
BERT -X- _ B-MethodName
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
re- -X- _ O
sults -X- _ O
on -X- _ O
11 -X- _ O
NLP -X- _ B-TaskName
tasks -X- _ O
. -X- _ O

( -X- _ O
4 -X- _ O
) -X- _ O
a -X- _ O
degenerate -X- _ O
text-∅ -X- _ O
pair -X- _ O
in -X- _ O
text -X- _ B-TaskName
classiﬁcation -X- _ I-TaskName
or -X- _ O
sequence -X- _ B-TaskName
tagging -X- _ I-TaskName
. -X- _ O
At -X- _ O
the -X- _ O
output -X- _ O
, -X- _ O
the -X- _ O
token -X- _ O
rep- -X- _ O
resentations -X- _ O
are -X- _ O
fed -X- _ O
into -X- _ O
an -X- _ O
output -X- _ O
layer -X- _ O
for -X- _ O
token- -X- _ O
level -X- _ O
tasks -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
sequence -X- _ B-TaskName
tagging -X- _ I-TaskName
or -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
, -X- _ O
and -X- _ O
the -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
representation -X- _ O
is -X- _ O
fed -X- _ O
into -X- _ O
an -X- _ O
output -X- _ O
layer -X- _ O
for -X- _ O
classiﬁcation -X- _ B-TaskName
, -X- _ O
such -X- _ O
as -X- _ O
en- -X- _ B-TaskName
tailment -X- _ I-TaskName
or -X- _ O
sentiment -X- _ B-TaskName
analysis -X- _ I-TaskName
. -X- _ O
Compared -X- _ O
to -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
is -X- _ O
rela- -X- _ O
tively -X- _ O
inexpensive -X- _ O
. -X- _ O
All -X- _ O
of -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
the -X- _ O
pa- -X- _ O
per -X- _ O
can -X- _ O
be -X- _ O
replicated -X- _ O
in -X- _ O
at -X- _ O
most -X- _ O
1 -X- _ O
hour -X- _ O
on -X- _ O
a -X- _ O
sin- -X- _ O
gle -X- _ O
Cloud -X- _ O
TPU -X- _ O
, -X- _ O
or -X- _ O
a -X- _ O
few -X- _ O
hours -X- _ O
on -X- _ O
a -X- _ O
GPU -X- _ O
, -X- _ O
starting -X- _ O
from -X- _ O
the -X- _ O
exact -X- _ O
same -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model.7 -X- _ O
We -X- _ O
de- -X- _ O
scribe -X- _ O
the -X- _ O
task -X- _ O
- -X- _ O
speciﬁc -X- _ O
details -X- _ O
in -X- _ O
the -X- _ O
correspond- -X- _ O
ing -X- _ O
subsections -X- _ O
of -X- _ O
Section -X- _ O
4 -X- _ O
. -X- _ O
More -X- _ O
details -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
A.5 -X- _ O
. -X- _ O

Fine -X- _ O
- -X- _ O
tuning -X- _ O
is -X- _ O
straightforward -X- _ O
since -X- _ O
the -X- _ O
self- -X- _ O
attention -X- _ O
mechanism -X- _ O
in -X- _ O
the -X- _ O
Transformer -X- _ O
al- -X- _ O
lows -X- _ O
BERT -X- _ B-MethodName
to -X- _ O
model -X- _ O
many -X- _ O
downstream -X- _ O
tasks -X- _ O
— -X- _ O
whether -X- _ O
they -X- _ O
involve -X- _ O
single -X- _ O
text -X- _ O
or -X- _ O
text -X- _ O
pairs -X- _ O
— -X- _ O
by -X- _ O
swapping -X- _ O
out -X- _ O
the -X- _ O
appropriate -X- _ O
inputs -X- _ O
and -X- _ O
outputs -X- _ O
. -X- _ O
For -X- _ O
applications -X- _ O
involving -X- _ O
text -X- _ O
pairs -X- _ O
, -X- _ O
a -X- _ O
common -X- _ O
pattern -X- _ O
is -X- _ O
to -X- _ O
independently -X- _ O
encode -X- _ O
text -X- _ O
pairs -X- _ O
be- -X- _ O
fore -X- _ O
applying -X- _ O
bidirectional -X- _ O
cross -X- _ O
attention -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
Parikh -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
; -X- _ O
Seo -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
BERT -X- _ B-MethodName
instead -X- _ O
uses -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
mechanism -X- _ O
to -X- _ O
unify -X- _ O
these -X- _ O
two -X- _ O
stages -X- _ O
, -X- _ O
as -X- _ O
encoding -X- _ O
a -X- _ O
concatenated -X- _ O
text -X- _ O
pair -X- _ O
with -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
effectively -X- _ O
includes -X- _ O
bidi- -X- _ O
rectional -X- _ O
cross -X- _ O
attention -X- _ O
between -X- _ O
two -X- _ O
sentences -X- _ O
. -X- _ O
For -X- _ O
each -X- _ O
task -X- _ O
, -X- _ O
we -X- _ O
simply -X- _ O
plug -X- _ O
in -X- _ O
the -X- _ O
task- -X- _ O
speciﬁc -X- _ O
inputs -X- _ O
and -X- _ O
outputs -X- _ O
into -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
ﬁne- -X- _ O
tune -X- _ O
all -X- _ O
the -X- _ O
parameters -X- _ O
end -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
end -X- _ O
. -X- _ O
At -X- _ O
the -X- _ O
in- -X- _ O
put -X- _ O
, -X- _ O
sentence -X- _ O
A -X- _ O
and -X- _ O
sentence -X- _ O
B -X- _ O
from -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
are -X- _ O
analogous -X- _ O
to -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
sentence -X- _ O
pairs -X- _ O
in -X- _ O
paraphras- -X- _ B-TaskName
ing -X- _ I-TaskName
, -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
hypothesis -X- _ O
- -X- _ O
premise -X- _ O
pairs -X- _ O
in -X- _ O
entailment -X- _ B-TaskName
, -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
question -X- _ O
- -X- _ O
passage -X- _ O
pairs -X- _ O
in -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
, -X- _ O
and -X- _ O

Pre -X- _ O
- -X- _ O
training -X- _ O
data -X- _ O
The -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
procedure -X- _ O
largely -X- _ O
follows -X- _ O
the -X- _ O
existing -X- _ O
literature -X- _ O
on -X- _ O
language -X- _ O
model -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
corpus -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
BooksCorpus -X- _ B-DatasetName
( -X- _ O
800 -X- _ O
M -X- _ O
words -X- _ O
) -X- _ O
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
and -X- _ O
English -X- _ B-DatasetName
Wikipedia -X- _ I-DatasetName
( -X- _ O
2,500 -X- _ O
M -X- _ O
words -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
Wikipedia -X- _ O
we -X- _ O
extract -X- _ O
only -X- _ O
the -X- _ O
text -X- _ O
passages -X- _ O
and -X- _ O
ignore -X- _ O
lists -X- _ O
, -X- _ O
tables -X- _ O
, -X- _ O
and -X- _ O
headers -X- _ O
. -X- _ O
It -X- _ O
is -X- _ O
criti- -X- _ O
cal -X- _ O
to -X- _ O
use -X- _ O
a -X- _ O
document -X- _ O
- -X- _ O
level -X- _ O
corpus -X- _ O
rather -X- _ O
than -X- _ O
a -X- _ O
shufﬂed -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
corpus -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
Billion -X- _ O
Word -X- _ O
Benchmark -X- _ O
( -X- _ O
Chelba -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
extract -X- _ O
long -X- _ O
contiguous -X- _ O
sequences -X- _ O
. -X- _ O

The -X- _ O
NSP -X- _ B-TaskName
task -X- _ O
is -X- _ O
closely -X- _ O
related -X- _ O
to -X- _ O
representation- -X- _ O
learning -X- _ O
objectives -X- _ O
used -X- _ O
in -X- _ O
Jernite -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
Logeswaran -X- _ O
and -X- _ O
Lee -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
in -X- _ O
prior -X- _ O
work -X- _ O
, -X- _ O
only -X- _ O
sentence -X- _ O
embeddings -X- _ O
are -X- _ O
transferred -X- _ O
to -X- _ O
down -X- _ O
- -X- _ O
stream -X- _ O
tasks -X- _ O
, -X- _ O
where -X- _ O
BERT -X- _ B-MethodName
transfers -X- _ O
all -X- _ O
pa- -X- _ O
rameters -X- _ O
to -X- _ O
initialize -X- _ O
end -X- _ O
- -X- _ O
task -X- _ O
model -X- _ O
parameters -X- _ O
. -X- _ O

Figure -X- _ O
2 -X- _ O
: -X- _ O
BERT -X- _ B-MethodName
input -X- _ O
representation -X- _ O
. -X- _ O
The -X- _ O
input -X- _ O
embeddings -X- _ O
are -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
the -X- _ O
token -X- _ O
embeddings -X- _ O
, -X- _ O
the -X- _ O
segmenta- -X- _ O
tion -X- _ O
embeddings -X- _ O
and -X- _ O
the -X- _ O
position -X- _ O
embeddings -X- _ O
. -X- _ O

E[CLS -X- _ O
] -X- _ O
Ehe -X- _ O
Elikes -X- _ O
Eplay -X- _ O
E##ing -X- _ O
E[SEP -X- _ O
] -X- _ O
Emy -X- _ O
Edog -X- _ O
Eis -X- _ O
Ecute -X- _ O
E[SEP -X- _ O
] -X- _ O

5The -X- _ O
ﬁnal -X- _ O
model -X- _ O
achieves -X- _ O
97%-98 -X- _ O
% -X- _ O
accuracy -X- _ O
on -X- _ O
NSP -X- _ B-TaskName
. -X- _ O
6The -X- _ O
vector -X- _ O
C -X- _ O
is -X- _ O
not -X- _ O
a -X- _ O
meaningful -X- _ O
sentence -X- _ O
representation -X- _ O
without -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
since -X- _ O
it -X- _ O
was -X- _ O
trained -X- _ O
with -X- _ O
NSP -X- _ B-TaskName
. -X- _ O

Task -X- _ O
# -X- _ O
2 -X- _ O
: -X- _ O
Next -X- _ B-TaskName
Sentence -X- _ I-TaskName
Prediction -X- _ I-TaskName
( -X- _ O
NSP -X- _ B-TaskName
) -X- _ O
Many -X- _ O
important -X- _ O
downstream -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
Ques- -X- _ B-TaskName
tion -X- _ I-TaskName
Answering -X- _ I-TaskName
( -X- _ O
QA -X- _ B-TaskName
) -X- _ O
and -X- _ O
Natural -X- _ B-TaskName
Language -X- _ I-TaskName
Infer- -X- _ I-TaskName
ence -X- _ I-TaskName
( -X- _ O
NLI -X- _ B-TaskName
) -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
understanding -X- _ O
the -X- _ O
rela- -X- _ O
tionship -X- _ O
between -X- _ O
two -X- _ O
sentences -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
not -X- _ O
di- -X- _ O
rectly -X- _ O
captured -X- _ O
by -X- _ O
language -X- _ O
modeling -X- _ O
. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
model -X- _ O
that -X- _ O
understands -X- _ O
sentence -X- _ O
rela- -X- _ O
tionships -X- _ O
, -X- _ O
we -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
for -X- _ O
a -X- _ O
binarized -X- _ O
next -X- _ O
sen- -X- _ O
tence -X- _ O
prediction -X- _ O
task -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
trivially -X- _ O
gener- -X- _ O
ated -X- _ O
from -X- _ O
any -X- _ O
monolingual -X- _ O
corpus -X- _ O
. -X- _ O
Speciﬁcally -X- _ O
, -X- _ O
when -X- _ O
choosing -X- _ O
the -X- _ O
sentences -X- _ O
A -X- _ O
and -X- _ O
B -X- _ O
for -X- _ O
each -X- _ O
pre- -X- _ O
training -X- _ O
example -X- _ O
, -X- _ O
50 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
B -X- _ O
is -X- _ O
the -X- _ O
actual -X- _ O
next -X- _ O
sentence -X- _ O
that -X- _ O
follows -X- _ O
A -X- _ O
( -X- _ O
labeled -X- _ O
as -X- _ O
IsNext -X- _ B-TaskName
) -X- _ O
, -X- _ O
and -X- _ O
50 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
it -X- _ O
is -X- _ O
a -X- _ O
random -X- _ O
sentence -X- _ O
from -X- _ O
the -X- _ O
corpus -X- _ O
( -X- _ O
labeled -X- _ O
as -X- _ O
NotNext -X- _ B-TaskName
) -X- _ O
. -X- _ O
As -X- _ O
we -X- _ O
show -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
C -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
next -X- _ B-TaskName
sentence -X- _ I-TaskName
predic- -X- _ I-TaskName
tion -X- _ I-TaskName
( -X- _ O
NSP).5 -X- _ B-TaskName
Despite -X- _ O
its -X- _ O
simplicity -X- _ O
, -X- _ O
we -X- _ O
demon- -X- _ O
strate -X- _ O
in -X- _ O
Section -X- _ O
5.1 -X- _ O
that -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
towards -X- _ O
this -X- _ O
task -X- _ O
is -X- _ O
very -X- _ O
beneﬁcial -X- _ O
to -X- _ O
both -X- _ O
QA -X- _ B-TaskName
and -X- _ O
NLI -X- _ B-TaskName
. -X- _ O
6 -X- _ O

In -X- _ O
order -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
deep -X- _ O
bidirectional -X- _ O
representa- -X- _ O
tion -X- _ O
, -X- _ O
we -X- _ O
simply -X- _ O
mask -X- _ O
some -X- _ O
percentage -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
tokens -X- _ O
at -X- _ O
random -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
predict -X- _ O
those -X- _ O
masked -X- _ O
tokens -X- _ O
. -X- _ O
We -X- _ O
refer -X- _ O
to -X- _ O
this -X- _ O
procedure -X- _ O
as -X- _ O
a -X- _ O
“ -X- _ O
masked -X- _ B-MethodName
LM -X- _ I-MethodName
” -X- _ O
( -X- _ O
MLM -X- _ B-MethodName
) -X- _ O
, -X- _ O
although -X- _ O
it -X- _ O
is -X- _ O
often -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
a -X- _ O
Cloze -X- _ O
task -X- _ O
in -X- _ O
the -X- _ O
literature -X- _ O
( -X- _ O
Taylor -X- _ O
, -X- _ O
1953 -X- _ O
) -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
case -X- _ O
, -X- _ O
the -X- _ O
ﬁnal -X- _ O
hidden -X- _ O
vectors -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
mask -X- _ O
tokens -X- _ O
are -X- _ O
fed -X- _ O
into -X- _ O
an -X- _ O
output -X- _ O
softmax -X- _ O
over -X- _ O
the -X- _ O
vocabulary -X- _ O
, -X- _ O
as -X- _ O
in -X- _ O
a -X- _ O
standard -X- _ O
LM -X- _ B-MethodName
. -X- _ O
In -X- _ O
all -X- _ O
of -X- _ O
our -X- _ O
experiments -X- _ O
, -X- _ O
we -X- _ O
mask -X- _ O
15 -X- _ O
% -X- _ O
of -X- _ O
all -X- _ O
WordPiece -X- _ O
to- -X- _ O
kens -X- _ O
in -X- _ O
each -X- _ O
sequence -X- _ O
at -X- _ O
random -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
to -X- _ O
denoising -X- _ O
auto -X- _ O
- -X- _ O
encoders -X- _ O
( -X- _ O
Vincent -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
only -X- _ O
predict -X- _ O
the -X- _ O
masked -X- _ O
words -X- _ O
rather -X- _ O
than -X- _ O
recon- -X- _ O
structing -X- _ O
the -X- _ O
entire -X- _ O
input -X- _ O
. -X- _ O
Although -X- _ O
this -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
bidirec- -X- _ O
tional -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
, -X- _ O
a -X- _ O
downside -X- _ O
is -X- _ O
that -X- _ O
we -X- _ O
are -X- _ O
creating -X- _ O
a -X- _ O
mismatch -X- _ O
between -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
since -X- _ O
the -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
token -X- _ O
does -X- _ O
not -X- _ O
ap- -X- _ O
pear -X- _ O
during -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O
To -X- _ O
mitigate -X- _ O
this -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
always -X- _ O
replace -X- _ O
“ -X- _ O
masked -X- _ O
” -X- _ O
words -X- _ O
with -X- _ O
the -X- _ O
ac- -X- _ O
tual -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
token -X- _ O
. -X- _ O
The -X- _ O
training -X- _ O
data -X- _ O
generator -X- _ O
chooses -X- _ O
15 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
token -X- _ O
positions -X- _ O
at -X- _ O
random -X- _ O
for -X- _ O
prediction -X- _ O
. -X- _ O
If -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
token -X- _ O
is -X- _ O
chosen -X- _ O
, -X- _ O
we -X- _ O
replace -X- _ O
the -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
token -X- _ O
with -X- _ O
( -X- _ O
1 -X- _ O
) -X- _ O
the -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
token -X- _ O
80 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
( -X- _ O
2 -X- _ O
) -X- _ O
a -X- _ O
random -X- _ O
token -X- _ O
10 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
( -X- _ O
3 -X- _ O
) -X- _ O
the -X- _ O
unchanged -X- _ O
i -X- _ O
- -X- _ O
th -X- _ O
token -X- _ O
10 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
Ti -X- _ O
will -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
original -X- _ O
token -X- _ O
with -X- _ O
cross -X- _ O
entropy -X- _ O
loss -X- _ O
. -X- _ O
We -X- _ O
compare -X- _ O
variations -X- _ O
of -X- _ O
this -X- _ O
procedure -X- _ O
in -X- _ O
Appendix -X- _ O
C.2 -X- _ O
. -X- _ O

former -X- _ O
is -X- _ O
often -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
a -X- _ O
“ -X- _ O
Transformer -X- _ B-MethodName
encoder -X- _ I-MethodName
” -X- _ O
while -X- _ O
the -X- _ O
left -X- _ O
- -X- _ O
context -X- _ O
- -X- _ O
only -X- _ O
version -X- _ O
is -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
a -X- _ O
“ -X- _ O
Transformer -X- _ B-MethodName
decoder -X- _ I-MethodName
” -X- _ O
since -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
text -X- _ O
generation -X- _ O
. -X- _ O

Task -X- _ O
# -X- _ O
1 -X- _ O
: -X- _ O
Masked -X- _ B-MethodName
LM -X- _ I-MethodName
Intuitively -X- _ O
, -X- _ O
it -X- _ O
is -X- _ O
reason- -X- _ O
able -X- _ O
to -X- _ O
believe -X- _ O
that -X- _ O
a -X- _ O
deep -X- _ O
bidirectional -X- _ O
model -X- _ O
is -X- _ O
strictly -X- _ O
more -X- _ O
powerful -X- _ O
than -X- _ O
either -X- _ O
a -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
model -X- _ O
or -X- _ O
the -X- _ O
shallow -X- _ O
concatenation -X- _ O
of -X- _ O
a -X- _ O
left -X- _ O
- -X- _ O
to- -X- _ O
right -X- _ O
and -X- _ O
a -X- _ O
right -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
left -X- _ O
model -X- _ O
. -X- _ O
Unfortunately -X- _ O
, -X- _ O
standard -X- _ O
conditional -X- _ O
language -X- _ O
models -X- _ O
can -X- _ O
only -X- _ O
be -X- _ O
trained -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
or -X- _ O
right -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
left -X- _ O
, -X- _ O
since -X- _ O
bidirec- -X- _ O
tional -X- _ O
conditioning -X- _ O
would -X- _ O
allow -X- _ O
each -X- _ O
word -X- _ O
to -X- _ O
in- -X- _ O
directly -X- _ O
“ -X- _ O
see -X- _ O
itself -X- _ O
” -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
model -X- _ O
could -X- _ O
trivially -X- _ O
predict -X- _ O
the -X- _ O
target -X- _ O
word -X- _ O
in -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
layered -X- _ O
context -X- _ O
. -X- _ O

Unlike -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018a -X- _ O
) -X- _ O
and -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
use -X- _ O
traditional -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
or -X- _ O
right -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
left -X- _ O
language -X- _ O
models -X- _ O
to -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
Instead -X- _ O
, -X- _ O
we -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
BERT -X- _ B-MethodName
using -X- _ O
two -X- _ O
unsuper- -X- _ O
vised -X- _ O
tasks -X- _ O
, -X- _ O
described -X- _ O
in -X- _ O
this -X- _ O
section -X- _ O
. -X- _ O
This -X- _ O
step -X- _ O
is -X- _ O
presented -X- _ O
in -X- _ O
the -X- _ O
left -X- _ O
part -X- _ O
of -X- _ O
Figure -X- _ O
1 -X- _ O
. -X- _ O

2016 -X- _ O
) -X- _ O
with -X- _ O
a -X- _ O
30,000 -X- _ O
token -X- _ O
vocabulary -X- _ O
. -X- _ O
The -X- _ O
ﬁrst -X- _ O
token -X- _ O
of -X- _ O
every -X- _ O
sequence -X- _ O
is -X- _ O
always -X- _ O
a -X- _ O
special -X- _ O
clas- -X- _ O
siﬁcation -X- _ O
token -X- _ O
( -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
ﬁnal -X- _ O
hidden -X- _ O
state -X- _ O
corresponding -X- _ O
to -X- _ O
this -X- _ O
token -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
ag- -X- _ O
gregate -X- _ O
sequence -X- _ O
representation -X- _ O
for -X- _ O
classiﬁcation -X- _ B-TaskName
tasks -X- _ O
. -X- _ O
Sentence -X- _ O
pairs -X- _ O
are -X- _ O
packed -X- _ O
together -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
sequence -X- _ O
. -X- _ O
We -X- _ O
differentiate -X- _ O
the -X- _ O
sentences -X- _ O
in -X- _ O
two -X- _ O
ways -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
separate -X- _ O
them -X- _ O
with -X- _ O
a -X- _ O
special -X- _ O
token -X- _ O
( -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
) -X- _ O
. -X- _ O
Second -X- _ O
, -X- _ O
we -X- _ O
add -X- _ O
a -X- _ O
learned -X- _ O
embed- -X- _ O
ding -X- _ O
to -X- _ O
every -X- _ O
token -X- _ O
indicating -X- _ O
whether -X- _ O
it -X- _ O
belongs -X- _ O
to -X- _ O
sentence -X- _ O
A -X- _ O
or -X- _ O
sentence -X- _ O
B. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
, -X- _ O
we -X- _ O
denote -X- _ O
input -X- _ O
embedding -X- _ O
as -X- _ O
E -X- _ O
, -X- _ O
the -X- _ O
ﬁnal -X- _ O
hidden -X- _ O
vector -X- _ O
of -X- _ O
the -X- _ O
special -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
token -X- _ O
as -X- _ O
C -X- _ O
∈ -X- _ O
RH -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
ﬁnal -X- _ O
hidden -X- _ O
vector -X- _ O
for -X- _ O
the -X- _ O
ith -X- _ O
input -X- _ O
token -X- _ O
as -X- _ O
Ti -X- _ O
∈ -X- _ O
RH -X- _ O
. -X- _ O
For -X- _ O
a -X- _ O
given -X- _ O
token -X- _ O
, -X- _ O
its -X- _ O
input -X- _ O
representation -X- _ O
is -X- _ O
constructed -X- _ O
by -X- _ O
summing -X- _ O
the -X- _ O
corresponding -X- _ O
token -X- _ O
, -X- _ O
segment -X- _ O
, -X- _ O
and -X- _ O
position -X- _ O
embeddings -X- _ O
. -X- _ O
A -X- _ O
visualiza- -X- _ O
tion -X- _ O
of -X- _ O
this -X- _ O
construction -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
in -X- _ O
Figure -X- _ O
2 -X- _ O
. -X- _ O

Input -X- _ O
/ -X- _ O
Output -X- _ O
Representations -X- _ O
To -X- _ O
make -X- _ O
BERT -X- _ B-MethodName
handle -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
down -X- _ O
- -X- _ O
stream -X- _ O
tasks -X- _ O
, -X- _ O
our -X- _ O
input -X- _ O
representation -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
unambiguously -X- _ O
represent -X- _ O
both -X- _ O
a -X- _ O
single -X- _ O
sentence -X- _ O
and -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
sentences -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
⟨ -X- _ O
Question -X- _ O
, -X- _ O
Answer -X- _ O
⟩ -X- _ O
) -X- _ O
in -X- _ O
one -X- _ O
token -X- _ O
sequence -X- _ O
. -X- _ O
Throughout -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
a -X- _ O
“ -X- _ O
sentence -X- _ O
” -X- _ O
can -X- _ O
be -X- _ O
an -X- _ O
arbi- -X- _ O
trary -X- _ O
span -X- _ O
of -X- _ O
contiguous -X- _ O
text -X- _ O
, -X- _ O
rather -X- _ O
than -X- _ O
an -X- _ O
actual -X- _ O
linguistic -X- _ O
sentence -X- _ O
. -X- _ O
A -X- _ O
“ -X- _ O
sequence -X- _ O
” -X- _ O
refers -X- _ O
to -X- _ O
the -X- _ O
in- -X- _ O
put -X- _ O
token -X- _ O
sequence -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
which -X- _ O
may -X- _ O
be -X- _ O
a -X- _ O
sin- -X- _ O
gle -X- _ O
sentence -X- _ O
or -X- _ O
two -X- _ O
sentences -X- _ O
packed -X- _ O
together -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
WordPiece -X- _ B-DatasetName
embeddings -X- _ O
( -X- _ O
Wu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O

1https://github.com/tensorﬂow/tensor2tensor -X- _ O
2http://nlp.seas.harvard.edu/2018/04/03/attention.html -X- _ O
3In -X- _ O
all -X- _ O
cases -X- _ O
we -X- _ O
set -X- _ O
the -X- _ O
feed -X- _ O
- -X- _ O
forward/ﬁlter -X- _ O
size -X- _ O
to -X- _ O
be -X- _ O
4H -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
3072 -X- _ O
for -X- _ O
the -X- _ O
H -X- _ B-HyperparameterName
= -X- _ O
768 -X- _ B-HyperparameterValue
and -X- _ O
4096 -X- _ B-HyperparameterValue
for -X- _ O
the -X- _ O
H -X- _ B-HyperparameterName
= -X- _ O
1024 -X- _ B-HyperparameterValue
. -X- _ O
4We -X- _ O
note -X- _ O
that -X- _ O
in -X- _ O
the -X- _ O
literature -X- _ O
the -X- _ O
bidirectional -X- _ O
Trans- -X- _ O

We -X- _ O
primarily -X- _ O
report -X- _ O
results -X- _ O
on -X- _ O
two -X- _ O
model -X- _ O
sizes -X- _ O
: -X- _ O
BERTBASE -X- _ B-MethodName
( -X- _ O
L=12 -X- _ B-HyperparameterName
, -X- _ O
H=768 -X- _ B-HyperparameterName
, -X- _ O
A=12 -X- _ B-HyperparameterName
, -X- _ O
Total -X- _ B-HyperparameterName
Param- -X- _ I-HyperparameterName
eters=110 -X- _ I-HyperparameterName
M -X- _ O
) -X- _ O
and -X- _ O
BERTLARGE -X- _ B-MethodName
( -X- _ O
L=24 -X- _ B-HyperparameterName
, -X- _ O
H=1024 -X- _ B-HyperparameterName
, -X- _ O
A=16 -X- _ B-HyperparameterName
, -X- _ O
Total -X- _ B-HyperparameterName
Parameters=340 -X- _ I-HyperparameterName
M -X- _ O
) -X- _ O
. -X- _ O
BERTBASE -X- _ B-MethodName
was -X- _ O
chosen -X- _ O
to -X- _ O
have -X- _ O
the -X- _ O
same -X- _ O
model -X- _ O
size -X- _ O
as -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
for -X- _ O
comparison -X- _ O
purposes -X- _ O
. -X- _ O
Critically -X- _ O
, -X- _ O
however -X- _ O
, -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
Transformer -X- _ O
uses -X- _ O
bidirectional -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
, -X- _ O
while -X- _ O
the -X- _ O
GPT -X- _ B-MethodName
Trans- -X- _ O
former -X- _ O
uses -X- _ O
constrained -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
where -X- _ O
every -X- _ O
token -X- _ O
can -X- _ O
only -X- _ O
attend -X- _ O
to -X- _ O
context -X- _ O
to -X- _ O
its -X- _ O
left.4 -X- _ O

In -X- _ O
this -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
denote -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
( -X- _ O
i.e. -X- _ O
, -X- _ O
Transformer -X- _ O
blocks -X- _ O
) -X- _ O
as -X- _ O
L -X- _ B-HyperparameterName
, -X- _ O
the -X- _ O
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
as -X- _ O
H -X- _ B-HyperparameterName
, -X- _ O
and -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
self -X- _ I-HyperparameterName
- -X- _ I-HyperparameterName
attention -X- _ I-HyperparameterName
heads -X- _ I-HyperparameterName
as -X- _ O
A.3 -X- _ B-HyperparameterName

Model -X- _ O
Architecture -X- _ O
BERT -X- _ B-MethodName
’s -X- _ O
model -X- _ O
architec- -X- _ O
ture -X- _ O
is -X- _ O
a -X- _ O
multi -X- _ O
- -X- _ O
layer -X- _ O
bidirectional -X- _ O
Transformer -X- _ O
en- -X- _ O
coder -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
implementation -X- _ O
de- -X- _ O
scribed -X- _ O
in -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
released -X- _ O
in -X- _ O
the -X- _ O
tensor2tensor -X- _ O
library.1 -X- _ O
Because -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
Transformers -X- _ O
has -X- _ O
become -X- _ O
common -X- _ O
and -X- _ O
our -X- _ O
im- -X- _ O
plementation -X- _ O
is -X- _ O
almost -X- _ O
identical -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
, -X- _ O
we -X- _ O
will -X- _ O
omit -X- _ O
an -X- _ O
exhaustive -X- _ O
background -X- _ O
descrip- -X- _ O
tion -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
architecture -X- _ O
and -X- _ O
refer -X- _ O
readers -X- _ O
to -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2017 -X- _ O
) -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
excellent -X- _ O
guides -X- _ O
such -X- _ O
as -X- _ O
“ -X- _ O
The -X- _ O
Annotated -X- _ O
Transformer -X- _ O
. -X- _ O
”2 -X- _ O

mal -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
architec- -X- _ O
ture -X- _ O
and -X- _ O
the -X- _ O
ﬁnal -X- _ O
downstream -X- _ O
architecture -X- _ O
. -X- _ O

We -X- _ O
introduce -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
its -X- _ O
detailed -X- _ O
implementa- -X- _ O
tion -X- _ O
in -X- _ O
this -X- _ O
section -X- _ O
. -X- _ O
There -X- _ O
are -X- _ O
two -X- _ O
steps -X- _ O
in -X- _ O
our -X- _ O
framework -X- _ O
: -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O
Dur- -X- _ O
ing -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
unlabeled -X- _ O
data -X- _ O
over -X- _ O
different -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
tasks -X- _ O
. -X- _ O
For -X- _ O
ﬁne- -X- _ O
tuning -X- _ O
, -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
is -X- _ O
ﬁrst -X- _ O
initialized -X- _ O
with -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
parameters -X- _ O
, -X- _ O
and -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
param- -X- _ O
eters -X- _ O
are -X- _ O
ﬁne -X- _ O
- -X- _ O
tuned -X- _ O
using -X- _ O
labeled -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
Each -X- _ O
downstream -X- _ O
task -X- _ O
has -X- _ O
sep- -X- _ O
arate -X- _ O
ﬁne -X- _ O
- -X- _ O
tuned -X- _ O
models -X- _ O
, -X- _ O
even -X- _ O
though -X- _ O
they -X- _ O
are -X- _ O
ini- -X- _ O
tialized -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
parameters -X- _ O
. -X- _ O
The -X- _ O
question -X- _ O
- -X- _ O
answering -X- _ O
example -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
will -X- _ O
serve -X- _ O
as -X- _ O
a -X- _ O
running -X- _ O
example -X- _ O
for -X- _ O
this -X- _ O
section -X- _ O
. -X- _ O
A -X- _ O
distinctive -X- _ O
feature -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
its -X- _ O
uniﬁed -X- _ O
ar- -X- _ O
chitecture -X- _ O
across -X- _ O
different -X- _ O
tasks -X- _ O
. -X- _ O
There -X- _ O
is -X- _ O
mini- -X- _ O

There -X- _ O
has -X- _ O
also -X- _ O
been -X- _ O
work -X- _ O
showing -X- _ O
effective -X- _ O
trans- -X- _ O
fer -X- _ O
from -X- _ O
supervised -X- _ O
tasks -X- _ O
with -X- _ O
large -X- _ O
datasets -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
inference -X- _ I-TaskName
( -X- _ O
Conneau -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
and -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
( -X- _ O
McCann -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
Computer -X- _ B-TaskName
vision -X- _ I-TaskName
research -X- _ O
has -X- _ O
also -X- _ O
demon- -X- _ O
strated -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
transfer -X- _ O
learning -X- _ O
from -X- _ O
large -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
, -X- _ O
where -X- _ O
an -X- _ O
effective -X- _ O
recipe -X- _ O
is -X- _ O
to -X- _ O
ﬁne -X- _ O
- -X- _ O
tune -X- _ O
models -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
with -X- _ O
Ima- -X- _ B-DatasetName
geNet -X- _ I-DatasetName
( -X- _ O
Deng -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2009 -X- _ O
; -X- _ O
Yosinski -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O

ing -X- _ O
and -X- _ O
auto -X- _ O
- -X- _ O
encoder -X- _ O
objectives -X- _ O
have -X- _ O
been -X- _ O
used -X- _ O
for -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
such -X- _ O
models -X- _ O
( -X- _ O
Howard -X- _ O
and -X- _ O
Ruder -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Dai -X- _ O
and -X- _ O
Le -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O

Figure -X- _ O
1 -X- _ O
: -X- _ O
Overall -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
procedures -X- _ O
for -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
Apart -X- _ O
from -X- _ O
output -X- _ O
layers -X- _ O
, -X- _ O
the -X- _ O
same -X- _ O
architec- -X- _ O
tures -X- _ O
are -X- _ O
used -X- _ O
in -X- _ O
both -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O
The -X- _ O
same -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
model -X- _ O
parameters -X- _ O
are -X- _ O
used -X- _ O
to -X- _ O
initialize -X- _ O
models -X- _ O
for -X- _ O
different -X- _ O
down -X- _ O
- -X- _ O
stream -X- _ O
tasks -X- _ O
. -X- _ O
During -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
, -X- _ O
all -X- _ O
parameters -X- _ O
are -X- _ O
ﬁne -X- _ O
- -X- _ O
tuned -X- _ O
. -X- _ O
[ -X- _ O
CLS -X- _ O
] -X- _ O
is -X- _ O
a -X- _ O
special -X- _ O
symbol -X- _ O
added -X- _ O
in -X- _ O
front -X- _ O
of -X- _ O
every -X- _ O
input -X- _ O
example -X- _ O
, -X- _ O
and -X- _ O
[ -X- _ O
SEP -X- _ O
] -X- _ O
is -X- _ O
a -X- _ O
special -X- _ O
separator -X- _ O
token -X- _ O
( -X- _ O
e.g. -X- _ O
separating -X- _ O
ques- -X- _ O
tions -X- _ O
/ -X- _ O
answers -X- _ O
) -X- _ O
. -X- _ O

As -X- _ O
with -X- _ O
the -X- _ O
feature -X- _ O
- -X- _ O
based -X- _ O
approaches -X- _ O
, -X- _ O
the -X- _ O
ﬁrst -X- _ O
works -X- _ O
in -X- _ O
this -X- _ O
direction -X- _ O
only -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
word -X- _ O
em- -X- _ O
bedding -X- _ O
parameters -X- _ O
from -X- _ O
unlabeled -X- _ O
text -X- _ O
( -X- _ O
Col- -X- _ O
lobert -X- _ O
and -X- _ O
Weston -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
. -X- _ O
More -X- _ O
recently -X- _ O
, -X- _ O
sentence -X- _ O
or -X- _ O
document -X- _ O
encoders -X- _ O
which -X- _ O
produce -X- _ O
contextual -X- _ O
token -X- _ O
representations -X- _ O
have -X- _ O
been -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
from -X- _ O
unlabeled -X- _ O
text -X- _ O
and -X- _ O
ﬁne -X- _ O
- -X- _ O
tuned -X- _ O
for -X- _ O
a -X- _ O
supervised -X- _ O
downstream -X- _ O
task -X- _ O
( -X- _ O
Dai -X- _ O
and -X- _ O
Le -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Howard -X- _ O
and -X- _ O
Ruder -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
advantage -X- _ O
of -X- _ O
these -X- _ O
approaches -X- _ O
is -X- _ O
that -X- _ O
few -X- _ O
parameters -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
learned -X- _ O
from -X- _ O
scratch -X- _ O
. -X- _ O
At -X- _ O
least -X- _ O
partly -X- _ O
due -X- _ O
to -X- _ O
this -X- _ O
advantage -X- _ O
, -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
achieved -X- _ O
pre- -X- _ O
viously -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
results -X- _ O
on -X- _ O
many -X- _ O
sentence- -X- _ O
level -X- _ O
tasks -X- _ O
from -X- _ O
the -X- _ O
GLUE -X- _ B-MetricName
benchmark -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
. -X- _ O
Left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
language -X- _ O
model- -X- _ O

2018a -X- _ O
) -X- _ O
generalize -X- _ O
traditional -X- _ O
word -X- _ O
embedding -X- _ O
re- -X- _ O
search -X- _ O
along -X- _ O
a -X- _ O
different -X- _ O
dimension -X- _ O
. -X- _ O
They -X- _ O
extract -X- _ O
context -X- _ O
- -X- _ O
sensitive -X- _ O
features -X- _ O
from -X- _ O
a -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
and -X- _ O
a -X- _ O
right -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
left -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O
The -X- _ O
contextual -X- _ O
rep- -X- _ O
resentation -X- _ O
of -X- _ O
each -X- _ O
token -X- _ O
is -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
the -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
and -X- _ O
right -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
left -X- _ O
representations -X- _ O
. -X- _ O
When -X- _ O
integrating -X- _ O
contextual -X- _ O
word -X- _ O
embeddings -X- _ O
with -X- _ O
existing -X- _ O
task -X- _ O
- -X- _ O
speciﬁc -X- _ O
architectures -X- _ O
, -X- _ O
ELMo -X- _ B-MethodName
advances -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
for -X- _ O
several -X- _ O
major -X- _ O
NLP -X- _ B-TaskName
benchmarks -X- _ O
( -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
including -X- _ O
ques- -X- _ B-TaskName
tion -X- _ I-TaskName
answering -X- _ I-TaskName
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
, -X- _ O
sentiment -X- _ B-TaskName
analysis -X- _ I-TaskName
( -X- _ O
Socher -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
named -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
( -X- _ O
Tjong -X- _ O
Kim -X- _ O
Sang -X- _ O
and -X- _ O
De -X- _ O
Meulder -X- _ O
, -X- _ O
2003 -X- _ O
) -X- _ O
. -X- _ O
Melamud -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
proposed -X- _ O
learning -X- _ O
contextual -X- _ O
representations -X- _ O
through -X- _ O
a -X- _ O
task -X- _ O
to -X- _ O
pre- -X- _ O
dict -X- _ O
a -X- _ O
single -X- _ O
word -X- _ O
from -X- _ O
both -X- _ O
left -X- _ O
and -X- _ O
right -X- _ O
context -X- _ O
using -X- _ O
LSTMs -X- _ B-MethodName
. -X- _ O
Similar -X- _ O
to -X- _ O
ELMo -X- _ B-MethodName
, -X- _ O
their -X- _ O
model -X- _ O
is -X- _ O
feature -X- _ O
- -X- _ O
based -X- _ O
and -X- _ O
not -X- _ O
deeply -X- _ O
bidirectional -X- _ O
. -X- _ O
Fedus -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
cloze -X- _ O
task -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
robustness -X- _ O
of -X- _ O
text -X- _ O
generation -X- _ O
mod- -X- _ O
els -X- _ O
. -X- _ O

These -X- _ O
approaches -X- _ O
have -X- _ O
been -X- _ O
generalized -X- _ O
to -X- _ O
coarser -X- _ O
granularities -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
sentence -X- _ O
embed- -X- _ O
dings -X- _ O
( -X- _ O
Kiros -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Logeswaran -X- _ O
and -X- _ O
Lee -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
or -X- _ O
paragraph -X- _ O
embeddings -X- _ O
( -X- _ O
Le -X- _ O
and -X- _ O
Mikolov -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
train -X- _ O
sentence -X- _ O
representations -X- _ O
, -X- _ O
prior -X- _ O
work -X- _ O
has -X- _ O
used -X- _ O
objectives -X- _ O
to -X- _ O
rank -X- _ O
candidate -X- _ O
next -X- _ O
sentences -X- _ O
( -X- _ O
Jernite -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Logeswaran -X- _ O
and -X- _ O
Lee -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
generation -X- _ O
of -X- _ O
next -X- _ O
sen- -X- _ O
tence -X- _ O
words -X- _ O
given -X- _ O
a -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
previous -X- _ O
sentence -X- _ O
( -X- _ O
Kiros -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
, -X- _ O
or -X- _ O
denoising -X- _ O
auto- -X- _ O
encoder -X- _ O
derived -X- _ O
objectives -X- _ O
( -X- _ O
Hill -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
ELMo -X- _ O
and -X- _ O
its -X- _ O
predecessor -X- _ O
( -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
, -X- _ O

Learning -X- _ O
widely -X- _ O
applicable -X- _ O
representations -X- _ O
of -X- _ O
words -X- _ O
has -X- _ O
been -X- _ O
an -X- _ O
active -X- _ O
area -X- _ O
of -X- _ O
research -X- _ O
for -X- _ O
decades -X- _ O
, -X- _ O
including -X- _ O
non -X- _ O
- -X- _ O
neural -X- _ O
( -X- _ O
Brown -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
1992 -X- _ O
; -X- _ O
Ando -X- _ O
and -X- _ O
Zhang -X- _ O
, -X- _ O
2005 -X- _ O
; -X- _ O
Blitzer -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2006 -X- _ O
) -X- _ O
and -X- _ O
neural -X- _ O
( -X- _ O
Mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
; -X- _ O
Pennington -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
methods -X- _ O
. -X- _ O
Pre -X- _ O
- -X- _ O
trained -X- _ O
word -X- _ O
embeddings -X- _ O
are -X- _ O
an -X- _ O
integral -X- _ O
part -X- _ O
of -X- _ O
modern -X- _ O
NLP -X- _ B-TaskName
systems -X- _ O
, -X- _ O
of- -X- _ O
fering -X- _ O
signiﬁcant -X- _ O
improvements -X- _ O
over -X- _ O
embeddings -X- _ O
learned -X- _ O
from -X- _ O
scratch -X- _ O
( -X- _ O
Turian -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
. -X- _ O
To -X- _ O
pre- -X- _ O
train -X- _ O
word -X- _ O
embedding -X- _ O
vectors -X- _ O
, -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
lan- -X- _ O
guage -X- _ O
modeling -X- _ O
objectives -X- _ O
have -X- _ O
been -X- _ O
used -X- _ O
( -X- _ O
Mnih -X- _ O
and -X- _ O
Hinton -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
objectives -X- _ O
to -X- _ O
dis- -X- _ O
criminate -X- _ O
correct -X- _ O
from -X- _ O
incorrect -X- _ O
words -X- _ O
in -X- _ O
left -X- _ O
and -X- _ O
right -X- _ O
context -X- _ O
( -X- _ O
Mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O

There -X- _ O
is -X- _ O
a -X- _ O
long -X- _ O
history -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
general -X- _ O
lan- -X- _ O
guage -X- _ O
representations -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
brieﬂy -X- _ O
review -X- _ O
the -X- _ O
most -X- _ O
widely -X- _ O
- -X- _ O
used -X- _ O
approaches -X- _ O
in -X- _ O
this -X- _ O
section -X- _ O
. -X- _ O

• -X- _ O
BERT -X- _ B-MethodName
advances -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
for -X- _ O
eleven -X- _ O
NLP -X- _ B-TaskName
tasks -X- _ O
. -X- _ O
The -X- _ O
code -X- _ O
and -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
mod- -X- _ O
els -X- _ O
are -X- _ O
available -X- _ O
at -X- _ O
https://github.com/ -X- _ O
google -X- _ O
- -X- _ O
research -X- _ O
/ -X- _ O
bert -X- _ O
. -X- _ O

• -X- _ O
We -X- _ O
show -X- _ O
that -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
representations -X- _ O
reduce -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
many -X- _ O
heavily -X- _ O
- -X- _ O
engineered -X- _ O
task- -X- _ O
speciﬁc -X- _ O
architectures -X- _ O
. -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
the -X- _ O
ﬁrst -X- _ O
ﬁne- -X- _ O
tuning -X- _ O
based -X- _ O
representation -X- _ O
model -X- _ O
that -X- _ O
achieves -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
performance -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
suite -X- _ O
of -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
and -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
tasks -X- _ O
, -X- _ O
outper- -X- _ O
forming -X- _ O
many -X- _ O
task -X- _ O
- -X- _ O
speciﬁc -X- _ O
architectures -X- _ O
. -X- _ O

• -X- _ O
We -X- _ O
demonstrate -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
bidirectional -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
for -X- _ O
language -X- _ O
representations -X- _ O
. -X- _ O
Un- -X- _ O
like -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
uses -X- _ O
unidirec- -X- _ O
tional -X- _ O
language -X- _ O
models -X- _ O
for -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
uses -X- _ O
masked -X- _ O
language -X- _ O
models -X- _ O
to -X- _ O
enable -X- _ O
pre- -X- _ O
trained -X- _ O
deep -X- _ O
bidirectional -X- _ O
representations -X- _ O
. -X- _ O
This -X- _ O
is -X- _ O
also -X- _ O
in -X- _ O
contrast -X- _ O
to -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2018a -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
uses -X- _ O
a -X- _ O
shallow -X- _ O
concatenation -X- _ O
of -X- _ O
independently -X- _ O
trained -X- _ O
left -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
right -X- _ O
and -X- _ O
right -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
left -X- _ O
LMs -X- _ B-MethodName
. -X- _ O

word -X- _ O
based -X- _ O
only -X- _ O
on -X- _ O
its -X- _ O
context -X- _ O
. -X- _ O
Unlike -X- _ O
left -X- _ O
- -X- _ O
to- -X- _ O
right -X- _ O
language -X- _ O
model -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
the -X- _ O
MLM -X- _ B-MethodName
ob- -X- _ O
jective -X- _ O
enables -X- _ O
the -X- _ O
representation -X- _ O
to -X- _ O
fuse -X- _ O
the -X- _ O
left -X- _ O
and -X- _ O
the -X- _ O
right -X- _ O
context -X- _ O
, -X- _ O
which -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
pre- -X- _ O
train -X- _ O
a -X- _ O
deep -X- _ O
bidirectional -X- _ O
Transformer -X- _ O
. -X- _ O
In -X- _ O
addi- -X- _ O
tion -X- _ O
to -X- _ O
the -X- _ O
masked -X- _ B-MethodName
language -X- _ I-MethodName
model -X- _ I-MethodName
, -X- _ O
we -X- _ O
also -X- _ O
use -X- _ O
a -X- _ O
“ -X- _ O
next -X- _ B-TaskName
sentence -X- _ I-TaskName
prediction -X- _ I-TaskName
” -X- _ O
task -X- _ O
that -X- _ O
jointly -X- _ O
pre- -X- _ O
trains -X- _ O
text -X- _ O
- -X- _ O
pair -X- _ O
representations -X- _ O
. -X- _ O
The -X- _ O
contributions -X- _ O
of -X- _ O
our -X- _ O
paper -X- _ O
are -X- _ O
as -X- _ O
follows -X- _ O
: -X- _ O

There -X- _ O
are -X- _ O
two -X- _ O
existing -X- _ O
strategies -X- _ O
for -X- _ O
apply- -X- _ O
ing -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
language -X- _ O
representations -X- _ O
to -X- _ O
down- -X- _ O
stream -X- _ O
tasks -X- _ O
: -X- _ O
feature -X- _ O
- -X- _ O
based -X- _ O
and -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O
The -X- _ O
feature -X- _ O
- -X- _ O
based -X- _ O
approach -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
ELMo -X- _ B-MethodName
( -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
) -X- _ O
, -X- _ O
uses -X- _ O
task -X- _ O
- -X- _ O
speciﬁc -X- _ O
architectures -X- _ O
that -X- _ O
include -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
representations -X- _ O
as -X- _ O
addi- -X- _ O
tional -X- _ O
features -X- _ O
. -X- _ O
The -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
approach -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
Generative -X- _ O
Pre -X- _ O
- -X- _ O
trained -X- _ O
Transformer -X- _ O
( -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
) -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
introduces -X- _ O
minimal -X- _ O
task -X- _ O
- -X- _ O
speciﬁc -X- _ O
parameters -X- _ O
, -X- _ O
and -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
downstream -X- _ O
tasks -X- _ O
by -X- _ O
simply -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
all -X- _ O
pre- -X- _ O
trained -X- _ O
parameters -X- _ O
. -X- _ O
The -X- _ O
two -X- _ O
approaches -X- _ O
share -X- _ O
the -X- _ O
same -X- _ O
objective -X- _ O
function -X- _ O
during -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
where -X- _ O
they -X- _ O
use -X- _ O
unidirectional -X- _ O
language -X- _ O
models -X- _ O
to -X- _ O
learn -X- _ O
general -X- _ O
language -X- _ O
representations -X- _ O
. -X- _ O
We -X- _ O
argue -X- _ O
that -X- _ O
current -X- _ O
techniques -X- _ O
restrict -X- _ O
the -X- _ O
power -X- _ O
of -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
representations -X- _ O
, -X- _ O
espe- -X- _ O
cially -X- _ O
for -X- _ O
the -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
approaches -X- _ O
. -X- _ O
The -X- _ O
ma- -X- _ O
jor -X- _ O
limitation -X- _ O
is -X- _ O
that -X- _ O
standard -X- _ O
language -X- _ O
models -X- _ O
are -X- _ O
unidirectional -X- _ O
, -X- _ O
and -X- _ O
this -X- _ O
limits -X- _ O
the -X- _ O
choice -X- _ O
of -X- _ O
archi- -X- _ O
tectures -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
during -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
in -X- _ O
OpenAI -X- _ B-MethodName
GPT -X- _ I-MethodName
, -X- _ O
the -X- _ O
authors -X- _ O
use -X- _ O
a -X- _ O
left -X- _ O
- -X- _ O
to- -X- _ O
right -X- _ O
architecture -X- _ O
, -X- _ O
where -X- _ O
every -X- _ O
token -X- _ O
can -X- _ O
only -X- _ O
at- -X- _ O
tend -X- _ O
to -X- _ O
previous -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
layers -X- _ O
of -X- _ O
the -X- _ O
Transformer -X- _ B-MethodName
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
. -X- _ O
Such -X- _ O
re- -X- _ O
strictions -X- _ O
are -X- _ O
sub -X- _ O
- -X- _ O
optimal -X- _ O
for -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
tasks -X- _ O
, -X- _ O
and -X- _ O
could -X- _ O
be -X- _ O
very -X- _ O
harmful -X- _ O
when -X- _ O
applying -X- _ O
ﬁne- -X- _ O
tuning -X- _ O
based -X- _ O
approaches -X- _ O
to -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
, -X- _ O
where -X- _ O
it -X- _ O
is -X- _ O
crucial -X- _ O
to -X- _ O
incor- -X- _ O
porate -X- _ O
context -X- _ O
from -X- _ O
both -X- _ O
directions -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
, -X- _ O
we -X- _ O
improve -X- _ O
the -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
based -X- _ O
approaches -X- _ O
by -X- _ O
proposing -X- _ O
BERT -X- _ B-MethodName
: -X- _ O
Bidirectional -X- _ B-MethodName
Encoder -X- _ I-MethodName
Representations -X- _ I-MethodName
from -X- _ I-MethodName
Transformers -X- _ I-MethodName
. -X- _ O
BERT -X- _ B-MethodName
alleviates -X- _ O
the -X- _ O
previously -X- _ O
mentioned -X- _ O
unidi- -X- _ O
rectionality -X- _ O
constraint -X- _ O
by -X- _ O
using -X- _ O
a -X- _ O
“ -X- _ O
masked -X- _ B-MethodName
lan- -X- _ I-MethodName
guage -X- _ I-MethodName
model -X- _ I-MethodName
” -X- _ O
( -X- _ O
MLM -X- _ B-MethodName
) -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
objective -X- _ O
, -X- _ O
in- -X- _ O
spired -X- _ O
by -X- _ O
the -X- _ O
Cloze -X- _ O
task -X- _ O
( -X- _ O
Taylor -X- _ O
, -X- _ O
1953 -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
masked -X- _ B-MethodName
language -X- _ I-MethodName
model -X- _ I-MethodName
randomly -X- _ O
masks -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
tokens -X- _ O
from -X- _ O
the -X- _ O
input -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
objective -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
original -X- _ O
vocabulary -X- _ O
i -X- _ O
d -X- _ O
of -X- _ O
the -X- _ O
masked -X- _ O

Table -X- _ O
6 -X- _ O
: -X- _ O
Ablation -X- _ O
over -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
size -X- _ O
. -X- _ O
# -X- _ O
L -X- _ B-HyperparameterName
= -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
; -X- _ O
# -X- _ O
H -X- _ B-HyperparameterName
= -X- _ O
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
; -X- _ O
# -X- _ O
A -X- _ B-HyperparameterName
= -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
at- -X- _ I-HyperparameterName
tention -X- _ I-HyperparameterName
heads -X- _ I-HyperparameterName
. -X- _ O
“ -X- _ O
LM -X- _ B-MethodName
( -X- _ O
ppl -X- _ O
) -X- _ O
” -X- _ O
is -X- _ O
the -X- _ O
masked -X- _ O
LM -X- _ B-MethodName
perplexity -X- _ O
of -X- _ O
held -X- _ O
- -X- _ O
out -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O

Mandar -X- _ O
Joshi -X- _ O
, -X- _ O
Eunsol -X- _ O
Choi -X- _ O
, -X- _ O
Daniel -X- _ O
S -X- _ O
Weld -X- _ O
, -X- _ O
and -X- _ O
Luke -X- _ O
Zettlemoyer -X- _ O
. -X- _ O
2017 -X- _ O
. -X- _ O
Triviaqa -X- _ O
: -X- _ O
A -X- _ O
large -X- _ O
scale -X- _ O
distantly -X- _ O
supervised -X- _ O
challenge -X- _ O
dataset -X- _ O
for -X- _ O
reading -X- _ O
comprehen- -X- _ O
sion -X- _ O
. -X- _ O
In -X- _ O
ACL -X- _ O
. -X- _ O

Ryan -X- _ O
Kiros -X- _ O
, -X- _ O
Yukun -X- _ O
Zhu -X- _ O
, -X- _ O
Ruslan -X- _ O
R -X- _ O
Salakhutdinov -X- _ O
, -X- _ O
Richard -X- _ O
Zemel -X- _ O
, -X- _ O
Raquel -X- _ O
Urtasun -X- _ O
, -X- _ O
Antonio -X- _ O
Torralba -X- _ O
, -X- _ O
and -X- _ O
Sanja -X- _ O
Fidler -X- _ O
. -X- _ O
2015 -X- _ O
. -X- _ O
Skip -X- _ O
- -X- _ O
thought -X- _ O
vectors -X- _ O
. -X- _ O
In -X- _ O
Advances -X- _ O
in -X- _ O
neural -X- _ O
information -X- _ O
processing -X- _ O
systems -X- _ O
, -X- _ O
pages -X- _ O
3294–3302 -X- _ O
. -X- _ O

Quoc -X- _ O
Le -X- _ O
and -X- _ O
Tomas -X- _ O
Mikolov -X- _ O
. -X- _ O
2014 -X- _ O
. -X- _ O
Distributed -X- _ O
rep- -X- _ O
resentations -X- _ O
of -X- _ O
sentences -X- _ O
and -X- _ O
documents -X- _ O
. -X- _ O
In -X- _ O
Inter- -X- _ O
national -X- _ O
Conference -X- _ O
on -X- _ O
Machine -X- _ O
Learning -X- _ O
, -X- _ O
pages -X- _ O
1188–1196 -X- _ O
. -X- _ O

Lajanugen -X- _ O
Logeswaran -X- _ O
and -X- _ O
Honglak -X- _ O
Lee -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O
An -X- _ O
efﬁcient -X- _ O
framework -X- _ O
for -X- _ O
learning -X- _ O
sentence -X- _ O
represen- -X- _ O
tations -X- _ O
. -X- _ O
In -X- _ O
International -X- _ O
Conference -X- _ O
on -X- _ O
Learning -X- _ O
Representations -X- _ O
. -X- _ O

Hector -X- _ O
J -X- _ O
Levesque -X- _ O
, -X- _ O
Ernest -X- _ O
Davis -X- _ O
, -X- _ O
and -X- _ O
Leora -X- _ O
Morgen- -X- _ O
stern -X- _ O
. -X- _ O
2011 -X- _ O
. -X- _ O
The -X- _ O
winograd -X- _ O
schema -X- _ O
challenge -X- _ O
. -X- _ O
In -X- _ O
Aaai -X- _ O
spring -X- _ O
symposium -X- _ O
: -X- _ O
Logical -X- _ O
formalizations -X- _ O
of -X- _ O
commonsense -X- _ O
reasoning -X- _ O
, -X- _ O
volume -X- _ O
46 -X- _ O
, -X- _ O
page -X- _ O
47 -X- _ O
. -X- _ O

Bryan -X- _ O
McCann -X- _ O
, -X- _ O
James -X- _ O
Bradbury -X- _ O
, -X- _ O
Caiming -X- _ O
Xiong -X- _ O
, -X- _ O
and -X- _ O
Richard -X- _ O
Socher -X- _ O
. -X- _ O
2017 -X- _ O
. -X- _ O
Learned -X- _ O
in -X- _ O
translation -X- _ O
: -X- _ O
Con- -X- _ O
textualized -X- _ O
word -X- _ O
vectors -X- _ O
. -X- _ O
In -X- _ O
NIPS -X- _ O
. -X- _ O

Oren -X- _ O
Melamud -X- _ O
, -X- _ O
Jacob -X- _ O
Goldberger -X- _ O
, -X- _ O
and -X- _ O
Ido -X- _ O
Dagan -X- _ O
. -X- _ O
2016 -X- _ O
. -X- _ O
context2vec -X- _ O
: -X- _ O
Learning -X- _ O
generic -X- _ O
context -X- _ O
em- -X- _ O
bedding -X- _ O
with -X- _ O
bidirectional -X- _ B-MethodName
LSTM -X- _ I-MethodName
. -X- _ O
In -X- _ O
CoNLL -X- _ O
. -X- _ O

Tomas -X- _ O
Mikolov -X- _ O
, -X- _ O
Ilya -X- _ O
Sutskever -X- _ O
, -X- _ O
Kai -X- _ O
Chen -X- _ O
, -X- _ O
Greg -X- _ O
S -X- _ O
Cor- -X- _ O
rado -X- _ O
, -X- _ O
and -X- _ O
Jeff -X- _ O
Dean -X- _ O
. -X- _ O
2013 -X- _ O
. -X- _ O
Distributed -X- _ O
representa- -X- _ O
tions -X- _ O
of -X- _ O
words -X- _ O
and -X- _ O
phrases -X- _ O
and -X- _ O
their -X- _ O
compositional- -X- _ O
ity -X- _ O
. -X- _ O
In -X- _ O
Advances -X- _ O
in -X- _ O
Neural -X- _ O
Information -X- _ O
Processing -X- _ O
Systems -X- _ O
26 -X- _ O
, -X- _ O
pages -X- _ O
3111–3119 -X- _ O
. -X- _ O
Curran -X- _ O
Associates -X- _ O
, -X- _ O
Inc. -X- _ O

Andriy -X- _ O
Mnih -X- _ O
and -X- _ O
Geoffrey -X- _ O
E -X- _ O
Hinton -X- _ O
. -X- _ O
2009 -X- _ O
. -X- _ O
A -X- _ O
scal- -X- _ O
able -X- _ O
hierarchical -X- _ O
distributed -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O
In -X- _ O
D. -X- _ O
Koller -X- _ O
, -X- _ O
D. -X- _ O
Schuurmans -X- _ O
, -X- _ O
Y. -X- _ O
Bengio -X- _ O
, -X- _ O
and -X- _ O
L. -X- _ O
Bot- -X- _ O
tou -X- _ O
, -X- _ O
editors -X- _ O
, -X- _ O
Advances -X- _ O
in -X- _ O
Neural -X- _ O
Information -X- _ O
Pro- -X- _ O
cessing -X- _ O
Systems -X- _ O
21 -X- _ O
, -X- _ O
pages -X- _ O
1081–1088 -X- _ O
. -X- _ O
Curran -X- _ O
As- -X- _ O
sociates -X- _ O
, -X- _ O
Inc. -X- _ O

Ankur -X- _ O
P -X- _ O
Parikh -X- _ O
, -X- _ O
Oscar -X- _ O
T¨ackstr¨om -X- _ O
, -X- _ O
Dipanjan -X- _ O
Das -X- _ O
, -X- _ O
and -X- _ O
Jakob -X- _ O
Uszkoreit -X- _ O
. -X- _ O
2016 -X- _ O
. -X- _ O
A -X- _ O
decomposable -X- _ O
attention -X- _ O
model -X- _ O
for -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
inference -X- _ I-TaskName
. -X- _ O
In -X- _ O
EMNLP -X- _ B-TaskName
. -X- _ O

Jeffrey -X- _ O
Pennington -X- _ O
, -X- _ O
Richard -X- _ O
Socher -X- _ O
, -X- _ O
and -X- _ O
Christo- -X- _ O
pher -X- _ O
D. -X- _ O
Manning -X- _ O
. -X- _ O
2014 -X- _ O
. -X- _ O
Glove -X- _ B-DatasetName
: -X- _ O
Global -X- _ B-DatasetName
vectors -X- _ I-DatasetName
for -X- _ I-DatasetName
word -X- _ I-DatasetName
representation -X- _ I-DatasetName
. -X- _ O
In -X- _ O
Empirical -X- _ B-TaskName
Methods -X- _ I-TaskName
in -X- _ I-TaskName
Nat- -X- _ I-TaskName
ural -X- _ I-TaskName
Language -X- _ I-TaskName
Processing -X- _ I-TaskName
( -X- _ O
EMNLP -X- _ B-TaskName
) -X- _ O
, -X- _ O
pages -X- _ O
1532 -X- _ O
– -X- _ O
1543 -X- _ O
. -X- _ O

Matthew -X- _ O
Peters -X- _ O
, -X- _ O
Waleed -X- _ O
Ammar -X- _ O
, -X- _ O
Chandra -X- _ O
Bhagavat- -X- _ O
ula -X- _ O
, -X- _ O
and -X- _ O
Russell -X- _ O
Power -X- _ O
. -X- _ O
2017 -X- _ O
. -X- _ O
Semi -X- _ O
- -X- _ O
supervised -X- _ O
se- -X- _ O
quence -X- _ O
tagging -X- _ O
with -X- _ O
bidirectional -X- _ O
language -X- _ O
models -X- _ O
. -X- _ O
In -X- _ O
ACL -X- _ O
. -X- _ O

Matthew -X- _ O
Peters -X- _ O
, -X- _ O
Mark -X- _ O
Neumann -X- _ O
, -X- _ O
Mohit -X- _ O
Iyyer -X- _ O
, -X- _ O
Matt -X- _ O
Gardner -X- _ O
, -X- _ O
Christopher -X- _ O
Clark -X- _ O
, -X- _ O
Kenton -X- _ O
Lee -X- _ O
, -X- _ O
and -X- _ O
Luke -X- _ O
Zettlemoyer -X- _ O
. -X- _ O
2018a -X- _ O
. -X- _ O
Deep -X- _ O
contextualized -X- _ O
word -X- _ O
rep- -X- _ O
resentations -X- _ O
. -X- _ O
In -X- _ O
NAACL -X- _ O
. -X- _ O

Matthew -X- _ O
Peters -X- _ O
, -X- _ O
Mark -X- _ O
Neumann -X- _ O
, -X- _ O
Luke -X- _ O
Zettlemoyer -X- _ O
, -X- _ O
and -X- _ O
Wen -X- _ O
- -X- _ O
tau -X- _ O
Yih -X- _ O
. -X- _ O
2018b -X- _ O
. -X- _ O
Dissecting -X- _ O
contextual -X- _ O
word -X- _ O
embeddings -X- _ O
: -X- _ O
Architecture -X- _ O
and -X- _ O
representation -X- _ O
. -X- _ O
In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2018 -X- _ O
Conference -X- _ O
on -X- _ O
Empiri- -X- _ B-TaskName
cal -X- _ I-TaskName
Methods -X- _ I-TaskName
in -X- _ I-TaskName
Natural -X- _ I-TaskName
Language -X- _ I-TaskName
Processing -X- _ I-TaskName
, -X- _ O
pages -X- _ O
1499–1509 -X- _ O
. -X- _ O

Alec -X- _ O
Radford -X- _ O
, -X- _ O
Karthik -X- _ O
Narasimhan -X- _ O
, -X- _ O
Tim -X- _ O
Salimans -X- _ O
, -X- _ O
and -X- _ O
Ilya -X- _ O
Sutskever -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O
Improving -X- _ O
language -X- _ O
under- -X- _ O
standing -X- _ O
with -X- _ O
unsupervised -X- _ O
learning -X- _ O
. -X- _ O
Technical -X- _ O
re- -X- _ O
port -X- _ O
, -X- _ O
OpenAI -X- _ O
. -X- _ O

Pranav -X- _ O
Rajpurkar -X- _ O
, -X- _ O
Jian -X- _ O
Zhang -X- _ O
, -X- _ O
Konstantin -X- _ O
Lopyrev -X- _ O
, -X- _ O
and -X- _ O
Percy -X- _ O
Liang -X- _ O
. -X- _ O
2016 -X- _ O
. -X- _ O
Squad -X- _ O
: -X- _ O
100,000 -X- _ O
+ -X- _ O
questions -X- _ O
for -X- _ O
machine -X- _ O
comprehension -X- _ O
of -X- _ O
text -X- _ O
. -X- _ O
In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2016 -X- _ O
Conference -X- _ O
on -X- _ O
Empirical -X- _ O
Methods -X- _ O
in -X- _ O
Nat- -X- _ B-TaskName
ural -X- _ I-TaskName
Language -X- _ I-TaskName
Processing -X- _ I-TaskName
, -X- _ O
pages -X- _ O
2383–2392 -X- _ O
. -X- _ O

Minjoon -X- _ O
Seo -X- _ O
, -X- _ O
Aniruddha -X- _ O
Kembhavi -X- _ O
, -X- _ O
Ali -X- _ O
Farhadi -X- _ O
, -X- _ O
and -X- _ O
Hannaneh -X- _ O
Hajishirzi -X- _ O
. -X- _ O
2017 -X- _ O
. -X- _ O
Bidirectional -X- _ O
attention -X- _ O
ﬂow -X- _ O
for -X- _ O
machine -X- _ O
comprehension -X- _ O
. -X- _ O
In -X- _ O
ICLR -X- _ O
. -X- _ O

Richard -X- _ O
Socher -X- _ O
, -X- _ O
Alex -X- _ O
Perelygin -X- _ O
, -X- _ O
Jean -X- _ O
Wu -X- _ O
, -X- _ O
Jason -X- _ O
Chuang -X- _ O
, -X- _ O
Christopher -X- _ O
D -X- _ O
Manning -X- _ O
, -X- _ O
Andrew -X- _ O
Ng -X- _ O
, -X- _ O
and -X- _ O
Christopher -X- _ O
Potts -X- _ O
. -X- _ O
2013 -X- _ O
. -X- _ O
Recursive -X- _ O
deep -X- _ O
models -X- _ O
for -X- _ O
semantic -X- _ O
compositionality -X- _ O
over -X- _ O
a -X- _ O
sentiment -X- _ O
tree- -X- _ O
bank -X- _ O
. -X- _ O
In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2013 -X- _ O
conference -X- _ O
on -X- _ O
empirical -X- _ O
methods -X- _ O
in -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
processing -X- _ I-TaskName
, -X- _ O
pages -X- _ O
1631–1642 -X- _ O
. -X- _ O

Fu -X- _ O
Sun -X- _ O
, -X- _ O
Linyang -X- _ O
Li -X- _ O
, -X- _ O
Xipeng -X- _ O
Qiu -X- _ O
, -X- _ O
and -X- _ O
Yang -X- _ O
Liu -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O
U -X- _ O
- -X- _ O
net -X- _ O
: -X- _ O
Machine -X- _ O
reading -X- _ O
comprehension -X- _ O
with -X- _ O
unanswerable -X- _ O
questions -X- _ O
. -X- _ O
arXiv -X- _ O
preprint -X- _ O
arXiv:1810.06638 -X- _ O
. -X- _ O

Wilson -X- _ O
L -X- _ O
Taylor -X- _ O
. -X- _ O
1953 -X- _ O
. -X- _ O
Cloze -X- _ O
procedure -X- _ O
: -X- _ O
A -X- _ O
new -X- _ O
tool -X- _ O
for -X- _ O
measuring -X- _ O
readability -X- _ O
. -X- _ O
Journalism -X- _ O
Bulletin -X- _ O
, -X- _ O
30(4):415–433 -X- _ O
. -X- _ O

Erik -X- _ O
F -X- _ O
Tjong -X- _ O
Kim -X- _ O
Sang -X- _ O
and -X- _ O
Fien -X- _ O
De -X- _ O
Meulder -X- _ O
. -X- _ O
2003 -X- _ O
. -X- _ O
Introduction -X- _ O
to -X- _ O
the -X- _ O
conll-2003 -X- _ O
shared -X- _ O
task -X- _ O
: -X- _ O
Language -X- _ B-TaskName
- -X- _ I-TaskName
independent -X- _ I-TaskName
named -X- _ I-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
. -X- _ O
In -X- _ O
CoNLL -X- _ O
. -X- _ O

Joseph -X- _ O
Turian -X- _ O
, -X- _ O
Lev -X- _ O
Ratinov -X- _ O
, -X- _ O
and -X- _ O
Yoshua -X- _ O
Bengio -X- _ O
. -X- _ O
2010 -X- _ O
. -X- _ O
Word -X- _ O
representations -X- _ O
: -X- _ O
A -X- _ O
simple -X- _ O
and -X- _ O
general -X- _ O
method -X- _ O
for -X- _ O
semi -X- _ O
- -X- _ O
supervised -X- _ O
learning -X- _ O
. -X- _ O
In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
48th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
Association -X- _ O
for -X- _ O
Compu- -X- _ O
tational -X- _ O
Linguistics -X- _ O
, -X- _ O
ACL -X- _ O
’ -X- _ O
10 -X- _ O
, -X- _ O
pages -X- _ O
384–394 -X- _ O
. -X- _ O

Ashish -X- _ O
Vaswani -X- _ O
, -X- _ O
Noam -X- _ O
Shazeer -X- _ O
, -X- _ O
Niki -X- _ O
Parmar -X- _ O
, -X- _ O
Jakob -X- _ O
Uszkoreit -X- _ O
, -X- _ O
Llion -X- _ O
Jones -X- _ O
, -X- _ O
Aidan -X- _ O
N -X- _ O
Gomez -X- _ O
, -X- _ O
Lukasz -X- _ O
Kaiser -X- _ O
, -X- _ O
and -X- _ O
Illia -X- _ O
Polosukhin -X- _ O
. -X- _ O
2017 -X- _ O
. -X- _ O
Attention -X- _ O
is -X- _ O
all -X- _ O
you -X- _ O
need -X- _ O
. -X- _ O
In -X- _ O
Advances -X- _ O
in -X- _ O
Neural -X- _ O
Information -X- _ O
Pro- -X- _ O
cessing -X- _ O
Systems -X- _ O
, -X- _ O
pages -X- _ O
6000–6010 -X- _ O
. -X- _ O

Pascal -X- _ O
Vincent -X- _ O
, -X- _ O
Hugo -X- _ O
Larochelle -X- _ O
, -X- _ O
Yoshua -X- _ O
Bengio -X- _ O
, -X- _ O
and -X- _ O
Pierre -X- _ O
- -X- _ O
Antoine -X- _ O
Manzagol -X- _ O
. -X- _ O
2008 -X- _ O
. -X- _ O
Extracting -X- _ O
and -X- _ O
composing -X- _ O
robust -X- _ O
features -X- _ O
with -X- _ O
denoising -X- _ O
autoen- -X- _ O
coders -X- _ O
. -X- _ O
In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
25th -X- _ O
international -X- _ O
conference -X- _ O
on -X- _ O
Machine -X- _ O
learning -X- _ O
, -X- _ O
pages -X- _ O
1096–1103 -X- _ O
. -X- _ O
ACM -X- _ O
. -X- _ O

Alex -X- _ O
Wang -X- _ O
, -X- _ O
Amanpreet -X- _ O
Singh -X- _ O
, -X- _ O
Julian -X- _ O
Michael -X- _ O
, -X- _ O
Fe- -X- _ O
lix -X- _ O
Hill -X- _ O
, -X- _ O
Omer -X- _ O
Levy -X- _ O
, -X- _ O
and -X- _ O
Samuel -X- _ O
Bowman -X- _ O
. -X- _ O
2018a -X- _ O
. -X- _ O
Glue -X- _ O
: -X- _ O
A -X- _ O
multi -X- _ O
- -X- _ O
task -X- _ O
benchmark -X- _ O
and -X- _ O
analysis -X- _ O
platform -X- _ O

for -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding -X- _ I-TaskName
. -X- _ O
In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
2018 -X- _ O
EMNLP -X- _ O
Workshop -X- _ O
BlackboxNLP -X- _ O
: -X- _ O
An- -X- _ O
alyzing -X- _ O
and -X- _ O
Interpreting -X- _ O
Neural -X- _ O
Networks -X- _ O
for -X- _ O
NLP -X- _ O
, -X- _ O
pages -X- _ O
353–355 -X- _ O
. -X- _ O

Wei -X- _ O
Wang -X- _ O
, -X- _ O
Ming -X- _ O
Yan -X- _ O
, -X- _ O
and -X- _ O
Chen -X- _ O
Wu -X- _ O
. -X- _ O
2018b -X- _ O
. -X- _ O
Multi- -X- _ O
granularity -X- _ O
hierarchical -X- _ O
attention -X- _ O
fusion -X- _ O
networks -X- _ O
for -X- _ O
reading -X- _ B-TaskName
comprehension -X- _ I-TaskName
and -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
. -X- _ O
In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
56th -X- _ O
Annual -X- _ O
Meeting -X- _ O
of -X- _ O
the -X- _ O
As- -X- _ O
sociation -X- _ O
for -X- _ O
Computational -X- _ O
Linguistics -X- _ O
( -X- _ O
Volume -X- _ O
1 -X- _ O
: -X- _ O
Long -X- _ O
Papers -X- _ O
) -X- _ O
. -X- _ O
Association -X- _ O
for -X- _ O
Computational -X- _ O
Lin- -X- _ O
guistics -X- _ O
. -X- _ O

Alex -X- _ O
Warstadt -X- _ O
, -X- _ O
Amanpreet -X- _ O
Singh -X- _ O
, -X- _ O
and -X- _ O
Samuel -X- _ O
R -X- _ O
Bow- -X- _ O
man -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O
Neural -X- _ O
network -X- _ O
acceptability -X- _ O
judg- -X- _ O
ments -X- _ O
. -X- _ O
arXiv -X- _ O
preprint -X- _ O
arXiv:1805.12471 -X- _ O
. -X- _ O

Adina -X- _ O
Williams -X- _ O
, -X- _ O
Nikita -X- _ O
Nangia -X- _ O
, -X- _ O
and -X- _ O
Samuel -X- _ O
R -X- _ O
Bow- -X- _ O
man -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O
A -X- _ O
broad -X- _ O
- -X- _ O
coverage -X- _ O
challenge -X- _ O
corpus -X- _ O
for -X- _ O
sentence -X- _ O
understanding -X- _ O
through -X- _ O
inference -X- _ O
. -X- _ O
In -X- _ O
NAACL -X- _ O
. -X- _ O

Yonghui -X- _ O
Wu -X- _ O
, -X- _ O
Mike -X- _ O
Schuster -X- _ O
, -X- _ O
Zhifeng -X- _ O
Chen -X- _ O
, -X- _ O
Quoc -X- _ O
V -X- _ O
Le -X- _ O
, -X- _ O
Mohammad -X- _ O
Norouzi -X- _ O
, -X- _ O
Wolfgang -X- _ O
Macherey -X- _ O
, -X- _ O
Maxim -X- _ O
Krikun -X- _ O
, -X- _ O
Yuan -X- _ O
Cao -X- _ O
, -X- _ O
Qin -X- _ O
Gao -X- _ O
, -X- _ O
Klaus -X- _ O
Macherey -X- _ O
, -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
2016 -X- _ O
. -X- _ O
Google -X- _ O
’s -X- _ O
neural -X- _ O
ma- -X- _ O
chine -X- _ O
translation -X- _ O
system -X- _ O
: -X- _ O
Bridging -X- _ O
the -X- _ O
gap -X- _ O
between -X- _ O
human -X- _ O
and -X- _ O
machine -X- _ O
translation -X- _ O
. -X- _ O
arXiv -X- _ O
preprint -X- _ O
arXiv:1609.08144 -X- _ O
. -X- _ O

Jason -X- _ O
Yosinski -X- _ O
, -X- _ O
Jeff -X- _ O
Clune -X- _ O
, -X- _ O
Yoshua -X- _ O
Bengio -X- _ O
, -X- _ O
and -X- _ O
Hod -X- _ O
Lipson -X- _ O
. -X- _ O
2014 -X- _ O
. -X- _ O
How -X- _ O
transferable -X- _ O
are -X- _ O
features -X- _ O
in -X- _ O
deep -X- _ O
neural -X- _ O
networks -X- _ O
? -X- _ O
In -X- _ O
Advances -X- _ O
in -X- _ O
neural -X- _ O
information -X- _ O
processing -X- _ O
systems -X- _ O
, -X- _ O
pages -X- _ O
3320–3328 -X- _ O
. -X- _ O

Adams -X- _ O
Wei -X- _ O
Yu -X- _ O
, -X- _ O
David -X- _ O
Dohan -X- _ O
, -X- _ O
Minh -X- _ O
- -X- _ O
Thang -X- _ O
Luong -X- _ O
, -X- _ O
Rui -X- _ O
Zhao -X- _ O
, -X- _ O
Kai -X- _ O
Chen -X- _ O
, -X- _ O
Mohammad -X- _ O
Norouzi -X- _ O
, -X- _ O
and -X- _ O
Quoc -X- _ O
V -X- _ O
Le -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O
QANet -X- _ O
: -X- _ O
Combining -X- _ O
local -X- _ O
convolution -X- _ O
with -X- _ O
global -X- _ O
self -X- _ O
- -X- _ O
attention -X- _ O
for -X- _ O
reading -X- _ O
comprehen- -X- _ O
sion -X- _ O
. -X- _ O
In -X- _ O
ICLR -X- _ O
. -X- _ O

Rowan -X- _ O
Zellers -X- _ O
, -X- _ O
Yonatan -X- _ O
Bisk -X- _ O
, -X- _ O
Roy -X- _ O
Schwartz -X- _ O
, -X- _ O
and -X- _ O
Yejin -X- _ O
Choi -X- _ O
. -X- _ O
2018 -X- _ O
. -X- _ O
Swag -X- _ B-DatasetName
: -X- _ O
A -X- _ O
large -X- _ O
- -X- _ O
scale -X- _ O
adversarial -X- _ O
dataset -X- _ O
for -X- _ O
grounded -X- _ O
commonsense -X- _ O
inference -X- _ O
. -X- _ O
In -X- _ O
Proceed- -X- _ O
ings -X- _ O
of -X- _ O
the -X- _ O
2018 -X- _ O
Conference -X- _ O
on -X- _ O
Empirical -X- _ O
Methods -X- _ O
in -X- _ O
Natural -X- _ B-TaskName
Language -X- _ I-TaskName
Processing -X- _ I-TaskName
( -X- _ O
EMNLP -X- _ B-DatasetName
) -X- _ O
. -X- _ O

Yukun -X- _ O
Zhu -X- _ O
, -X- _ O
Ryan -X- _ O
Kiros -X- _ O
, -X- _ O
Rich -X- _ O
Zemel -X- _ O
, -X- _ O
Ruslan -X- _ O
Salakhut- -X- _ O
dinov -X- _ O
, -X- _ O
Raquel -X- _ O
Urtasun -X- _ O
, -X- _ O
Antonio -X- _ O
Torralba -X- _ O
, -X- _ O
and -X- _ O
Sanja -X- _ O
Fidler -X- _ O
. -X- _ O
2015 -X- _ O
. -X- _ O
Aligning -X- _ O
books -X- _ O
and -X- _ O
movies -X- _ O
: -X- _ O
Towards -X- _ O
story -X- _ O
- -X- _ O
like -X- _ O
visual -X- _ O
explanations -X- _ O
by -X- _ O
watching -X- _ O
movies -X- _ O
and -X- _ O
reading -X- _ O
books -X- _ O
. -X- _ O
In -X- _ O
Proceedings -X- _ O
of -X- _ O
the -X- _ O
IEEE -X- _ O
international -X- _ O
conference -X- _ O
on -X- _ O
computer -X- _ O
vision -X- _ O
, -X- _ O
pages -X- _ O
19–27 -X- _ O
. -X- _ O

Appendix -X- _ O
for -X- _ O
“ -X- _ O
BERT -X- _ B-MethodName
: -X- _ O
Pre -X- _ O
- -X- _ O
training -X- _ O
of -X- _ O
Deep -X- _ O
Bidirectional -X- _ B-MethodName
Transformers -X- _ I-MethodName
for -X- _ O
Language -X- _ O
Understanding -X- _ O
” -X- _ O

• -X- _ O
Additional -X- _ O
implementation -X- _ O
details -X- _ O
for -X- _ O
BERT -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Appendix -X- _ O
A -X- _ O
; -X- _ O

• -X- _ O
Additional -X- _ O
details -X- _ O
for -X- _ O
our -X- _ O
experiments -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Appendix -X- _ O
B -X- _ O
; -X- _ O
and -X- _ O

80 -X- _ O
% -X- _ O
10 -X- _ O
% -X- _ O
10 -X- _ O
% -X- _ O
84.2 -X- _ O
95.4 -X- _ O
94.9 -X- _ O
100 -X- _ O
% -X- _ O
0 -X- _ O
% -X- _ O
0 -X- _ O
% -X- _ O
84.3 -X- _ O
94.9 -X- _ O
94.0 -X- _ O
80 -X- _ O
% -X- _ O
0 -X- _ O
% -X- _ O
20 -X- _ O
% -X- _ O
84.1 -X- _ O
95.2 -X- _ O
94.6 -X- _ O
80 -X- _ O
% -X- _ O
20 -X- _ O
% -X- _ O
0 -X- _ O
% -X- _ O
84.4 -X- _ O
95.2 -X- _ O
94.7 -X- _ O
0 -X- _ O
% -X- _ O
20 -X- _ O
% -X- _ O
80 -X- _ O
% -X- _ O
83.7 -X- _ O
94.8 -X- _ O
94.6 -X- _ O
0 -X- _ O
% -X- _ O
0 -X- _ O
% -X- _ O
100 -X- _ O
% -X- _ O
83.6 -X- _ O
94.9 -X- _ O
94.6 -X- _ O

Language -X- _ O
model -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
be -X- _ O
effective -X- _ O
for -X- _ O
improving -X- _ O
many -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
processing -X- _ I-TaskName
tasks -X- _ O
( -X- _ O
Dai -X- _ O
and -X- _ O
Le -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
; -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Howard -X- _ O
and -X- _ O
Ruder -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
These -X- _ O
include -X- _ O
sentence -X- _ O
- -X- _ O
level -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
natural -X- _ B-TaskName
language -X- _ I-TaskName
inference -X- _ I-TaskName
( -X- _ O
Bowman -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Williams -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
paraphrasing -X- _ B-TaskName
( -X- _ O
Dolan -X- _ O
and -X- _ O
Brockett -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
aim -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
re- -X- _ O
lationships -X- _ O
between -X- _ O
sentences -X- _ O
by -X- _ O
analyzing -X- _ O
them -X- _ O
holistically -X- _ O
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
token -X- _ O
- -X- _ O
level -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
named -X- _ B-TaskName
entity -X- _ I-TaskName
recognition -X- _ I-TaskName
and -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
, -X- _ O
where -X- _ O
models -X- _ O
are -X- _ O
required -X- _ O
to -X- _ O
produce -X- _ O
ﬁne -X- _ O
- -X- _ O
grained -X- _ O
output -X- _ O
at -X- _ O
the -X- _ O
token -X- _ O
level -X- _ O
( -X- _ O
Tjong -X- _ O
Kim -X- _ O
Sang -X- _ O
and -X- _ O
De -X- _ O
Meulder -X- _ O
, -X- _ O
2003 -X- _ O
; -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O

BERT -X- _ B-MethodName
is -X- _ O
conceptually -X- _ O
simple -X- _ O
and -X- _ O
empirically -X- _ O
powerful -X- _ O
. -X- _ O
It -X- _ O
obtains -X- _ O
new -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
re- -X- _ O
sults -X- _ O
on -X- _ O
eleven -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
tasks -X- _ O
, -X- _ O
including -X- _ O
pushing -X- _ O
the -X- _ O
GLUE -X- _ B-MetricName
score -X- _ O
to -X- _ O
80.5 -X- _ B-MetricValue
% -X- _ I-MetricValue
( -X- _ O
7.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
point -X- _ O
absolute -X- _ O
improvement -X- _ O
) -X- _ O
, -X- _ O
MultiNLI -X- _ B-TaskName
accuracy -X- _ B-MetricName
to -X- _ O
86.7 -X- _ B-MetricValue
% -X- _ I-MetricValue
( -X- _ O
4.6 -X- _ O
% -X- _ O
absolute -X- _ O
improvement -X- _ O
) -X- _ O
, -X- _ O
SQuAD -X- _ B-DatasetName
v1.1 -X- _ I-DatasetName
question -X- _ O
answer- -X- _ O
ing -X- _ O
Test -X- _ O
F1 -X- _ B-MetricName
to -X- _ O
93.2 -X- _ B-MetricValue
( -X- _ O
1.5 -X- _ O
point -X- _ O
absolute -X- _ O
im- -X- _ O
provement -X- _ O
) -X- _ O
and -X- _ O
SQuAD -X- _ B-DatasetName
v2.0 -X- _ I-DatasetName
Test -X- _ O
F1 -X- _ B-MetricName
to -X- _ O
83.1 -X- _ B-MetricValue
( -X- _ O
5.1 -X- _ O
point -X- _ O
absolute -X- _ O
improvement -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
introduce -X- _ O
a -X- _ O
new -X- _ O
language -X- _ O
representa- -X- _ O
tion -X- _ O
model -X- _ O
called -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
which -X- _ O
stands -X- _ O
for -X- _ O
Bidirectional -X- _ B-MethodName
Encoder -X- _ I-MethodName
Representations -X- _ I-MethodName
from -X- _ I-MethodName
Transformers -X- _ I-MethodName
. -X- _ O
Unlike -X- _ O
recent -X- _ O
language -X- _ O
repre- -X- _ O
sentation -X- _ O
models -X- _ O
( -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018a -X- _ O
; -X- _ O
Rad- -X- _ O
ford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
designed -X- _ O
to -X- _ O
pre- -X- _ O
train -X- _ O
deep -X- _ O
bidirectional -X- _ O
representations -X- _ O
from -X- _ O
unlabeled -X- _ O
text -X- _ O
by -X- _ O
jointly -X- _ O
conditioning -X- _ O
on -X- _ O
both -X- _ O
left -X- _ O
and -X- _ O
right -X- _ O
context -X- _ O
in -X- _ O
all -X- _ O
layers -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
re- -X- _ O
sult -X- _ O
, -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
can -X- _ O
be -X- _ O
ﬁne- -X- _ O
tuned -X- _ O
with -X- _ O
just -X- _ O
one -X- _ O
additional -X- _ O
output -X- _ O
layer -X- _ O
to -X- _ O
create -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
models -X- _ O
for -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
tasks -X- _ O
, -X- _ O
such -X- _ O
as -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
and -X- _ O
language -X- _ B-TaskName
inference -X- _ I-TaskName
, -X- _ O
without -X- _ O
substantial -X- _ O
task- -X- _ O
speciﬁc -X- _ O
architecture -X- _ O
modiﬁcations -X- _ O
. -X- _ O

Jacob -X- _ O
Devlin -X- _ O
Ming -X- _ O
- -X- _ O
Wei -X- _ O
Chang -X- _ O
Kenton -X- _ O
Lee -X- _ O
Kristina -X- _ O
Toutanova -X- _ O
Google -X- _ O
AI -X- _ O
Language -X- _ O
{ -X- _ O
jacobdevlin,mingweichang,kentonl,kristout}@google.com -X- _ O

BERT -X- _ B-MethodName
: -X- _ O
Pre -X- _ O
- -X- _ O
training -X- _ O
of -X- _ O
Deep -X- _ O
Bidirectional -X- _ B-MethodName
Transformers -X- _ I-MethodName
for -X- _ O
Language -X- _ O
Understanding -X- _ O

