-DOCSTART- -X- O
Learning -X- _ B-HyperparameterName
Rate -X- _ I-HyperparameterName
3e-4 -X- _ O
for -X- _ O
Small -X- _ O
, -X- _ O
1e-4 -X- _ O
for -X- _ O
Base -X- _ O
, -X- _ O
5e-5 -X- _ O
for -X- _ O
Large -X- _ O
Adam -X- _ B-HyperparameterName
ϵ -X- _ I-HyperparameterName
1e-6 -X- _ B-HyperparameterValue
Adam -X- _ B-HyperparameterName
β1 -X- _ I-HyperparameterName
0.9 -X- _ B-HyperparameterValue
Adam -X- _ B-HyperparameterName
β2 -X- _ I-HyperparameterName
0.999 -X- _ B-HyperparameterValue
Layerwise -X- _ B-HyperparameterName
LR -X- _ I-HyperparameterName
decay -X- _ I-HyperparameterName
0.8 -X- _ B-HyperparameterValue
for -X- _ O
Base -X- _ O
/ -X- _ O
Small -X- _ O
, -X- _ O
0.9 -X- _ O
for -X- _ O
Large -X- _ B-HyperparameterName
Learning -X- _ I-HyperparameterName
rate -X- _ I-HyperparameterName
decay -X- _ I-HyperparameterName
Linear -X- _ O
Warmup -X- _ O
fraction -X- _ O
0.1 -X- _ O
Attention -X- _ B-HyperparameterName
Dropout -X- _ I-HyperparameterName
0.1 -X- _ B-HyperparameterValue
Dropout -X- _ B-HyperparameterName
0.1 -X- _ B-HyperparameterValue
Weight -X- _ B-HyperparameterName
Decay -X- _ I-HyperparameterName
0 -X- _ B-HyperparameterValue
Batch -X- _ B-HyperparameterName
Size -X- _ I-HyperparameterName
32 -X- _ B-HyperparameterValue
Train -X- _ B-HyperparameterName
Epochs -X- _ I-HyperparameterName
10 -X- _ B-HyperparameterValue
for -X- _ O
RTE -X- _ O
and -X- _ O
STS -X- _ O
, -X- _ O
2 -X- _ O
for -X- _ O
SQuAD -X- _ B-DatasetName
, -X- _ O
3 -X- _ O
for -X- _ O
other -X- _ O
tasks -X- _ O

Number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
12 -X- _ O
12 -X- _ O
24 -X- _ O
Hidden -X- _ B-HyperparameterName
Size -X- _ I-HyperparameterName
256 -X- _ O
768 -X- _ O
1024 -X- _ O
FFN -X- _ B-HyperparameterName
inner -X- _ I-HyperparameterName
hidden -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
1024 -X- _ O
3072 -X- _ O
4096 -X- _ O
Attention -X- _ B-HyperparameterName
heads -X- _ I-HyperparameterName
4 -X- _ O
12 -X- _ O
16 -X- _ O
Attention -X- _ B-HyperparameterName
head -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
64 -X- _ O
64 -X- _ O
64 -X- _ O
Embedding -X- _ B-HyperparameterName
Size -X- _ I-HyperparameterName
128 -X- _ O
768 -X- _ O
1024 -X- _ O
Generator -X- _ B-HyperparameterName
Size -X- _ I-HyperparameterName
( -X- _ O
multiplier -X- _ O
for -X- _ O
hidden -X- _ O
- -X- _ O
size -X- _ O
, -X- _ O
1/4 -X- _ O
1/3 -X- _ O
1/4 -X- _ O
FFN -X- _ O
- -X- _ O
size -X- _ O
, -X- _ O
and -X- _ O
num -X- _ O
- -X- _ O
attention -X- _ O
- -X- _ O
heads -X- _ O
) -X- _ O
Mask -X- _ B-HyperparameterName
percent -X- _ I-HyperparameterName
15 -X- _ O
15 -X- _ O
25 -X- _ O
Learning -X- _ B-HyperparameterName
Rate -X- _ I-HyperparameterName
Decay -X- _ I-HyperparameterName
Linear -X- _ O
Linear -X- _ O
Linear -X- _ O
Warmup -X- _ B-HyperparameterName
steps -X- _ I-HyperparameterName
10000 -X- _ O
10000 -X- _ O
10000 -X- _ O
Learning -X- _ B-HyperparameterName
Rate -X- _ I-HyperparameterName
5e-4 -X- _ O
2e-4 -X- _ O
2e-4 -X- _ O
Adam -X- _ B-HyperparameterName
ϵ -X- _ I-HyperparameterName
1e-6 -X- _ O
1e-6 -X- _ O
1e-6 -X- _ O
Adam -X- _ B-HyperparameterName
β1 -X- _ I-HyperparameterName
0.9 -X- _ O
0.9 -X- _ O
0.9 -X- _ O
Adam -X- _ B-HyperparameterName
β2 -X- _ I-HyperparameterName
0.999 -X- _ O
0.999 -X- _ O
0.999 -X- _ O
Attention -X- _ B-HyperparameterName
Dropout -X- _ I-HyperparameterName
0.1 -X- _ O
0.1 -X- _ O
0.1 -X- _ O
Dropout -X- _ B-HyperparameterName
0.1 -X- _ O
0.1 -X- _ O
0.1 -X- _ O
Weight -X- _ B-HyperparameterName
Decay -X- _ I-HyperparameterName
0.01 -X- _ O
0.01 -X- _ O
0.01 -X- _ O
Batch -X- _ B-HyperparameterName
Size -X- _ I-HyperparameterName
128 -X- _ O
256 -X- _ O
2048 -X- _ O
Train -X- _ B-HyperparameterName
Steps -X- _ I-HyperparameterName
( -X- _ O
BERT -X- _ B-MethodName
/ -X- _ O
ELECTRA -X- _ B-MethodName
) -X- _ O
1.45M/1 -X- _ O
M -X- _ O
1M/766 -X- _ O
K -X- _ O
464K/400 -X- _ O
K -X- _ O

• -X- _ O
For -X- _ O
RTE -X- _ B-DatasetName
and -X- _ O
STS -X- _ B-DatasetName
we -X- _ O
use -X- _ O
intermediate -X- _ O
task -X- _ O
training -X- _ O
( -X- _ O
Phang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
starting -X- _ O
from -X- _ O
an -X- _ O
ELECTRA -X- _ B-MethodName
checkpoint -X- _ O
that -X- _ O
has -X- _ O
been -X- _ O
ﬁne -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
MNLI -X- _ B-DatasetName
. -X- _ O
For -X- _ O
RTE -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
it -X- _ O
helpful -X- _ O
to -X- _ O
combine -X- _ O
this -X- _ O
with -X- _ O
a -X- _ O
lower -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
2e-5 -X- _ B-HyperparameterValue
. -X- _ O

Following -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
show -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
WNLI -X- _ B-DatasetName
GLUE -X- _ I-DatasetName
task -X- _ O
for -X- _ O
the -X- _ O
dev -X- _ O
set -X- _ O
results -X- _ O
, -X- _ O
as -X- _ O
it -X- _ O
is -X- _ O
difﬁcult -X- _ O
to -X- _ O
beat -X- _ O
even -X- _ O
the -X- _ O
majority -X- _ O
classiﬁer -X- _ O
using -X- _ O
a -X- _ O
standard -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
- -X- _ O
as -X- _ O
- -X- _ O
classiﬁer -X- _ O
approach -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
test -X- _ O
set -X- _ O
results -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
the -X- _ O
standard -X- _ O
tricks -X- _ O
used -X- _ O
by -X- _ O
many -X- _ O
of -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
leaderboard -X- _ O
submissions -X- _ O
including -X- _ O
RoBERTa -X- _ B-MethodName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
XLNet -X- _ B-MethodName
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
ALBERT -X- _ B-MethodName
( -X- _ O
Lan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
Speciﬁcally -X- _ O
: -X- _ O

For -X- _ O
Large -X- _ O
- -X- _ O
sized -X- _ O
models -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
hyperparameters -X- _ O
from -X- _ O
Clark -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
for -X- _ O
the -X- _ O
most -X- _ O
part -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
after -X- _ O
noticing -X- _ O
that -X- _ O
RoBERTa -X- _ B-MethodName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
uses -X- _ O
more -X- _ O
training -X- _ O
epochs -X- _ B-HyperparameterName
( -X- _ O
up -X- _ O
to -X- _ O
10 -X- _ B-HyperparameterValue
rather -X- _ O
than -X- _ O
3 -X- _ B-HyperparameterValue
) -X- _ O
we -X- _ O
searched -X- _ O
for -X- _ O
the -X- _ O
best -X- _ O
number -X- _ O
of -X- _ O
train -X- _ O
epochs -X- _ B-HyperparameterName
out -X- _ O
of -X- _ O
[ -X- _ O
10 -X- _ B-HyperparameterValue
, -X- _ O
3 -X- _ B-HyperparameterValue
] -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
. -X- _ O
For -X- _ O
SQuAD -X- _ B-DatasetName
, -X- _ O
we -X- _ O
decreased -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
train -X- _ O
epochs -X- _ B-HyperparameterName
to -X- _ O
2 -X- _ B-HyperparameterValue
to -X- _ O
be -X- _ O
consistent -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
RoBERTa -X- _ B-MethodName
. -X- _ O
For -X- _ O
Base- -X- _ O
sized -X- _ O
models -X- _ O
we -X- _ O
searched -X- _ O
for -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
out -X- _ O
of -X- _ O
[ -X- _ O
3e-5 -X- _ B-HyperparameterValue
, -X- _ O
5e-5 -X- _ B-HyperparameterValue
, -X- _ O
1e-4 -X- _ B-HyperparameterValue
, -X- _ O
1.5e-4 -X- _ B-HyperparameterValue
] -X- _ O
and -X- _ O
the -X- _ O
layer -X- _ O
- -X- _ O
wise -X- _ O
learning -X- _ B-HyperparameterName
- -X- _ I-HyperparameterName
rate -X- _ I-HyperparameterName
decay -X- _ I-HyperparameterName
out -X- _ O
of -X- _ O
[ -X- _ O
0.9 -X- _ B-HyperparameterValue
, -X- _ O
0.8 -X- _ B-HyperparameterValue
, -X- _ O
0.7 -X- _ B-HyperparameterValue
] -X- _ O
, -X- _ O
but -X- _ O
otherwise -X- _ O
used -X- _ O
the -X- _ O
same -X- _ O
hyperparameters -X- _ O
as -X- _ O
for -X- _ O
Large -X- _ O
models -X- _ O
. -X- _ O
We -X- _ O
found -X- _ O
the -X- _ O
small -X- _ O
models -X- _ O
beneﬁt -X- _ O
from -X- _ O
a -X- _ O
larger -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
and -X- _ O
searched -X- _ O
for -X- _ O
the -X- _ O
best -X- _ O
one -X- _ O
out -X- _ O
of -X- _ O
[ -X- _ O
1e-4 -X- _ B-HyperparameterValue
, -X- _ O
2e-4 -X- _ B-HyperparameterValue
, -X- _ O
3e-4 -X- _ B-HyperparameterValue
, -X- _ O
5e-3 -X- _ B-HyperparameterValue
] -X- _ O
. -X- _ O
With -X- _ O
the -X- _ O
exception -X- _ O
of -X- _ O
number -X- _ O
of -X- _ O
train -X- _ O
epochs -X- _ B-HyperparameterName
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
same -X- _ O
hyperparameters -X- _ O
for -X- _ O
all -X- _ O
tasks -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
previous -X- _ O
research -X- _ O
on -X- _ O
GLUE -X- _ O
such -X- _ O
as -X- _ O
BERT -X- _ O
, -X- _ O
XLNet -X- _ O
, -X- _ O
and -X- _ O
RoBERTa -X- _ O
separately -X- _ O
searched -X- _ O
for -X- _ O
the -X- _ O
best -X- _ O
hyperparameters -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
. -X- _ O
We -X- _ O
expect -X- _ O
our -X- _ O
results -X- _ O
would -X- _ O
improve -X- _ O
slightly -X- _ O
if -X- _ O
we -X- _ O
performed -X- _ O
the -X- _ O
same -X- _ O
sort -X- _ O
of -X- _ O
additional -X- _ O
hyperparameter -X- _ O
search -X- _ O
. -X- _ O
The -X- _ O
full -X- _ O
set -X- _ O
of -X- _ O
hyperparameters -X- _ O
is -X- _ O
listed -X- _ O
in -X- _ O
Table -X- _ O
7 -X- _ O
. -X- _ O

The -X- _ O
following -X- _ O
details -X- _ O
apply -X- _ O
to -X- _ O
both -X- _ O
our -X- _ O
ELECTRA -X- _ B-MethodName
models -X- _ O
and -X- _ O
BERT -X- _ B-MethodName
baselines -X- _ O
. -X- _ O
We -X- _ O
mostly -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
hyperparameters -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
We -X- _ O
set -X- _ O
λ -X- _ B-HyperparameterName
, -X- _ O
the -X- _ O
weight -X- _ B-HyperparameterName
for -X- _ O
the -X- _ O
discriminator -X- _ O
objective -X- _ O
in -X- _ O
the -X- _ O
loss -X- _ O
to -X- _ O
50.8 -X- _ B-HyperparameterValue
We -X- _ O
use -X- _ O
dynamic -X- _ O
token -X- _ O
masking -X- _ O
with -X- _ O
the -X- _ O
masked -X- _ O
positions -X- _ O
decided -X- _ O
on -X- _ O
- -X- _ O
the-ﬂy -X- _ O
instead -X- _ O
of -X- _ O
during -X- _ O
preprocessing -X- _ O
. -X- _ O
Also -X- _ O
, -X- _ O
we -X- _ O
did -X- _ O
not -X- _ O
use -X- _ O
the -X- _ O
next -X- _ O
sentence -X- _ O
prediction -X- _ O
objective -X- _ O
proposed -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
BERT -X- _ B-MethodName
paper -X- _ O
, -X- _ O
as -X- _ O
recent -X- _ O
work -X- _ O
has -X- _ O
suggested -X- _ O
it -X- _ O
does -X- _ O
not -X- _ O
improve -X- _ O
scores -X- _ O
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
; -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
our -X- _ O
ELECTRA -X- _ B-MethodName
- -X- _ I-MethodName
Large -X- _ I-MethodName
model -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
a -X- _ O
higher -X- _ O
mask -X- _ B-HyperparameterName
percent -X- _ I-HyperparameterName
( -X- _ O
25 -X- _ B-HyperparameterValue
instead -X- _ O
of -X- _ O
15 -X- _ B-HyperparameterValue
) -X- _ O
because -X- _ O
we -X- _ O
noticed -X- _ O
the -X- _ O
generator -X- _ O
was -X- _ O
achieving -X- _ O
high -X- _ O
accuracy -X- _ B-MetricName
with -X- _ O
15 -X- _ B-HyperparameterValue
% -X- _ I-HyperparameterValue
masking -X- _ O
, -X- _ O
resulting -X- _ O
in -X- _ O
very -X- _ O
few -X- _ O
replaced -X- _ O
tokens -X- _ O
. -X- _ O
We -X- _ O
searched -X- _ O
for -X- _ O
the -X- _ O
best -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
for -X- _ O
the -X- _ O
Base -X- _ O
and -X- _ O
Small -X- _ O
models -X- _ O
out -X- _ O
of -X- _ O
[ -X- _ O
1e-4 -X- _ B-HyperparameterValue
, -X- _ O
2e-4 -X- _ B-HyperparameterValue
, -X- _ O
3e-4 -X- _ B-HyperparameterValue
, -X- _ O
5e-4 -X- _ B-HyperparameterValue
] -X- _ O
and -X- _ O
selected -X- _ O
λ -X- _ B-HyperparameterName
out -X- _ O
of -X- _ O
[ -X- _ O
1 -X- _ B-HyperparameterValue
, -X- _ O
10 -X- _ B-HyperparameterValue
, -X- _ O
20 -X- _ B-HyperparameterValue
, -X- _ O
50 -X- _ B-HyperparameterValue
, -X- _ O
100 -X- _ B-HyperparameterValue
] -X- _ O
in -X- _ O
early -X- _ O
experiments -X- _ O
. -X- _ O
Otherwise -X- _ O
we -X- _ O
did -X- _ O
no -X- _ O
hyperparameter -X- _ O
tuning -X- _ O
beyond -X- _ O
the -X- _ O
experiments -X- _ O
in -X- _ O
Section -X- _ O
3.2 -X- _ O
. -X- _ O
The -X- _ O
full -X- _ O
set -X- _ O
of -X- _ O
hyperparameters -X- _ O
are -X- _ O
listed -X- _ O
in -X- _ O
Table -X- _ O
6 -X- _ O
. -X- _ O

We -X- _ O
have -X- _ O
proposed -X- _ O
replaced -X- _ O
token -X- _ O
detection -X- _ O
, -X- _ O
a -X- _ O
new -X- _ O
self -X- _ O
- -X- _ O
supervised -X- _ O
task -X- _ O
for -X- _ O
language -X- _ B-TaskName
representation -X- _ I-TaskName
learning -X- _ I-TaskName
. -X- _ O
The -X- _ O
key -X- _ O
idea -X- _ O
is -X- _ O
training -X- _ O
a -X- _ O
text -X- _ O
encoder -X- _ O
to -X- _ O
distinguish -X- _ O
input -X- _ O
tokens -X- _ O
from -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
nega- -X- _ O
tive -X- _ O
samples -X- _ O
produced -X- _ O
by -X- _ O
an -X- _ O
small -X- _ O
generator -X- _ O
network -X- _ O
. -X- _ O
Compared -X- _ O
to -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
, -X- _ O
our -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
objective -X- _ O
is -X- _ O
more -X- _ O
compute -X- _ O
- -X- _ O
efﬁcient -X- _ O
and -X- _ O
results -X- _ O
in -X- _ O
better -X- _ O
performance -X- _ O
on -X- _ O
downstream -X- _ B-TaskName
tasks -X- _ I-TaskName
. -X- _ O
It -X- _ O
works -X- _ O
well -X- _ O
even -X- _ O
when -X- _ O
using -X- _ O
relatively -X- _ O
small -X- _ O
amounts -X- _ O
of -X- _ O
compute -X- _ O
, -X- _ O
which -X- _ O
we -X- _ O
hope -X- _ O
will -X- _ O
make -X- _ O
developing -X- _ O
and -X- _ O
applying -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
text -X- _ O
encoders -X- _ O
more -X- _ O
accessible -X- _ O
to -X- _ O
researchers -X- _ O
and -X- _ O
practi- -X- _ O
tioners -X- _ O
with -X- _ O
less -X- _ O
access -X- _ O
to -X- _ O
computing -X- _ O
resources -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
hope -X- _ O
more -X- _ O
future -X- _ O
work -X- _ O
on -X- _ O
NLP -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
will -X- _ O
consider -X- _ O
efﬁciency -X- _ B-MetricName
as -X- _ O
well -X- _ O
as -X- _ O
absolute -X- _ O
performance -X- _ O
, -X- _ O
and -X- _ O
follow -X- _ O
our -X- _ O
effort -X- _ O
in -X- _ O
reporting -X- _ O
compute -X- _ O
usage -X- _ O
and -X- _ O
parameter -X- _ O
counts -X- _ O
along -X- _ O
with -X- _ O
evaluation -X- _ O
metrics -X- _ O
. -X- _ O

Word2Vec -X- _ B-MethodName
( -X- _ O
Mikolov -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
, -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
earliest -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
methods -X- _ O
for -X- _ O
NLP -X- _ O
, -X- _ O
uses -X- _ O
contrastive -X- _ O
learning -X- _ O
. -X- _ O
In -X- _ O
fact -X- _ O
, -X- _ O
ELECTRA -X- _ B-MethodName
can -X- _ O
be -X- _ O
viewed -X- _ O
as -X- _ O
a -X- _ O
massively -X- _ O
scaled -X- _ O
- -X- _ O
up -X- _ O
version -X- _ O
of -X- _ O
Continuous -X- _ O
Bag- -X- _ O
of -X- _ O
- -X- _ O
Words -X- _ O
( -X- _ O
CBOW -X- _ O
) -X- _ O
with -X- _ O
Negative -X- _ O
Sampling -X- _ O
. -X- _ O
CBOW -X- _ O
also -X- _ O
predicts -X- _ O
an -X- _ O
input -X- _ O
token -X- _ O
given -X- _ O
surrounding -X- _ O
context -X- _ O
and -X- _ O
negative -X- _ O
sampling -X- _ O
rephrases -X- _ O
the -X- _ O
learning -X- _ O
task -X- _ O
as -X- _ O
a -X- _ O
binary -X- _ B-TaskName
classiﬁcation -X- _ I-TaskName
task -X- _ O
on -X- _ O
whether -X- _ O
the -X- _ O
input -X- _ O
token -X- _ O
comes -X- _ O
from -X- _ O
the -X- _ O
data -X- _ O
or -X- _ O
proposal -X- _ O
distribution -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
CBOW -X- _ O
uses -X- _ O
a -X- _ O
bag -X- _ O
- -X- _ O
of- -X- _ O
vectors -X- _ O
encoder -X- _ O
rather -X- _ O
than -X- _ O
a -X- _ O
transformer -X- _ O
and -X- _ O
a -X- _ O
simple -X- _ O
proposal -X- _ O
distribution -X- _ O
derived -X- _ O
from -X- _ O
unigram -X- _ O
token -X- _ O
frequencies -X- _ O
instead -X- _ O
of -X- _ O
a -X- _ O
learned -X- _ O
generator -X- _ O
. -X- _ O

Contrastive -X- _ O
Learning -X- _ O
Broadly -X- _ O
, -X- _ O
contrastive -X- _ O
learning -X- _ O
methods -X- _ O
distinguish -X- _ O
observed -X- _ O
data -X- _ O
points -X- _ O
from -X- _ O
ﬁctitious -X- _ O
negative -X- _ O
samples -X- _ O
. -X- _ O
They -X- _ O
have -X- _ O
been -X- _ O
applied -X- _ O
to -X- _ O
many -X- _ O
modalities -X- _ O
including -X- _ O
text -X- _ O
( -X- _ O
Smith -X- _ O
& -X- _ O
Eisner -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
, -X- _ O
images -X- _ O
( -X- _ O
Chopra -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2005 -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
video -X- _ O
( -X- _ O
Wang -X- _ O
& -X- _ O
Gupta -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Sermanet -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
data -X- _ O
. -X- _ O
Common -X- _ O
approaches -X- _ O
learn -X- _ O
embedding -X- _ O
spaces -X- _ O
where -X- _ O
related -X- _ O
data -X- _ O
points -X- _ O
are -X- _ O
similar -X- _ O
( -X- _ O
Saunshi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
or -X- _ O
models -X- _ O
that -X- _ O
rank -X- _ O
real -X- _ O
data -X- _ O
points -X- _ O
over -X- _ O
negative -X- _ O
samples -X- _ O
( -X- _ O
Collobert -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
; -X- _ O
Bordes -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2013 -X- _ O
) -X- _ O
. -X- _ O
ELECTRA -X- _ B-MethodName
is -X- _ O
particularly -X- _ O
related -X- _ O
to -X- _ O
Noise -X- _ B-TaskName
- -X- _ I-TaskName
Contrastive -X- _ I-TaskName
Estimation -X- _ I-TaskName
( -X- _ O
NCE -X- _ B-TaskName
) -X- _ O
( -X- _ O
Gutmann -X- _ O
& -X- _ O
Hyv¨arinen -X- _ O
, -X- _ O
2010 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
also -X- _ O
trains -X- _ O
a -X- _ O
binary -X- _ O
classiﬁer -X- _ O
to -X- _ O
distinguish -X- _ O
real -X- _ O
and -X- _ O
fake -X- _ O
data -X- _ O
points -X- _ O
. -X- _ O

Generative -X- _ B-MethodName
Adversarial -X- _ I-MethodName
Networks -X- _ I-MethodName
GANs -X- _ I-MethodName
( -X- _ O
Goodfellow -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
are -X- _ O
effective -X- _ O
at -X- _ O
generating -X- _ O
high -X- _ O
- -X- _ O
quality -X- _ O
synthetic -X- _ O
data -X- _ O
. -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2016 -X- _ O
) -X- _ O
propose -X- _ O
using -X- _ O
the -X- _ O
discriminator -X- _ O
of -X- _ O
a -X- _ O
GAN -X- _ B-MethodName
in -X- _ O
downstream -X- _ O
tasks -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
similar -X- _ O
to -X- _ O
our -X- _ O
method -X- _ O
. -X- _ O
GANs -X- _ B-MethodName
have -X- _ O
been -X- _ O
applied -X- _ O
to -X- _ O
text -X- _ O
data -X- _ O
( -X- _ O
Yu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
; -X- _ O
Zhang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
, -X- _ O
although -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
approaches -X- _ O
still -X- _ O
lag -X- _ O
behind -X- _ O
standard -X- _ O
maximum- -X- _ B-MethodName
likelihood -X- _ I-MethodName
training -X- _ I-MethodName
( -X- _ O
Caccia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Tevet -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Although -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
use -X- _ O
adversarial -X- _ O
learning -X- _ O
, -X- _ O
our -X- _ O
generator -X- _ O
is -X- _ O
particularly -X- _ O
reminiscent -X- _ O
of -X- _ O
MaskGAN -X- _ B-MethodName
( -X- _ O
Fedus -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
trains -X- _ O
the -X- _ O
generator -X- _ O
to -X- _ O
ﬁll -X- _ O
in -X- _ O
tokens -X- _ O
deleted -X- _ O
from -X- _ O
the -X- _ O
input -X- _ O
. -X- _ O

Self -X- _ O
- -X- _ O
Supervised -X- _ O
Pre -X- _ O
- -X- _ O
training -X- _ O
for -X- _ O
NLP -X- _ O
Self -X- _ O
- -X- _ O
supervised -X- _ O
learning -X- _ O
has -X- _ O
been -X- _ O
used -X- _ O
to -X- _ O
learn -X- _ O
word -X- _ O
rep- -X- _ O
resentations -X- _ O
( -X- _ O
Collobert -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
; -X- _ O
Pennington -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2014 -X- _ O
) -X- _ O
and -X- _ O
more -X- _ O
recently -X- _ O
contextual -X- _ O
represen- -X- _ O
tations -X- _ O
of -X- _ O
words -X- _ O
though -X- _ O
objectives -X- _ O
such -X- _ O
as -X- _ O
language -X- _ O
modeling -X- _ O
( -X- _ O
Dai -X- _ O
& -X- _ O
Le -X- _ O
, -X- _ O
2015 -X- _ O
; -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
; -X- _ O
Howard -X- _ O
& -X- _ O
Ruder -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
pre -X- _ O
- -X- _ O
trains -X- _ O
a -X- _ O
large -X- _ O
Transformer -X- _ B-MethodName
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
at -X- _ O
the -X- _ O
masked -X- _ O
- -X- _ O
language -X- _ O
modeling -X- _ O
task -X- _ O
. -X- _ O
There -X- _ O
have -X- _ O
been -X- _ O
numerous -X- _ O
extensions -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
MASS -X- _ B-MethodName
( -X- _ O
Song -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
UniLM -X- _ B-MethodName
( -X- _ O
Dong -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
extend -X- _ O
BERT -X- _ B-MethodName
to -X- _ O
generation -X- _ B-TaskName
tasks -X- _ O
by -X- _ O
adding -X- _ O
auto -X- _ O
- -X- _ O
regressive -X- _ O
generative -X- _ O
training -X- _ O
objectives -X- _ O
. -X- _ O
ERNIE -X- _ B-MethodName
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019a -X- _ O
) -X- _ O
and -X- _ O
SpanBERT -X- _ B-MethodName
( -X- _ O
Joshi -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
mask -X- _ O
out -X- _ O
contiguous -X- _ O
sequences -X- _ O
of -X- _ O
token -X- _ O
for -X- _ O
improved -X- _ O
span -X- _ O
representations -X- _ O
. -X- _ O
This -X- _ O
idea -X- _ O
may -X- _ O
be -X- _ O
complementary -X- _ O
to -X- _ O
ELECTRA -X- _ B-MethodName
; -X- _ O
we -X- _ O
think -X- _ O
it -X- _ O
would -X- _ O
be -X- _ O
interesting -X- _ O
to -X- _ O
make -X- _ O
ELECTRA -X- _ B-MethodName
’s -X- _ O
generator -X- _ O
auto -X- _ O
- -X- _ O
regressive -X- _ O
and -X- _ O
add -X- _ O
a -X- _ O
“ -X- _ O
replaced -X- _ O
span -X- _ O
detection -X- _ O
” -X- _ O
task -X- _ O
. -X- _ O
Instead -X- _ O
of -X- _ O
masking -X- _ O
out -X- _ O
input -X- _ O
tokens -X- _ O
, -X- _ O
XLNet -X- _ B-MethodName
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
masks -X- _ O
attention -X- _ O
weights -X- _ O
such -X- _ O
that -X- _ O
the -X- _ O
input -X- _ O
sequence -X- _ O
is -X- _ O
auto- -X- _ O
regressively -X- _ O
generated -X- _ O
in -X- _ O
a -X- _ O
random -X- _ O
order -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
this -X- _ O
method -X- _ O
suffers -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
inefﬁciencies -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
because -X- _ O
XLNet -X- _ B-MethodName
only -X- _ O
generates -X- _ O
15 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
tokens -X- _ O
in -X- _ O
this -X- _ O
way -X- _ O
. -X- _ O
Like -X- _ O
ELECTRA -X- _ B-MethodName
, -X- _ O
XL- -X- _ B-MethodName
Net -X- _ I-MethodName
may -X- _ O
alleviate -X- _ O
BERT -X- _ B-MethodName
’s -X- _ O
pretrain-ﬁnetune -X- _ O
discrepancy -X- _ O
by -X- _ O
not -X- _ O
requiring -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
tokens -X- _ O
, -X- _ O
although -X- _ O
this -X- _ O
is -X- _ O
n’t -X- _ O
entirely -X- _ O
clear -X- _ O
because -X- _ O
XLNet -X- _ B-MethodName
uses -X- _ O
two -X- _ O
“ -X- _ O
streams -X- _ O
” -X- _ O
of -X- _ O
attention -X- _ O
during -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
but -X- _ O
only -X- _ O
one -X- _ O
for -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
. -X- _ O
Recently -X- _ O
, -X- _ O
models -X- _ O
such -X- _ O
as -X- _ O
TinyBERT -X- _ B-MethodName
( -X- _ O
Jiao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
MobileBERT -X- _ B-MethodName
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019b -X- _ O
) -X- _ O
show -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
can -X- _ O
effectively -X- _ O
be -X- _ O
distilled -X- _ O
down -X- _ O
to -X- _ O
a -X- _ O
smaller -X- _ O
model -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
we -X- _ O
focus -X- _ O
more -X- _ O
on -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
speed -X- _ O
rather -X- _ O
than -X- _ O
inference -X- _ O
speed -X- _ O
, -X- _ O
so -X- _ O
we -X- _ O
train -X- _ O
ELECTRA -X- _ B-MethodName
- -X- _ I-MethodName
Small -X- _ I-MethodName
from -X- _ O
scratch -X- _ O
. -X- _ O

The -X- _ O
improvement -X- _ O
of -X- _ O
ELECTRA -X- _ B-MethodName
over -X- _ O
All -X- _ O
- -X- _ O
Tokens -X- _ O
MLM -X- _ O
suggests -X- _ O
that -X- _ O
the -X- _ O
ELECTRA -X- _ B-MethodName
’s -X- _ O
gains -X- _ O
come -X- _ O
from -X- _ O
more -X- _ O
than -X- _ O
just -X- _ O
faster -X- _ O
training -X- _ O
. -X- _ O
We -X- _ O
study -X- _ O
this -X- _ O
further -X- _ O
by -X- _ O
comparing -X- _ O
BERT -X- _ B-MethodName
to -X- _ O
ELECTRA -X- _ B-MethodName
for -X- _ O
various -X- _ O
model -X- _ O
sizes -X- _ O
( -X- _ O
see -X- _ O
Figure -X- _ O
4 -X- _ O
, -X- _ O
left -X- _ O
) -X- _ O
. -X- _ O
We -X- _ O
ﬁnd -X- _ O
that -X- _ O
the -X- _ O
gains -X- _ O
from -X- _ O
ELECTRA -X- _ B-MethodName
grow -X- _ O
larger -X- _ O
as -X- _ O
the -X- _ O
models -X- _ O
get -X- _ O
smaller -X- _ O
. -X- _ O
The -X- _ O
small -X- _ O
models -X- _ O
are -X- _ O
trained -X- _ O
fully -X- _ O
to -X- _ O
convergence -X- _ O
( -X- _ O
see -X- _ O
Figure -X- _ O
4 -X- _ O
, -X- _ O
right -X- _ O
) -X- _ O
, -X- _ O
showing -X- _ O
that -X- _ O
ELECTRA -X- _ B-MethodName
achieves -X- _ O
higher -X- _ O
downstream -X- _ B-MetricName
accuracy -X- _ I-MetricName
than -X- _ O
BERT -X- _ B-MethodName
when -X- _ O
fully -X- _ O
trained -X- _ O
. -X- _ O
We -X- _ O
speculate -X- _ O
that -X- _ O
ELECTRA -X- _ B-MethodName
is -X- _ O
more -X- _ O
parameter -X- _ O
- -X- _ O
efﬁcient -X- _ O
than -X- _ O
BERT -X- _ B-MethodName
because -X- _ O
it -X- _ O
does -X- _ O
not -X- _ O
have -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
full -X- _ O
distribution -X- _ O
of -X- _ O
possible -X- _ O
tokens -X- _ O
at -X- _ O
each -X- _ O
position -X- _ O
, -X- _ O
but -X- _ O
we -X- _ O
believe -X- _ O
more -X- _ O
analysis -X- _ O
is -X- _ O
needed -X- _ O
to -X- _ O
completely -X- _ O
explain -X- _ O
ELECTRA -X- _ B-MethodName
’s -X- _ O
parameter -X- _ O
efﬁciency -X- _ O
. -X- _ O

same -X- _ O
10 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
our -X- _ O
results -X- _ O
suggest -X- _ O
these -X- _ O
simple -X- _ O
heuristics -X- _ O
are -X- _ O
insufﬁcient -X- _ O
to -X- _ O
fully -X- _ O
solve -X- _ O
the -X- _ O
issue -X- _ O
. -X- _ O
Lastly -X- _ O
, -X- _ O
we -X- _ O
ﬁnd -X- _ O
that -X- _ O
All -X- _ O
- -X- _ O
Tokens -X- _ O
MLM -X- _ O
, -X- _ O
the -X- _ O
generative -X- _ O
model -X- _ O
that -X- _ O
makes -X- _ O
predictions -X- _ O
over -X- _ O
all -X- _ O
tokens -X- _ O
instead -X- _ O
of -X- _ O
a -X- _ O
subset -X- _ O
, -X- _ O
closes -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
gap -X- _ O
between -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
ELECTRA -X- _ B-MethodName
. -X- _ O
In -X- _ O
total -X- _ O
, -X- _ O
these -X- _ O
results -X- _ O
suggest -X- _ O
a -X- _ O
large -X- _ O
amount -X- _ O
of -X- _ O
ELECTRA -X- _ B-MethodName
’s -X- _ O
improvement -X- _ O
can -X- _ O
be -X- _ O
attributed -X- _ O
to -X- _ O
learning -X- _ O
from -X- _ O
all -X- _ O
tokens -X- _ O
and -X- _ O
a -X- _ O
smaller -X- _ O
amount -X- _ O
can -X- _ O
be -X- _ O
attributed -X- _ O
to -X- _ O
alleviating -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
ﬁne -X- _ O
- -X- _ O
tune -X- _ O
mismatch -X- _ O
. -X- _ O

Results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
5 -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
we -X- _ O
ﬁnd -X- _ O
that -X- _ O
ELECTRA -X- _ B-MethodName
is -X- _ O
greatly -X- _ O
beneﬁting -X- _ O
from -X- _ O
having -X- _ O
a -X- _ O
loss -X- _ O
deﬁned -X- _ O
over -X- _ O
all -X- _ O
input -X- _ O
tokens -X- _ O
rather -X- _ O
than -X- _ O
just -X- _ O
a -X- _ O
subset -X- _ O
: -X- _ O
ELECTRA -X- _ B-MethodName
15 -X- _ O
% -X- _ O
performs -X- _ O
much -X- _ O
worse -X- _ O
than -X- _ O
ELECTRA -X- _ B-MethodName
. -X- _ O
Secondly -X- _ O
, -X- _ O
we -X- _ O
ﬁnd -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
performance -X- _ O
is -X- _ O
being -X- _ O
slightly -X- _ O
harmed -X- _ O
from -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
ﬁne -X- _ O
- -X- _ O
tune -X- _ O
mismatch -X- _ O
from -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
tokens -X- _ O
, -X- _ O
as -X- _ O
Replace -X- _ O
MLM -X- _ O
slightly -X- _ O
outperforms -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
We -X- _ O
note -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
including -X- _ O
our -X- _ O
implementation -X- _ O
) -X- _ O
already -X- _ O
includes -X- _ O
a -X- _ O
trick -X- _ O
to -X- _ O
help -X- _ O
with -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
train/ﬁne- -X- _ O
tune -X- _ O
discrepancy -X- _ O
: -X- _ O
masked -X- _ O
tokens -X- _ O
are -X- _ O
replaced -X- _ O
with -X- _ O
a -X- _ O
random -X- _ O
token -X- _ O
10 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
and -X- _ O
are -X- _ O
kept -X- _ O
the -X- _ O

• -X- _ O
All -X- _ O
- -X- _ O
Tokens -X- _ O
MLM -X- _ O
: -X- _ O
Like -X- _ O
in -X- _ O
Replace -X- _ O
MLM -X- _ O
, -X- _ O
masked -X- _ O
tokens -X- _ O
are -X- _ O
replaced -X- _ O
with -X- _ O
generator -X- _ O
sam- -X- _ O
ples -X- _ O
. -X- _ O
Furthermore -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
predicts -X- _ O
the -X- _ O
identity -X- _ O
of -X- _ O
all -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
, -X- _ O
not -X- _ O
just -X- _ O
ones -X- _ O
that -X- _ O
were -X- _ O
masked -X- _ O
out -X- _ O
. -X- _ O
We -X- _ O
found -X- _ O
it -X- _ O
improved -X- _ O
results -X- _ O
to -X- _ O
train -X- _ O
this -X- _ O
model -X- _ O
with -X- _ O
an -X- _ O
explicit -X- _ O
copy -X- _ O
mechanism -X- _ O
that -X- _ O
outputs -X- _ O
a -X- _ O
copy -X- _ O
probability -X- _ O
D -X- _ O
for -X- _ O
each -X- _ O
token -X- _ O
using -X- _ O
a -X- _ O
sigmoid -X- _ O
layer -X- _ O
. -X- _ O
The -X- _ O
model -X- _ O
’s -X- _ O
output -X- _ O
distribution -X- _ O
puts -X- _ O
D -X- _ O
weight -X- _ O
on -X- _ O
the -X- _ O
input -X- _ O
token -X- _ O
plus -X- _ O
1 -X- _ O
− -X- _ O
D -X- _ O
times -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
the -X- _ O
MLM -X- _ O
softmax -X- _ O
. -X- _ O
This -X- _ O
model -X- _ O
is -X- _ O
essentially -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
ELEC- -X- _ B-MethodName
TRA -X- _ I-MethodName
. -X- _ O
Note -X- _ O
that -X- _ O
without -X- _ O
generator -X- _ O
replacements -X- _ O
, -X- _ O
the -X- _ O
model -X- _ O
would -X- _ O
trivially -X- _ O
learn -X- _ O
to -X- _ O
make -X- _ O
predictions -X- _ O
from -X- _ O
the -X- _ O
vocabulary -X- _ O
for -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
tokens -X- _ O
and -X- _ O
copy -X- _ O
the -X- _ O
input -X- _ O
for -X- _ O
other -X- _ O
ones -X- _ O
. -X- _ O

mark -X- _ O
. -X- _ O
ELECTRA -X- _ B-MethodName
- -X- _ I-MethodName
Base -X- _ I-MethodName
also -X- _ O
yields -X- _ O
strong -X- _ O
results -X- _ O
, -X- _ O
scoring -X- _ O
substantially -X- _ O
better -X- _ O
than -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
Base -X- _ I-MethodName
and -X- _ O
XLNet -X- _ B-MethodName
- -X- _ I-MethodName
Base -X- _ I-MethodName
, -X- _ O
and -X- _ O
even -X- _ O
surpassing -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
Large -X- _ I-MethodName
according -X- _ O
to -X- _ O
most -X- _ O
metrics -X- _ O
. -X- _ O
ELECTRA -X- _ B-MethodName
generally -X- _ O
performs -X- _ O
better -X- _ O
at -X- _ O
SQuAD -X- _ B-DatasetName
2.0 -X- _ I-DatasetName
than -X- _ O
1.1 -X- _ O
. -X- _ O
Perhaps -X- _ O
replaced -X- _ O
token -X- _ O
detection -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
model -X- _ O
distinguishes -X- _ O
real -X- _ O
tokens -X- _ O
from -X- _ O
plausible -X- _ O
fakes -X- _ O
, -X- _ O
is -X- _ O
particularly -X- _ O
transferable -X- _ O
to -X- _ O
the -X- _ O
answerability -X- _ O
clas- -X- _ O
siﬁcation -X- _ O
of -X- _ O
SQuAD -X- _ B-DatasetName
2.0 -X- _ I-DatasetName
, -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
model -X- _ O
must -X- _ O
distinguish -X- _ O
answerable -X- _ O
questions -X- _ O
from -X- _ O
fake -X- _ O
unan- -X- _ O
swerable -X- _ O
questions -X- _ O
. -X- _ O

Results -X- _ O
on -X- _ O
SQuAD -X- _ B-DatasetName
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
4 -X- _ O
. -X- _ O
Consistent -X- _ O
, -X- _ O
with -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
results -X- _ O
, -X- _ O
ELECTRA -X- _ B-MethodName
scores -X- _ O
better -X- _ O
than -X- _ O
masked -X- _ O
- -X- _ O
language -X- _ O
- -X- _ O
modeling -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
given -X- _ O
the -X- _ O
same -X- _ O
compute -X- _ O
resources -X- _ O
. -X- _ O
For -X- _ O
ex- -X- _ O
ample -X- _ O
, -X- _ O
ELECTRA-400 -X- _ B-MethodName
K -X- _ I-MethodName
outperforms -X- _ O
RoBERTa-100k -X- _ B-MethodName
and -X- _ O
our -X- _ O
BERT -X- _ B-MethodName
baseline -X- _ O
, -X- _ O
which -X- _ O
use -X- _ O
similar -X- _ O
amounts -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
compute -X- _ O
. -X- _ O
ELECTRA-400 -X- _ B-MethodName
K -X- _ O
also -X- _ O
performs -X- _ O
comparably -X- _ O
to -X- _ O
RoBERTa-500 -X- _ B-MethodName
K -X- _ O
despite -X- _ O
using -X- _ O
less -X- _ O
than -X- _ O
1/4th -X- _ O
of -X- _ O
the -X- _ O
compute -X- _ O
. -X- _ O
Unsurprisingly -X- _ O
, -X- _ O
training -X- _ O
ELECTRA -X- _ B-MethodName
longer -X- _ O
improves -X- _ O
results -X- _ O
further -X- _ O
: -X- _ O
ELECTRA-1.75 -X- _ B-MethodName
M -X- _ O
scores -X- _ O
higher -X- _ O
than -X- _ O
previous -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
SQuAD -X- _ B-DatasetName
2.0 -X- _ I-DatasetName
bench- -X- _ O

Results -X- _ O
on -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
dev -X- _ O
set -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
2 -X- _ O
. -X- _ O
ELECTRA-400 -X- _ B-MethodName
K -X- _ O
performs -X- _ O
comparably -X- _ O
to -X- _ O
RoBERTa -X- _ B-MethodName
and -X- _ O
XLNet -X- _ B-MethodName
. -X- _ O
However -X- _ O
, -X- _ O
it -X- _ O
took -X- _ O
less -X- _ O
than -X- _ O
1/4 -X- _ O
of -X- _ O
the -X- _ O
compute -X- _ O
to -X- _ O
train -X- _ O
ELECTRA-400 -X- _ B-MethodName
K -X- _ I-MethodName
as -X- _ O
it -X- _ O
did -X- _ O
to -X- _ O
train -X- _ O
RoBERTa -X- _ B-MethodName
and -X- _ O
XLNet -X- _ B-MethodName
, -X- _ O
demonstrating -X- _ O
that -X- _ O
ELECTRA -X- _ B-MethodName
’s -X- _ O
sample -X- _ O
- -X- _ O
efﬁciency -X- _ O
gains -X- _ O
hold -X- _ O
at -X- _ O
large -X- _ O
scale -X- _ O
. -X- _ O
Training -X- _ O
ELECTRA -X- _ B-MethodName
for -X- _ O
longer -X- _ O
( -X- _ O
ELECTRA-1.75 -X- _ B-MethodName
M -X- _ I-MethodName
) -X- _ O
results -X- _ O
in -X- _ O
a -X- _ O
model -X- _ O
that -X- _ O
outscores -X- _ O
them -X- _ O
on -X- _ O
most -X- _ O
GLUE -X- _ B-DatasetName
tasks -X- _ O
while -X- _ O
still -X- _ O
requiring -X- _ O
less -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
compute -X- _ O
. -X- _ O
Surprisingly -X- _ O
, -X- _ O
our -X- _ O
baseline -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
scores -X- _ O
notably -X- _ O
worse -X- _ O
than -X- _ O
RoBERTa-100 -X- _ B-MethodName
K -X- _ I-MethodName
, -X- _ O
suggesting -X- _ O
our -X- _ O
models -X- _ O
may -X- _ O
beneﬁt -X- _ O
from -X- _ O
more -X- _ O
hyperparameter -X- _ O
tuning -X- _ O
or -X- _ O
using -X- _ O
the -X- _ O
RoBERTa -X- _ B-MethodName
training -X- _ O
data -X- _ O
. -X- _ O
ELECTRA -X- _ B-MethodName
’s -X- _ O
gains -X- _ O
hold -X- _ O
on -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
test -X- _ O
set -X- _ O
( -X- _ O
see -X- _ O
Table -X- _ O
3 -X- _ O
) -X- _ O
, -X- _ O
although -X- _ O
these -X- _ O
comparisons -X- _ O
are -X- _ O
less -X- _ O
apples -X- _ O
- -X- _ O
to -X- _ O
- -X- _ O
apples -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
additional -X- _ O
tricks -X- _ O
employed -X- _ O
by -X- _ O
the -X- _ O
models -X- _ O
( -X- _ O
see -X- _ O
Appendix -X- _ O
B -X- _ O
) -X- _ O
. -X- _ O

We -X- _ O
train -X- _ O
big -X- _ O
ELECTRA -X- _ B-MethodName
models -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
replaced -X- _ O
token -X- _ O
detection -X- _ O
pre- -X- _ O
training -X- _ O
task -X- _ O
at -X- _ O
the -X- _ O
large -X- _ O
scale -X- _ O
of -X- _ O
current -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
Transformers -X- _ O
. -X- _ O
Our -X- _ O
ELECTRA- -X- _ B-MethodName
Large -X- _ I-MethodName
models -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
size -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
Large -X- _ I-MethodName
but -X- _ O
are -X- _ O
trained -X- _ O
for -X- _ O
much -X- _ O
longer -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
model -X- _ O
for -X- _ O
400k -X- _ B-HyperparameterValue
steps -X- _ B-HyperparameterName
( -X- _ O
ELECTRA-400 -X- _ B-MethodName
K -X- _ O
; -X- _ O
roughly -X- _ O
1/4 -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
compute -X- _ O
of -X- _ O
RoBERTa -X- _ B-MethodName
) -X- _ O
and -X- _ O
one -X- _ O
for -X- _ O
1.75 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
steps -X- _ B-HyperparameterName
( -X- _ O
ELECTRA-1.75 -X- _ B-HyperparameterName
M -X- _ O
; -X- _ O
similar -X- _ O
compute -X- _ O
to -X- _ O
RoBERTa -X- _ B-MethodName
) -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
2048 -X- _ B-HyperparameterValue
and -X- _ O
the -X- _ O
XLNet -X- _ B-MethodName
pre -X- _ O
- -X- _ O
training -X- _ O
data -X- _ O
. -X- _ O
We -X- _ O
note -X- _ O
that -X- _ O
although -X- _ O
the -X- _ O
XLNet -X- _ B-MethodName
data -X- _ O
is -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
data -X- _ O
used -X- _ O
to -X- _ O
train -X- _ O
RoBERTa -X- _ B-MethodName
, -X- _ O
the -X- _ O
comparison -X- _ O
is -X- _ O
not -X- _ O
entirely -X- _ O
direct -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
baseline -X- _ O
, -X- _ O
we -X- _ O
trained -X- _ O
our -X- _ O
own -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
Large -X- _ I-MethodName
model -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
hyperparameters -X- _ O
and -X- _ O
training -X- _ O
time -X- _ O
as -X- _ O
ELECTRA-400K. -X- _ B-MethodName

Results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
1 -X- _ O
. -X- _ O
See -X- _ O
Appendix -X- _ O
D -X- _ O
for -X- _ O
additional -X- _ O
results -X- _ O
, -X- _ O
including -X- _ O
stronger -X- _ O
small -X- _ O
- -X- _ O
sized -X- _ O
and -X- _ O
base -X- _ O
- -X- _ O
sized -X- _ O
models -X- _ O
trained -X- _ O
with -X- _ O
more -X- _ O
compute -X- _ O
. -X- _ O
ELECTRA -X- _ B-MethodName
- -X- _ I-MethodName
Small -X- _ I-MethodName
performs -X- _ O
remarkably -X- _ O
well -X- _ O
given -X- _ O
its -X- _ O
size -X- _ O
, -X- _ O
achieving -X- _ O
a -X- _ O
higher -X- _ O
GLUE -X- _ B-MetricName
score -X- _ I-MetricName
than -X- _ O
other -X- _ O
methods -X- _ O
using -X- _ O
substantially -X- _ O
more -X- _ O
compute -X- _ O
and -X- _ O
parameters -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
it -X- _ O
scores -X- _ O
5 -X- _ B-MetricValue
points -X- _ O
higher -X- _ O
than -X- _ O
a -X- _ O
comparable -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
Small -X- _ I-MethodName
model -X- _ O
and -X- _ O
even -X- _ O
outperforms -X- _ O
the -X- _ O
much -X- _ O
larger -X- _ O
GPT -X- _ B-MethodName
model -X- _ O
. -X- _ O
ELECTRA -X- _ B-MethodName
- -X- _ I-MethodName
Small -X- _ I-MethodName
is -X- _ O
trained -X- _ O
mostly -X- _ O
to -X- _ O
convergence -X- _ O
, -X- _ O
with -X- _ O
models -X- _ O
trained -X- _ O
for -X- _ O
even -X- _ O
less -X- _ O
time -X- _ O
( -X- _ O
as -X- _ O
little -X- _ O
as -X- _ O
6 -X- _ O
hours -X- _ O
) -X- _ O
still -X- _ O
achieving -X- _ O
reasonable -X- _ O
performance -X- _ O
. -X- _ O
While -X- _ O
small -X- _ O
models -X- _ O
distilled -X- _ O
from -X- _ O
larger -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
transformers -X- _ O
can -X- _ O
also -X- _ O
achieve -X- _ O
good -X- _ O
GLUE -X- _ B-MetricName
scores -X- _ I-MetricName
( -X- _ O
Sun -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019b -X- _ O
; -X- _ O
Jiao -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
these -X- _ O
models -X- _ O
require -X- _ O
ﬁrst -X- _ O
expending -X- _ O
substantial -X- _ O
compute -X- _ O
to -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
the -X- _ O
larger -X- _ O
teacher -X- _ O
model -X- _ O
. -X- _ O
The -X- _ O
results -X- _ O
also -X- _ O
demonstrate -X- _ O
the -X- _ O
strength -X- _ O
of -X- _ O
ELECTRA -X- _ B-MethodName
at -X- _ O
a -X- _ O
moderate -X- _ O
size -X- _ O
; -X- _ O
our -X- _ O
base -X- _ O
- -X- _ O
sized -X- _ O
ELECTRA -X- _ B-MethodName
model -X- _ O
substantially -X- _ O
outperforms -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
Base -X- _ I-MethodName
and -X- _ O
even -X- _ O
outperforms -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
Large -X- _ I-MethodName
( -X- _ O
which -X- _ O
gets -X- _ O
84.0 -X- _ B-MetricValue
GLUE -X- _ B-MetricName
score -X- _ I-MetricName
) -X- _ O
. -X- _ O
We -X- _ O
hope -X- _ O
ELECTRA -X- _ B-MethodName
’s -X- _ O
ability -X- _ O
to -X- _ O
achieve -X- _ O
strong -X- _ O
results -X- _ O
with -X- _ O
relatively -X- _ O
little -X- _ O
compute -X- _ O
will -X- _ O
broaden -X- _ O
the -X- _ O
accessibility -X- _ O
of -X- _ O
developing -X- _ O
and -X- _ O
applying -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
models -X- _ O
in -X- _ O
NLP -X- _ O
. -X- _ O

As -X- _ O
a -X- _ O
goal -X- _ O
of -X- _ O
this -X- _ O
work -X- _ O
is -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
efﬁciency -X- _ O
of -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
develop -X- _ O
a -X- _ O
small -X- _ O
model -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
quickly -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
GPU -X- _ O
. -X- _ O
Starting -X- _ O
with -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
- -X- _ O
Base -X- _ O
hyperparameters -X- _ O
, -X- _ O
we -X- _ O
shortened -X- _ O
the -X- _ O
sequence -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
( -X- _ O
from -X- _ O
512 -X- _ B-HyperparameterValue
to -X- _ O
128 -X- _ B-HyperparameterValue
) -X- _ O
, -X- _ O
reduced -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
( -X- _ O
from -X- _ O
256 -X- _ B-HyperparameterValue
to -X- _ O
128 -X- _ B-HyperparameterValue
) -X- _ O
, -X- _ O
reduced -X- _ O
the -X- _ O
model -X- _ O
’s -X- _ O
hidden -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
( -X- _ O
from -X- _ O
768 -X- _ B-HyperparameterValue
to -X- _ O
256 -X- _ B-HyperparameterValue
) -X- _ O
, -X- _ O
and -X- _ O
used -X- _ O
smaller -X- _ O
token -X- _ B-HyperparameterName
embeddings -X- _ I-HyperparameterName
( -X- _ O
from -X- _ O
768 -X- _ B-HyperparameterValue
to -X- _ O
128 -X- _ B-HyperparameterValue
) -X- _ O
. -X- _ O
To -X- _ O
provide -X- _ O
a -X- _ O
fair -X- _ O
comparison -X- _ O
, -X- _ O
we -X- _ O
also -X- _ O
train -X- _ O
a -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
Small -X- _ I-MethodName
model -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
hyperparameters -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
Small -X- _ I-MethodName
for -X- _ O
1.5 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
steps -X- _ B-HyperparameterName
, -X- _ O
so -X- _ O
it -X- _ O
uses -X- _ O
the -X- _ O
same -X- _ O
training -X- _ O
FLOPs -X- _ O
as -X- _ O
ELECTRA -X- _ B-MethodName
- -X- _ I-MethodName
Small -X- _ I-MethodName
, -X- _ O
which -X- _ O
was -X- _ O
trained -X- _ O
for -X- _ O
1 -X- _ B-HyperparameterValue
M -X- _ I-HyperparameterValue
steps.5 -X- _ B-HyperparameterName
In -X- _ O
addition -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
we -X- _ O
compare -X- _ O
against -X- _ O
two -X- _ O
less -X- _ O
resource -X- _ O
- -X- _ O
intensive -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
methods -X- _ O
based -X- _ O
on -X- _ O
language -X- _ O
modeling -X- _ O
: -X- _ O
ELMo -X- _ B-MethodName
( -X- _ O
Peters -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
and -X- _ O
GPT -X- _ B-MethodName
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018).6 -X- _ O
We -X- _ O
also -X- _ O
show -X- _ O
results -X- _ O
for -X- _ O
a -X- _ O
base -X- _ O
- -X- _ O
sized -X- _ O
ELECTRA -X- _ B-MethodName
model -X- _ O
comparable -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
- -X- _ O
Base -X- _ O
. -X- _ O

problems -X- _ O
with -X- _ O
adversarial -X- _ O
training -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
the -X- _ O
adversarial -X- _ O
generator -X- _ O
is -X- _ O
simply -X- _ O
worse -X- _ O
at -X- _ O
masked -X- _ O
lan- -X- _ O
guage -X- _ O
modeling -X- _ O
; -X- _ O
it -X- _ O
achieves -X- _ O
58 -X- _ B-MetricValue
% -X- _ I-MetricValue
accuracy -X- _ B-MetricName
at -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
compared -X- _ O
to -X- _ O
65 -X- _ B-MetricValue
% -X- _ I-MetricValue
accuracy -X- _ B-MetricName
for -X- _ O
an -X- _ O
MLE -X- _ O
- -X- _ O
trained -X- _ O
one -X- _ O
. -X- _ O
We -X- _ O
believe -X- _ O
the -X- _ O
worse -X- _ O
accuracy -X- _ B-MetricName
is -X- _ O
mainly -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
poor -X- _ O
sample -X- _ O
efﬁciency -X- _ O
of -X- _ O
reinforcement -X- _ O
learning -X- _ O
when -X- _ O
working -X- _ O
in -X- _ O
the -X- _ O
large -X- _ O
action -X- _ O
space -X- _ O
of -X- _ O
generating -X- _ O
text -X- _ O
. -X- _ O
Secondly -X- _ O
, -X- _ O
the -X- _ O
adversarially -X- _ O
trained -X- _ O
generator -X- _ O
produces -X- _ O
a -X- _ O
low -X- _ O
- -X- _ O
entropy -X- _ B-MetricName
output -X- _ O
distribution -X- _ O
where -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
proba- -X- _ O
bility -X- _ O
mass -X- _ O
is -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
token -X- _ O
, -X- _ O
which -X- _ O
means -X- _ O
there -X- _ O
is -X- _ O
not -X- _ O
much -X- _ O
diversity -X- _ O
in -X- _ O
the -X- _ O
generator -X- _ O
samples -X- _ O
. -X- _ O
Both -X- _ O
of -X- _ O
these -X- _ O
problems -X- _ O
have -X- _ O
been -X- _ O
observed -X- _ O
in -X- _ O
GANs -X- _ O
for -X- _ O
text -X- _ O
in -X- _ O
prior -X- _ O
work -X- _ O
( -X- _ O
Caccia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

Results -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
right -X- _ O
of -X- _ O
Figure -X- _ O
3 -X- _ O
. -X- _ O
During -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
training -X- _ O
, -X- _ O
downstream -X- _ O
task -X- _ O
performance -X- _ O
notably -X- _ O
improves -X- _ O
after -X- _ O
the -X- _ O
switch -X- _ O
from -X- _ O
the -X- _ O
generative -X- _ O
to -X- _ O
the -X- _ O
discriminative -X- _ O
objective -X- _ O
, -X- _ O
but -X- _ O
does -X- _ O
not -X- _ O
end -X- _ O
up -X- _ O
outscoring -X- _ O
joint -X- _ O
training -X- _ O
. -X- _ O
Although -X- _ O
still -X- _ O
outperforming -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
we -X- _ O
found -X- _ O
adversarial -X- _ O
training -X- _ O
to -X- _ O
underperform -X- _ O
maximum -X- _ B-MethodName
- -X- _ I-MethodName
likelihood -X- _ I-MethodName
training -X- _ I-MethodName
. -X- _ O
Further -X- _ O
analysis -X- _ O
suggests -X- _ O
the -X- _ O
gap -X- _ O
is -X- _ O
caused -X- _ O
by -X- _ O
two -X- _ O

Note -X- _ O
that -X- _ O
the -X- _ O
weight -X- _ O
initialization -X- _ O
in -X- _ O
this -X- _ O
procedure -X- _ O
requires -X- _ O
having -X- _ O
the -X- _ O
same -X- _ O
size -X- _ B-HyperparameterName
for -X- _ O
the -X- _ O
generator -X- _ O
and -X- _ O
discriminator -X- _ O
. -X- _ O
We -X- _ O
found -X- _ O
that -X- _ O
without -X- _ O
the -X- _ O
weight -X- _ O
initialization -X- _ O
the -X- _ O
discriminator -X- _ O
would -X- _ O
some- -X- _ O
times -X- _ O
fail -X- _ O
to -X- _ O
learn -X- _ O
at -X- _ O
all -X- _ O
beyond -X- _ O
the -X- _ O
majority -X- _ O
class -X- _ O
, -X- _ O
perhaps -X- _ O
because -X- _ O
the -X- _ O
generator -X- _ O
started -X- _ O
so -X- _ O
far -X- _ O
ahead -X- _ O
of -X- _ O
the -X- _ O
discriminator -X- _ O
. -X- _ O
Joint -X- _ O
training -X- _ O
on -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
naturally -X- _ O
provides -X- _ O
a -X- _ O
curriculum -X- _ O
for -X- _ O
the -X- _ O
dis- -X- _ O
criminator -X- _ O
where -X- _ O
the -X- _ O
generator -X- _ O
starts -X- _ O
off -X- _ O
weak -X- _ O
but -X- _ O
gets -X- _ O
better -X- _ O
throughout -X- _ O
training -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
explored -X- _ O
training -X- _ O
the -X- _ O
generator -X- _ O
adversarially -X- _ O
as -X- _ O
in -X- _ O
a -X- _ O
GAN -X- _ O
, -X- _ O
using -X- _ O
reinforcement -X- _ O
learning -X- _ O
to -X- _ O
accommodate -X- _ O
the -X- _ O
discrete -X- _ O
operations -X- _ O
of -X- _ O
sampling -X- _ O
from -X- _ O
the -X- _ O
generator -X- _ O
. -X- _ O
See -X- _ O
Appendix -X- _ O
F -X- _ O
for -X- _ O
details -X- _ O
. -X- _ O

1 -X- _ O
. -X- _ O
Train -X- _ O
only -X- _ O
the -X- _ O
generator -X- _ O
with -X- _ O
LMLM -X- _ O
for -X- _ O
n -X- _ O
steps -X- _ B-HyperparameterName
. -X- _ O
2 -X- _ O
. -X- _ O
Initialize -X- _ O
the -X- _ O
weights -X- _ O
of -X- _ O
the -X- _ O
discriminator -X- _ O
with -X- _ O
the -X- _ O
weights -X- _ O
of -X- _ O
the -X- _ O
generator -X- _ O
. -X- _ O
Then -X- _ O
train -X- _ O
the -X- _ O
discriminator -X- _ O
with -X- _ O
LDisc -X- _ O
for -X- _ O
n -X- _ O
steps -X- _ B-HyperparameterName
, -X- _ O
keeping -X- _ O
the -X- _ O
generator -X- _ O
’s -X- _ O
weights -X- _ O
frozen -X- _ O
. -X- _ O

Training -X- _ O
Algorithms -X- _ O
Lastly -X- _ O
, -X- _ O
we -X- _ O
explore -X- _ O
other -X- _ O
training -X- _ O
algorithms -X- _ O
for -X- _ O
ELECTRA -X- _ B-MethodName
, -X- _ O
although -X- _ O
these -X- _ O
did -X- _ O
not -X- _ O
end -X- _ O
up -X- _ O
improving -X- _ O
results -X- _ O
. -X- _ O
The -X- _ O
proposed -X- _ O
training -X- _ O
objective -X- _ O
jointly -X- _ O
trains -X- _ O
the -X- _ O
generator -X- _ O
and -X- _ O
discriminator -X- _ O
. -X- _ O
We -X- _ O
experiment -X- _ O
with -X- _ O
instead -X- _ O
using -X- _ O
the -X- _ O
following -X- _ O
two -X- _ O
- -X- _ O
stage -X- _ O
training -X- _ O
procedure -X- _ O
: -X- _ O

Smaller -X- _ O
Generators -X- _ O
If -X- _ O
the -X- _ O
generator -X- _ O
and -X- _ O
discriminator -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
size -X- _ O
, -X- _ O
training -X- _ O
ELECTRA -X- _ B-MethodName
would -X- _ O
take -X- _ O
around -X- _ O
twice -X- _ O
as -X- _ O
much -X- _ O
compute -X- _ O
per -X- _ O
step -X- _ O
as -X- _ O
training -X- _ O
only -X- _ O
with -X- _ O
masked -X- _ O
language -X- _ O
mod- -X- _ O
eling -X- _ O
. -X- _ O
We -X- _ O
suggest -X- _ O
using -X- _ O
a -X- _ O
smaller -X- _ O
generator -X- _ O
to -X- _ O
reduce -X- _ O
this -X- _ O
factor -X- _ O
. -X- _ O
Speciﬁcally -X- _ O
, -X- _ O
we -X- _ O
make -X- _ O
models -X- _ O
smaller -X- _ O
by -X- _ O
decreasing -X- _ O
the -X- _ O
layer -X- _ B-HyperparameterName
sizes -X- _ I-HyperparameterName
while -X- _ O
keeping -X- _ O
the -X- _ O
other -X- _ O
hyperparameters -X- _ O
constant -X- _ O
. -X- _ O
We -X- _ O
also -X- _ O
explore -X- _ O
using -X- _ O
an -X- _ O
extremely -X- _ O
simple -X- _ O
“ -X- _ O
unigram -X- _ O
” -X- _ O
generator -X- _ O
that -X- _ O
samples -X- _ O
fake -X- _ O
tokens -X- _ O
according -X- _ O
their -X- _ O
frequency -X- _ O
in -X- _ O
the -X- _ O
train -X- _ O
corpus -X- _ O
. -X- _ O
GLUE -X- _ B-DatasetName
scores -X- _ O
for -X- _ O
differently -X- _ O
- -X- _ O
sized -X- _ O
generators -X- _ O
and -X- _ O
discriminators -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
left -X- _ O
of -X- _ O
Figure -X- _ O
3 -X- _ O
. -X- _ O
All -X- _ O
models -X- _ O
are -X- _ O
trained -X- _ O
for -X- _ O
500k -X- _ B-HyperparameterValue
steps -X- _ B-HyperparameterName
, -X- _ O
which -X- _ O
puts -X- _ O
the -X- _ O
smaller -X- _ O
gen- -X- _ O
erators -X- _ O
at -X- _ O
a -X- _ O
disadvantage -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
compute -X- _ O
because -X- _ O
they -X- _ O
require -X- _ O
less -X- _ O
compute -X- _ O
per -X- _ O
training -X- _ O
step -X- _ O
. -X- _ O
Nevertheless -X- _ O
, -X- _ O
we -X- _ O
ﬁnd -X- _ O
that -X- _ O
models -X- _ O
work -X- _ O
best -X- _ O
with -X- _ O
generators -X- _ O
1/4 -X- _ O
- -X- _ O
1/2 -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
discriminator -X- _ O
. -X- _ O
We -X- _ O
speculate -X- _ O
that -X- _ O
having -X- _ O
too -X- _ O
strong -X- _ O
of -X- _ O
a -X- _ O
generator -X- _ O
may -X- _ O
pose -X- _ O
a -X- _ O
too -X- _ O
- -X- _ O
challenging -X- _ O
task -X- _ O
for -X- _ O
the -X- _ O
discriminator -X- _ O
, -X- _ O
preventing -X- _ O
it -X- _ O
from -X- _ O
learning -X- _ O
as -X- _ O
effectively -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
the -X- _ O
discriminator -X- _ O
may -X- _ O
have -X- _ O
to -X- _ O
use -X- _ O
many -X- _ O
of -X- _ O
its -X- _ O
parameters -X- _ O
modeling -X- _ O
the -X- _ O
generator -X- _ O
rather -X- _ O
than -X- _ O
the -X- _ O
actual -X- _ O
data -X- _ O
distribution -X- _ O
. -X- _ O
Further -X- _ O
experiments -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
use -X- _ O
the -X- _ O
best -X- _ O
generator -X- _ O
size -X- _ B-HyperparameterName
found -X- _ O
for -X- _ O
the -X- _ O
given -X- _ O
discriminator -X- _ O
size -X- _ B-HyperparameterName
. -X- _ O

tied -X- _ O
token -X- _ O
embeddings -X- _ O
because -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
is -X- _ O
particularly -X- _ O
effective -X- _ O
at -X- _ O
learning -X- _ O
these -X- _ O
representations -X- _ O
: -X- _ O
while -X- _ O
the -X- _ O
discriminator -X- _ O
only -X- _ O
updates -X- _ O
tokens -X- _ O
that -X- _ O
are -X- _ O
present -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
or -X- _ O
are -X- _ O
sampled -X- _ O
by -X- _ O
the -X- _ O
generator -X- _ O
, -X- _ O
the -X- _ O
generator -X- _ O
’s -X- _ O
softmax -X- _ O
over -X- _ O
the -X- _ O
vocabulary -X- _ O
densely -X- _ O
updates -X- _ O
all -X- _ O
token -X- _ O
embeddings -X- _ O
. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
hand -X- _ O
, -X- _ O
tying -X- _ O
all -X- _ O
encoder -X- _ O
weights -X- _ O
caused -X- _ O
little -X- _ O
improvement -X- _ O
while -X- _ O
incurring -X- _ O
the -X- _ O
signiﬁcant -X- _ O
disadvantage -X- _ O
of -X- _ O
requiring -X- _ O
the -X- _ O
generator -X- _ O
and -X- _ O
discriminator -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
same -X- _ O
size -X- _ O
. -X- _ O
Based -X- _ O
on -X- _ O
these -X- _ O
ﬁndings -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
tied -X- _ O
embeddings -X- _ O
for -X- _ O
further -X- _ O
experiments -X- _ O
in -X- _ O
this -X- _ O
paper -X- _ O
. -X- _ O

We -X- _ O
compare -X- _ O
the -X- _ O
weight -X- _ O
tying -X- _ O
strategies -X- _ O
when -X- _ O
the -X- _ O
generator -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
size -X- _ O
as -X- _ O
the -X- _ O
discriminator -X- _ O
. -X- _ O
We -X- _ O
train -X- _ O
these -X- _ O
models -X- _ O
for -X- _ O
500k -X- _ O
steps -X- _ O
. -X- _ O
GLUE -X- _ B-DatasetName
scores -X- _ O
are -X- _ O
83.6 -X- _ B-MetricValue
for -X- _ O
no -X- _ O
weight -X- _ O
tying -X- _ O
, -X- _ O
84.3 -X- _ B-MetricValue
for -X- _ O
tying -X- _ O
token -X- _ O
embeddings -X- _ O
, -X- _ O
and -X- _ O
84.4 -X- _ B-MetricValue
for -X- _ O
tying -X- _ O
all -X- _ O
weights -X- _ O
. -X- _ O
We -X- _ O
hypothesize -X- _ O
that -X- _ O
ELECTRA -X- _ B-MethodName
beneﬁts -X- _ O
from -X- _ O

Weight -X- _ O
Sharing -X- _ O
We -X- _ O
propose -X- _ O
improving -X- _ O
the -X- _ O
efﬁciency -X- _ O
of -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
by -X- _ O
sharing -X- _ O
weights -X- _ O
be- -X- _ O
tween -X- _ O
the -X- _ O
generator -X- _ O
and -X- _ O
discriminator -X- _ O
. -X- _ O
If -X- _ O
the -X- _ O
generator -X- _ O
and -X- _ O
discriminator -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
size -X- _ O
, -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
transformer -X- _ O
weights -X- _ O
can -X- _ O
be -X- _ O
tied -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
we -X- _ O
found -X- _ O
it -X- _ O
to -X- _ O
be -X- _ O
more -X- _ O
efﬁcient -X- _ O
to -X- _ O
have -X- _ O
a -X- _ O
small -X- _ O
genera- -X- _ O
tor -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
case -X- _ O
we -X- _ O
only -X- _ O
share -X- _ O
the -X- _ O
embeddings -X- _ O
( -X- _ O
both -X- _ O
the -X- _ O
token -X- _ O
and -X- _ O
positional -X- _ O
embeddings -X- _ O
) -X- _ O
of -X- _ O
the -X- _ O
generator -X- _ O
and -X- _ O
discriminator -X- _ O
. -X- _ O
In -X- _ O
this -X- _ O
case -X- _ O
we -X- _ O
use -X- _ O
embeddings -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
discriminator -X- _ O
’s -X- _ O
hidden -X- _ O
states.4 -X- _ O
The -X- _ O
“ -X- _ O
input -X- _ O
” -X- _ O
and -X- _ O
“ -X- _ O
output -X- _ O
” -X- _ O
token -X- _ O
embeddings -X- _ O
of -X- _ O
the -X- _ O
generator -X- _ O
are -X- _ O
always -X- _ O
tied -X- _ O
as -X- _ O
in -X- _ O
BERT -X- _ B-MethodName
. -X- _ O

We -X- _ O
improve -X- _ O
our -X- _ O
method -X- _ O
by -X- _ O
proposing -X- _ O
and -X- _ O
evaluating -X- _ O
several -X- _ O
extensions -X- _ O
to -X- _ O
the -X- _ O
model -X- _ O
. -X- _ O
Unless -X- _ O
stated -X- _ O
otherwise -X- _ O
, -X- _ O
these -X- _ O
experiments -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
model -X- _ O
size -X- _ O
and -X- _ O
training -X- _ O
data -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
- -X- _ I-MethodName
Base -X- _ I-MethodName
. -X- _ O

Our -X- _ O
model -X- _ O
architecture -X- _ O
and -X- _ O
most -X- _ O
hyperparameters -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
’s -X- _ O
. -X- _ O
For -X- _ O
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
on -X- _ O
GLUE -X- _ B-DatasetName
, -X- _ O
we -X- _ O
add -X- _ O
simple -X- _ O
linear -X- _ O
classiﬁers -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
ELECTRA -X- _ B-MethodName
. -X- _ O
For -X- _ O
SQuAD -X- _ B-DatasetName
, -X- _ O
we -X- _ O
add -X- _ O
the -X- _ O
question- -X- _ B-TaskName
answering -X- _ I-TaskName
module -X- _ O
from -X- _ O
XLNet -X- _ B-MethodName
on -X- _ O
top -X- _ O
of -X- _ O
ELECTRA -X- _ B-MethodName
, -X- _ O
which -X- _ O
is -X- _ O
slightly -X- _ O
more -X- _ O
sophisticated -X- _ O
than -X- _ O
BERT -X- _ B-MethodName
’s -X- _ O
in -X- _ O
that -X- _ O
it -X- _ O
jointly -X- _ O
rather -X- _ O
than -X- _ O
independently -X- _ O
predicts -X- _ O
the -X- _ O
start -X- _ O
and -X- _ O
end -X- _ O
positions -X- _ O
and -X- _ O
has -X- _ O
a -X- _ O
“ -X- _ O
answerability -X- _ O
” -X- _ O
classiﬁer -X- _ O
added -X- _ O
for -X- _ O
SQuAD -X- _ B-DatasetName
2.0 -X- _ I-DatasetName
. -X- _ O
Some -X- _ O
of -X- _ O
our -X- _ O
evaluation -X- _ O
datasets -X- _ O
are -X- _ O
small -X- _ O
, -X- _ O
which -X- _ O
means -X- _ O
accuracies -X- _ O
of -X- _ O
ﬁne -X- _ O
- -X- _ O
tuned -X- _ O
models -X- _ O
can -X- _ O
vary -X- _ O
substantially -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
random -X- _ O
seed -X- _ O
. -X- _ O
We -X- _ O
therefore -X- _ O
report -X- _ O
the -X- _ O
median -X- _ B-MetricName
of -X- _ O
10 -X- _ B-MetricValue
ﬁne -X- _ O
- -X- _ O
tuning -X- _ O
runs -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
checkpoint -X- _ O
for -X- _ O
each -X- _ O
result -X- _ O
. -X- _ O
Unless -X- _ O
stated -X- _ O
otherwise -X- _ O
, -X- _ O
results -X- _ O
are -X- _ O
on -X- _ O
the -X- _ O
dev -X- _ O
set -X- _ O
. -X- _ O
See -X- _ O
the -X- _ O
appendix -X- _ O
for -X- _ O
further -X- _ O
training -X- _ O
details -X- _ O
and -X- _ O
hyperparameter -X- _ O
values -X- _ O
. -X- _ O

We -X- _ O
evaluate -X- _ O
on -X- _ O
the -X- _ O
General -X- _ B-DatasetName
Language -X- _ I-DatasetName
Understanding -X- _ I-DatasetName
Evaluation -X- _ I-DatasetName
( -X- _ O
GLUE -X- _ B-DatasetName
) -X- _ O
benchmark -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
Stanford -X- _ B-DatasetName
Question -X- _ I-DatasetName
Answering -X- _ I-DatasetName
( -X- _ O
SQuAD -X- _ B-DatasetName
) -X- _ O
dataset -X- _ O
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
GLUE -X- _ B-DatasetName
contains -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
tasks -X- _ O
covering -X- _ O
textual -X- _ B-TaskName
entailment -X- _ I-TaskName
( -X- _ O
RTE -X- _ O
and -X- _ O
MNLI -X- _ O
) -X- _ O
question -X- _ B-TaskName
- -X- _ I-TaskName
answer -X- _ I-TaskName
entailment -X- _ I-TaskName
( -X- _ O
QNLI -X- _ O
) -X- _ O
, -X- _ O
paraphrase -X- _ B-TaskName
( -X- _ O
MRPC -X- _ O
) -X- _ O
, -X- _ O
question -X- _ B-TaskName
paraphrase -X- _ I-TaskName
( -X- _ O
QQP -X- _ O
) -X- _ O
, -X- _ O
textual -X- _ B-TaskName
similarity -X- _ I-TaskName
( -X- _ O
STS -X- _ B-TaskName
) -X- _ O
, -X- _ O
sentiment -X- _ B-TaskName
( -X- _ O
SST -X- _ B-TaskName
) -X- _ O
, -X- _ O
and -X- _ O
lin- -X- _ B-TaskName
guistic -X- _ I-TaskName
acceptability -X- _ I-TaskName
( -X- _ O
CoLA -X- _ B-DatasetName
) -X- _ O
. -X- _ O
See -X- _ O
Appendix -X- _ O
C -X- _ O
for -X- _ O
more -X- _ O
details -X- _ O
on -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
tasks -X- _ O
. -X- _ O
Our -X- _ O
evaluation -X- _ O
metrics -X- _ O
are -X- _ O
Spearman -X- _ B-MetricName
correlation -X- _ I-MetricName
for -X- _ O
STS -X- _ B-TaskName
, -X- _ O
Matthews -X- _ B-MetricName
correlation -X- _ I-MetricName
for -X- _ O
CoLA -X- _ B-DatasetName
, -X- _ O
and -X- _ O
accuracy -X- _ B-MetricName
for -X- _ O
the -X- _ O
other -X- _ O
GLUE -X- _ B-DatasetName
tasks -X- _ O
; -X- _ O
we -X- _ O
generally -X- _ O
report -X- _ O
the -X- _ O
average -X- _ O
score -X- _ O
over -X- _ O
all -X- _ O
tasks -X- _ O
. -X- _ O
For -X- _ O
SQuAD -X- _ B-DatasetName
, -X- _ O
we -X- _ O
evaluate -X- _ O
on -X- _ O
versions -X- _ O
1.1 -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
models -X- _ O
select -X- _ O
the -X- _ O
span -X- _ O
of -X- _ O
text -X- _ O
answering -X- _ O
a -X- _ O
question -X- _ O
, -X- _ O
and -X- _ O
2.0 -X- _ O
, -X- _ O
in -X- _ O
which -X- _ O
some -X- _ O
questions -X- _ O
are -X- _ O
unanswerable -X- _ O
by -X- _ O
the -X- _ O
passage -X- _ O
. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
standard -X- _ O
evaluation -X- _ O
metrics -X- _ O
of -X- _ O
Exact -X- _ B-MetricName
- -X- _ I-MetricName
Match -X- _ I-MetricName
( -X- _ O
EM -X- _ B-MetricName
) -X- _ O
and -X- _ O
F1 -X- _ B-MetricName
scores -X- _ I-MetricName
. -X- _ O
For -X- _ O
most -X- _ O
experiments -X- _ O
we -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
data -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
which -X- _ O
consists -X- _ O
of -X- _ O
3.3 -X- _ O
Billion -X- _ O
tokens -X- _ O
from -X- _ O
Wikipedia -X- _ B-DatasetName
and -X- _ O
BooksCorpus -X- _ B-DatasetName
( -X- _ O
Zhu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2015 -X- _ O
) -X- _ O
. -X- _ O
However -X- _ O
, -X- _ O
for -X- _ O
our -X- _ O
Large -X- _ O
model -X- _ O
we -X- _ O
pre -X- _ O
- -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
data -X- _ O
used -X- _ O
for -X- _ O
XLNet -X- _ B-MethodName
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
which -X- _ O
extends -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
dataset -X- _ O
to -X- _ O
33B -X- _ O
tokens -X- _ O
by -X- _ O
including -X- _ O
data -X- _ O
from -X- _ O
ClueWeb -X- _ B-DatasetName
( -X- _ O
Callan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2009 -X- _ O
) -X- _ O
, -X- _ O
CommonCrawl -X- _ B-DatasetName
, -X- _ O
and -X- _ O
Gigaword -X- _ B-DatasetName
( -X- _ O
Parker -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2011 -X- _ O
) -X- _ O
. -X- _ O
All -X- _ O
of -X- _ O
the -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
and -X- _ O
evaluation -X- _ O
is -X- _ O
on -X- _ O
English -X- _ B-DatasetName
data -X- _ I-DatasetName
, -X- _ O
although -X- _ O
we -X- _ O
think -X- _ O
it -X- _ O
would -X- _ O
be -X- _ O
interesting -X- _ O
to -X- _ O
apply -X- _ O
our -X- _ O
methods -X- _ O
to -X- _ O
multilingual -X- _ O
data -X- _ O
in -X- _ O
the -X- _ O
future -X- _ O
. -X- _ O

over -X- _ O
a -X- _ O
large -X- _ O
corpus -X- _ O
X -X- _ O
of -X- _ O
raw -X- _ O
text -X- _ O
. -X- _ O
We -X- _ O
approximate -X- _ O
the -X- _ O
expectations -X- _ O
in -X- _ O
the -X- _ O
losses -X- _ O
with -X- _ O
a -X- _ O
single -X- _ O
sample -X- _ O
. -X- _ O
We -X- _ O
do -X- _ O
n’t -X- _ O
back -X- _ O
- -X- _ O
propagate -X- _ O
the -X- _ O
discriminator -X- _ O
loss -X- _ O
through -X- _ O
the -X- _ O
generator -X- _ O
( -X- _ O
indeed -X- _ O
, -X- _ O
we -X- _ O
ca -X- _ O
n’t -X- _ O
because -X- _ O
of -X- _ O
the -X- _ O
sampling -X- _ O
step -X- _ O
) -X- _ O
. -X- _ O
After -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
, -X- _ O
we -X- _ O
throw -X- _ O
out -X- _ O
the -X- _ O
generator -X- _ O
and -X- _ O
ﬁne -X- _ O
- -X- _ O
tune -X- _ O
the -X- _ O
discriminator -X- _ O
on -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O

by -X- _ O
using -X- _ O
reinforcement -X- _ O
learning -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
generator -X- _ O
( -X- _ O
see -X- _ O
Appendix -X- _ O
F -X- _ O
) -X- _ O
, -X- _ O
this -X- _ O
performed -X- _ O
worse -X- _ O
than -X- _ O
maximum -X- _ O
- -X- _ O
likelihood -X- _ O
training -X- _ O
. -X- _ O
Lastly -X- _ O
, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
supply -X- _ O
the -X- _ O
generator -X- _ O
with -X- _ O
a -X- _ O
noise -X- _ O
vector -X- _ O
as -X- _ O
input -X- _ O
, -X- _ O
as -X- _ O
is -X- _ O
typical -X- _ O
with -X- _ O
a -X- _ O
GAN -X- _ O
. -X- _ O

3Typically -X- _ O
k -X- _ O
= -X- _ O
⌈0.15n⌉ -X- _ O
, -X- _ O
i.e. -X- _ O
, -X- _ O
15 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
tokens -X- _ O
are -X- _ O
masked -X- _ O
out -X- _ O
. -X- _ O

Although -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
training -X- _ O
objective -X- _ O
of -X- _ O
a -X- _ O
GAN -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
several -X- _ O
key -X- _ O
differences -X- _ O
. -X- _ O
First -X- _ O
, -X- _ O
if -X- _ O
the -X- _ O
generator -X- _ O
happens -X- _ O
to -X- _ O
generate -X- _ O
the -X- _ O
correct -X- _ O
token -X- _ O
, -X- _ O
that -X- _ O
token -X- _ O
is -X- _ O
considered -X- _ O
“ -X- _ O
real -X- _ O
” -X- _ O
instead -X- _ O
of -X- _ O
“ -X- _ O
fake -X- _ O
” -X- _ O
; -X- _ O
we -X- _ O
found -X- _ O
this -X- _ O
formulation -X- _ O
to -X- _ O
moderately -X- _ O
improve -X- _ O
results -X- _ O
on -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
More -X- _ O
importantly -X- _ O
, -X- _ O
the -X- _ O
generator -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
maximum -X- _ B-MetricName
likelihood -X- _ I-MetricName
rather -X- _ O
than -X- _ O
being -X- _ O
trained -X- _ O
adversarially -X- _ O
to -X- _ O
fool -X- _ O
the -X- _ O
discriminator -X- _ O
. -X- _ O
Adversarially -X- _ O
training -X- _ O
the -X- _ O
generator -X- _ O
is -X- _ O
challenging -X- _ O
because -X- _ O
it -X- _ O
is -X- _ O
impossible -X- _ O
to -X- _ O
back- -X- _ O
propagate -X- _ O
through -X- _ O
sampling -X- _ O
from -X- _ O
the -X- _ O
generator -X- _ O
. -X- _ O
Although -X- _ O
we -X- _ O
experimented -X- _ O
circumventing -X- _ O
this -X- _ O
issue -X- _ O

t=1 -X- _ O
−1(xcorrupt -X- _ O
t -X- _ O
= -X- _ O
xt -X- _ O
) -X- _ O
log -X- _ O
D(xcorrupt -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
− -X- _ O
1(xcorrupt -X- _ O
t -X- _ O
̸= -X- _ O
xt -X- _ O
) -X- _ O
log(1 -X- _ O
− -X- _ O
D(xcorrupt -X- _ O
, -X- _ O
t -X- _ O
) -X- _ O
) -X- _ O

ˆxi -X- _ O
∼ -X- _ O
pG(xi|xmasked -X- _ O
) -X- _ O
for -X- _ O
i -X- _ O
∈ -X- _ O
m -X- _ O
xcorrupt -X- _ O
= -X- _ O
REPLACE(x -X- _ O
, -X- _ O
m -X- _ O
, -X- _ O
ˆx -X- _ O
) -X- _ O

mi -X- _ O
∼ -X- _ O
unif{1 -X- _ O
, -X- _ O
n -X- _ O
} -X- _ O
for -X- _ O
i -X- _ O
= -X- _ O
1 -X- _ O
to -X- _ O
k -X- _ O
xmasked -X- _ O
= -X- _ O
REPLACE(x -X- _ O
, -X- _ O
m -X- _ O
, -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
) -X- _ O

The -X- _ O
generator -X- _ O
is -X- _ O
trained -X- _ O
to -X- _ O
perform -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
( -X- _ O
MLM -X- _ O
) -X- _ O
. -X- _ O
Given -X- _ O
an -X- _ O
input -X- _ O
x -X- _ O
= -X- _ O
[ -X- _ O
x1 -X- _ O
, -X- _ O
x2 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
xn -X- _ O
] -X- _ O
, -X- _ O
MLM -X- _ O
ﬁrst -X- _ O
select -X- _ O
a -X- _ O
random -X- _ O
set -X- _ O
of -X- _ O
positions -X- _ O
( -X- _ O
integers -X- _ O
between -X- _ O
1 -X- _ O
and -X- _ O
n -X- _ O
) -X- _ O
to -X- _ O
mask -X- _ O
out -X- _ O
m -X- _ O
= -X- _ O
[ -X- _ O
m1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
mk].3 -X- _ O
The -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
selected -X- _ O
positions -X- _ O
are -X- _ O
replaced -X- _ O
with -X- _ O
a -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
token -X- _ O
: -X- _ O
we -X- _ O
denote -X- _ O
this -X- _ O
as -X- _ O
xmasked -X- _ O
= -X- _ O
REPLACE(x -X- _ O
, -X- _ O
m -X- _ O
, -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
) -X- _ O
. -X- _ O
The -X- _ O
generator -X- _ O
then -X- _ O
learns -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
original -X- _ O
identities -X- _ O
of -X- _ O
the -X- _ O
masked -X- _ O
- -X- _ O
out -X- _ O
tokens -X- _ O
. -X- _ O
The -X- _ O
discriminator -X- _ O
is -X- _ O
trained -X- _ O
to -X- _ O
distinguish -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
data -X- _ O
from -X- _ O
tokens -X- _ O
that -X- _ O
have -X- _ O
been -X- _ O
replaced -X- _ O
by -X- _ O
generator -X- _ O
samples -X- _ O
. -X- _ O
More -X- _ O
speciﬁcally -X- _ O
, -X- _ O
we -X- _ O
create -X- _ O
a -X- _ O
corrupted -X- _ O
example -X- _ O
xcorrupt -X- _ O
by -X- _ O
replacing -X- _ O
the -X- _ O
masked -X- _ O
- -X- _ O
out -X- _ O
tokens -X- _ O
with -X- _ O
generator -X- _ O
samples -X- _ O
and -X- _ O
train -X- _ O
the -X- _ O
discriminator -X- _ O
to -X- _ O
predict -X- _ O
which -X- _ O
tokens -X- _ O
in -X- _ O
xcorrupt -X- _ O
match -X- _ O
the -X- _ O
original -X- _ O
input -X- _ O
x. -X- _ O
Formally -X- _ O
, -X- _ O
model -X- _ O
inputs -X- _ O
are -X- _ O
constructed -X- _ O
according -X- _ O
to -X- _ O

where -X- _ O
e -X- _ O
denotes -X- _ O
token -X- _ O
embeddings -X- _ O
. -X- _ O
For -X- _ O
a -X- _ O
given -X- _ O
position -X- _ O
t -X- _ O
, -X- _ O
the -X- _ O
discriminator -X- _ O
predicts -X- _ O
whether -X- _ O
the -X- _ O
token -X- _ O
xt -X- _ O
is -X- _ O
“ -X- _ O
real -X- _ O
, -X- _ O
” -X- _ O
i.e. -X- _ O
, -X- _ O
that -X- _ O
it -X- _ O
comes -X- _ O
from -X- _ O
the -X- _ O
data -X- _ O
rather -X- _ O
than -X- _ O
the -X- _ O
generator -X- _ O
distribution -X- _ O
, -X- _ O
with -X- _ O
a -X- _ O
sigmoid -X- _ O
output -X- _ O
layer -X- _ O
: -X- _ O

Our -X- _ O
approach -X- _ O
trains -X- _ O
two -X- _ O
neural -X- _ O
networks -X- _ O
, -X- _ O
a -X- _ O
generator -X- _ O
G -X- _ O
and -X- _ O
a -X- _ O
discriminator -X- _ O
D. -X- _ O
Each -X- _ O
one -X- _ O
primarily -X- _ O
consists -X- _ O
of -X- _ O
an -X- _ O
encoder -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
a -X- _ O
Transformer -X- _ O
network -X- _ O
) -X- _ O
that -X- _ O
maps -X- _ O
a -X- _ O
sequence -X- _ O
on -X- _ O
input -X- _ O
tokens -X- _ O
x -X- _ O
= -X- _ O
[ -X- _ O
x1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
xn -X- _ O
] -X- _ O
into -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
contextualized -X- _ O
vector -X- _ O
representations -X- _ O
h(x -X- _ O
) -X- _ O
= -X- _ O
[ -X- _ O
h1 -X- _ O
, -X- _ O
... -X- _ O
, -X- _ O
hn -X- _ O
] -X- _ O
. -X- _ O
For -X- _ O
a -X- _ O
given -X- _ O
position -X- _ O
t -X- _ O
, -X- _ O
( -X- _ O
in -X- _ O
our -X- _ O
case -X- _ O
only -X- _ O
positions -X- _ O
where -X- _ O
xt -X- _ O
= -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
) -X- _ O
, -X- _ O
the -X- _ O
generator -X- _ O
outputs -X- _ O
a -X- _ O
probability -X- _ O
for -X- _ O
generating -X- _ O
a -X- _ O
particular -X- _ O
token -X- _ O
xt -X- _ O
with -X- _ O
a -X- _ O
softmax -X- _ O
layer -X- _ O
: -X- _ O

We -X- _ O
ﬁrst -X- _ O
describe -X- _ O
the -X- _ O
replaced -X- _ O
token -X- _ O
detection -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
task -X- _ O
; -X- _ O
see -X- _ O
Figure -X- _ O
2 -X- _ O
for -X- _ O
an -X- _ O
overview -X- _ O
. -X- _ O
We -X- _ O
suggest -X- _ O
and -X- _ O
evaluate -X- _ O
several -X- _ O
modeling -X- _ O
improvements -X- _ O
for -X- _ O
this -X- _ O
method -X- _ O
in -X- _ O
Section -X- _ O
3.2 -X- _ O
. -X- _ O

Most -X- _ O
current -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
methods -X- _ O
require -X- _ O
large -X- _ O
amounts -X- _ O
of -X- _ O
compute -X- _ O
to -X- _ O
be -X- _ O
effective -X- _ O
, -X- _ O
raising -X- _ O
con- -X- _ O
cerns -X- _ O
about -X- _ O
their -X- _ O
cost -X- _ O
and -X- _ O
accessibility -X- _ O
. -X- _ O
Since -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
with -X- _ O
more -X- _ O
compute -X- _ O
almost -X- _ O
always -X- _ O
re- -X- _ O
sults -X- _ O
in -X- _ O
better -X- _ O
downstream -X- _ O
accuracies -X- _ O
, -X- _ O
we -X- _ O
argue -X- _ O
an -X- _ O
important -X- _ O
consideration -X- _ O
for -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
methods -X- _ O
should -X- _ O
be -X- _ O
compute -X- _ O
efﬁciency -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
absolute -X- _ O
downstream -X- _ O
performance -X- _ O
. -X- _ O
From -X- _ O
this -X- _ O
viewpoint -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
ELECTRA -X- _ B-MethodName
models -X- _ O
of -X- _ O
various -X- _ O
sizes -X- _ O
and -X- _ O
evaluate -X- _ O
their -X- _ O
downstream -X- _ O
performance -X- _ O
vs. -X- _ O
their -X- _ O
compute -X- _ O
requirement -X- _ O
. -X- _ O
In -X- _ O
particular -X- _ O
, -X- _ O
we -X- _ O
run -X- _ O
experiments -X- _ O
on -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
natural -X- _ B-TaskName
language -X- _ I-TaskName
understand- -X- _ I-TaskName
ing -X- _ I-TaskName
benchmark -X- _ O
( -X- _ O
Wang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
SQuAD -X- _ B-DatasetName
question -X- _ B-TaskName
answering -X- _ I-TaskName
benchmark -X- _ O
( -X- _ O
Rajpurkar -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2016 -X- _ O
) -X- _ O
. -X- _ O
ELECTRA -X- _ B-MethodName
substantially -X- _ O
outperforms -X- _ O
MLM -X- _ O
- -X- _ O
based -X- _ O
methods -X- _ O
such -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
XLNet -X- _ B-MethodName
given -X- _ O
the -X- _ O
same -X- _ O
model -X- _ O
size -X- _ O
, -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
compute -X- _ O
( -X- _ O
see -X- _ O
Figure -X- _ O
1 -X- _ O
) -X- _ O
. -X- _ O
For -X- _ O
example -X- _ O
, -X- _ O
we -X- _ O
build -X- _ O
an -X- _ O
ELECTRA -X- _ B-MethodName
- -X- _ O
Small -X- _ O
model -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
trained -X- _ O
on -X- _ O
1 -X- _ O
GPU -X- _ O
in -X- _ O
4 -X- _ O
days.2 -X- _ O
ELECTRA -X- _ B-MethodName
- -X- _ O
Small -X- _ O
outperforms -X- _ O
a -X- _ O
comparably -X- _ O
small -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
by -X- _ O
5 -X- _ B-MetricValue
points -X- _ O
on -X- _ O
GLUE -X- _ B-DatasetName
, -X- _ O
and -X- _ O
even -X- _ O
outperforms -X- _ O
the -X- _ O
much -X- _ O
larger -X- _ O
GPT -X- _ B-MethodName
model -X- _ O
( -X- _ O
Radford -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O
Our -X- _ O
approach -X- _ O
also -X- _ O
works -X- _ O
well -X- _ O
at -X- _ O
large -X- _ O
scale -X- _ O
, -X- _ O
where -X- _ O
we -X- _ O
train -X- _ O
an -X- _ O
ELECTRA -X- _ B-MethodName
- -X- _ O
Large -X- _ O
model -X- _ O
that -X- _ O
performs -X- _ O
comparably -X- _ O
to -X- _ O
RoBERTa -X- _ B-MethodName
( -X- _ O
Liu -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
and -X- _ O
XLNet -X- _ B-MethodName
( -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
, -X- _ O
de- -X- _ O
spite -X- _ O
having -X- _ O
fewer -X- _ O
parameters -X- _ O
and -X- _ O
using -X- _ O
1/4 -X- _ O
of -X- _ O
the -X- _ O
compute -X- _ O
for -X- _ O
training -X- _ O
. -X- _ O
Training -X- _ O
ELECTRA -X- _ B-MethodName
- -X- _ O
Large -X- _ O
further -X- _ O
results -X- _ O
in -X- _ O
an -X- _ O
even -X- _ O
stronger -X- _ O
model -X- _ O
that -X- _ O
outperforms -X- _ O
ALBERT -X- _ B-MethodName
( -X- _ O
Lan -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2019 -X- _ O
) -X- _ O
on -X- _ O
GLUE -X- _ B-DatasetName
and -X- _ O
sets -X- _ O
a -X- _ O
new -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
for -X- _ O
SQuAD -X- _ B-MethodName
2.0 -X- _ I-MethodName
. -X- _ O
Taken -X- _ O
together -X- _ O
, -X- _ O
our -X- _ O
results -X- _ O
indicate -X- _ O
that -X- _ O
the -X- _ O
discrim- -X- _ B-TaskName
inative -X- _ I-TaskName
task -X- _ O
of -X- _ O
distinguishing -X- _ O
real -X- _ O
data -X- _ O
from -X- _ O
challenging -X- _ O
negative -X- _ O
samples -X- _ O
is -X- _ O
more -X- _ O
compute -X- _ O
- -X- _ O
efﬁcient -X- _ O
and -X- _ O
parameter -X- _ O
- -X- _ O
efﬁcient -X- _ O
than -X- _ O
existing -X- _ O
generative -X- _ O
approaches -X- _ O
for -X- _ O
language -X- _ O
representation -X- _ O
learning -X- _ O
. -X- _ O

We -X- _ O
call -X- _ O
our -X- _ O
approach -X- _ O
ELECTRA1 -X- _ B-MethodName
for -X- _ O
“ -X- _ O
Efﬁciently -X- _ O
Learning -X- _ O
an -X- _ O
Encoder -X- _ O
that -X- _ O
Classiﬁes -X- _ O
Token -X- _ O
Re- -X- _ O
placements -X- _ O
Accurately -X- _ O
. -X- _ O
” -X- _ O
As -X- _ O
in -X- _ O
prior -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
apply -X- _ O
it -X- _ O
to -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
Transformer -X- _ O
text -X- _ O
encoders -X- _ O
( -X- _ O
Vaswani -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2017 -X- _ O
) -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
ﬁne -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
Through -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
ablations -X- _ O
, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
learning -X- _ O
from -X- _ O
all -X- _ O
input -X- _ O
positions -X- _ O
causes -X- _ O
ELECTRA -X- _ B-MethodName
to -X- _ O
train -X- _ O
much -X- _ O
faster -X- _ O
than -X- _ O
BERT -X- _ B-MethodName
. -X- _ O
We -X- _ O
also -X- _ O
show -X- _ O
ELECTRA -X- _ B-MethodName
achieves -X- _ O
higher -X- _ O
accuracy -X- _ B-MetricName
on -X- _ O
downstream -X- _ O
tasks -X- _ O
when -X- _ O
fully -X- _ O
trained -X- _ O
. -X- _ O

approach -X- _ O
is -X- _ O
reminiscent -X- _ O
of -X- _ O
training -X- _ O
the -X- _ O
discriminator -X- _ O
of -X- _ O
a -X- _ O
GAN -X- _ B-MethodName
, -X- _ O
our -X- _ O
method -X- _ O
is -X- _ O
not -X- _ O
adversarial -X- _ O
in -X- _ O
that -X- _ O
the -X- _ O
generator -X- _ O
producing -X- _ O
corrupted -X- _ O
tokens -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
maximum -X- _ B-MetricName
likelihood -X- _ I-MetricName
due -X- _ O
to -X- _ O
the -X- _ O
difﬁculty -X- _ O
of -X- _ O
applying -X- _ O
GANs -X- _ B-MethodName
to -X- _ O
text -X- _ O
( -X- _ O
Caccia -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2018 -X- _ O
) -X- _ O
. -X- _ O

Replaced -X- _ O
Token -X- _ O
Detection -X- _ O
Pre -X- _ O
- -X- _ O
training -X- _ O
Masked -X- _ O
Language -X- _ O
Model -X- _ O
Pre -X- _ O
- -X- _ O
training -X- _ O

As -X- _ O
an -X- _ O
alternative -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
replaced -X- _ O
token -X- _ O
detection -X- _ O
, -X- _ O
a -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
task -X- _ O
in -X- _ O
which -X- _ O
the -X- _ O
model -X- _ O
learns -X- _ O
to -X- _ O
distinguish -X- _ O
real -X- _ O
input -X- _ O
tokens -X- _ O
from -X- _ O
plausible -X- _ O
but -X- _ O
synthetically -X- _ O
generated -X- _ O
replacements -X- _ O
. -X- _ O
Instead -X- _ O
of -X- _ O
masking -X- _ O
, -X- _ O
our -X- _ O
method -X- _ O
corrupts -X- _ O
the -X- _ O
input -X- _ O
by -X- _ O
replacing -X- _ O
some -X- _ O
tokens -X- _ O
with -X- _ O
samples -X- _ O
from -X- _ O
a -X- _ O
proposal -X- _ O
distribution -X- _ O
, -X- _ O
which -X- _ O
is -X- _ O
typically -X- _ O
the -X- _ O
output -X- _ O
of -X- _ O
a -X- _ O
small -X- _ O
masked -X- _ O
language -X- _ O
model -X- _ O
. -X- _ O
This -X- _ O
corruption -X- _ O
proce- -X- _ O
dure -X- _ O
solves -X- _ O
a -X- _ O
mismatch -X- _ O
in -X- _ O
BERT -X- _ B-MethodName
( -X- _ O
although -X- _ O
not -X- _ O
in -X- _ O
XLNet -X- _ B-MethodName
) -X- _ O
where -X- _ O
the -X- _ O
network -X- _ O
sees -X- _ O
artiﬁcial -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
tokens -X- _ O
during -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
but -X- _ O
not -X- _ O
when -X- _ O
being -X- _ O
ﬁne -X- _ O
- -X- _ O
tuned -X- _ O
on -X- _ O
downstream -X- _ O
tasks -X- _ O
. -X- _ O
We -X- _ O
then -X- _ O
pre -X- _ O
- -X- _ O
train -X- _ O
the -X- _ O
network -X- _ O
as -X- _ O
a -X- _ O
discriminator -X- _ O
that -X- _ O
predicts -X- _ O
for -X- _ O
every -X- _ O
token -X- _ O
whether -X- _ O
it -X- _ O
is -X- _ O
an -X- _ O
original -X- _ O
or -X- _ O
a -X- _ O
replacement -X- _ O
. -X- _ O
In -X- _ O
contrast -X- _ O
, -X- _ O
MLM -X- _ O
trains -X- _ O
the -X- _ O
network -X- _ O
as -X- _ O
a -X- _ O
generator -X- _ O
that -X- _ O
predicts -X- _ O
the -X- _ O
original -X- _ O
identities -X- _ O
of -X- _ O
the -X- _ O
corrupted -X- _ O
tokens -X- _ O
. -X- _ O
A -X- _ O
key -X- _ O
advantage -X- _ O
of -X- _ O
our -X- _ O
discriminative -X- _ O
task -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
learns -X- _ O
from -X- _ O
all -X- _ O
input -X- _ O
tokens -X- _ O
instead -X- _ O
of -X- _ O
just -X- _ O
the -X- _ O
small -X- _ O
masked -X- _ O
- -X- _ O
out -X- _ O
subset -X- _ O
, -X- _ O
making -X- _ O
it -X- _ O
more -X- _ O
computationally -X- _ O
efﬁcient -X- _ O
. -X- _ O
Although -X- _ O
our -X- _ O

Current -X- _ O
state -X- _ O
- -X- _ O
of -X- _ O
- -X- _ O
the -X- _ O
- -X- _ O
art -X- _ O
representation -X- _ O
learning -X- _ O
methods -X- _ O
for -X- _ O
language -X- _ O
can -X- _ O
be -X- _ O
viewed -X- _ O
as -X- _ O
learning -X- _ O
denoising -X- _ O
autoencoders -X- _ O
( -X- _ O
Vincent -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
, -X- _ O
2008 -X- _ O
) -X- _ O
. -X- _ O
They -X- _ O
select -X- _ O
a -X- _ O
small -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
unlabeled -X- _ O
input -X- _ O
sequence -X- _ O
( -X- _ O
typically -X- _ O
15 -X- _ O
% -X- _ O
) -X- _ O
, -X- _ O
mask -X- _ O
the -X- _ O
identities -X- _ O
of -X- _ O
those -X- _ O
tokens -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
; -X- _ O
Devlin -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
) -X- _ O
or -X- _ O
attention -X- _ O
to -X- _ O
those -X- _ O
tokens -X- _ O
( -X- _ O
e.g. -X- _ O
, -X- _ O
XLNet -X- _ O
; -X- _ O
Yang -X- _ O
et -X- _ O
al -X- _ O
. -X- _ O
( -X- _ O
2019 -X- _ O
) -X- _ O
) -X- _ O
, -X- _ O
and -X- _ O
then -X- _ O
train -X- _ O
the -X- _ O
network -X- _ O
to -X- _ O
recover -X- _ O
the -X- _ O
original -X- _ O
input -X- _ O
. -X- _ O
While -X- _ O
more -X- _ O
effective -X- _ O
than -X- _ O
conventional -X- _ O
language -X- _ O
- -X- _ O
model -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
due -X- _ O
to -X- _ O
learning -X- _ O
bidirectional -X- _ O
representations -X- _ O
, -X- _ O
these -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
( -X- _ O
MLM -X- _ O
) -X- _ O
approaches -X- _ O
incur -X- _ O
a -X- _ O
substan- -X- _ O
tial -X- _ O
compute -X- _ O
cost -X- _ O
because -X- _ O
the -X- _ O
network -X- _ O
only -X- _ O
learns -X- _ O
from -X- _ O
15 -X- _ O
% -X- _ O
of -X- _ O
the -X- _ O
tokens -X- _ O
per -X- _ O
example -X- _ O
. -X- _ O

Masked -X- _ O
language -X- _ O
modeling -X- _ O
( -X- _ O
MLM -X- _ O
) -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
methods -X- _ O
such -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
corrupt -X- _ O
the -X- _ O
input -X- _ O
by -X- _ O
replacing -X- _ O
some -X- _ O
tokens -X- _ O
with -X- _ O
[ -X- _ O
MASK -X- _ O
] -X- _ O
and -X- _ O
then -X- _ O
train -X- _ O
a -X- _ O
model -X- _ O
to -X- _ O
re- -X- _ O
construct -X- _ O
the -X- _ O
original -X- _ O
tokens -X- _ O
. -X- _ O
While -X- _ O
they -X- _ O
produce -X- _ O
good -X- _ O
results -X- _ O
when -X- _ O
transferred -X- _ O
to -X- _ O
downstream -X- _ O
NLP -X- _ O
tasks -X- _ O
, -X- _ O
they -X- _ O
generally -X- _ O
require -X- _ O
large -X- _ O
amounts -X- _ O
of -X- _ O
compute -X- _ O
to -X- _ O
be -X- _ O
effective -X- _ O
. -X- _ O
As -X- _ O
an -X- _ O
alternative -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
more -X- _ O
sample -X- _ O
- -X- _ O
efﬁcient -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
task -X- _ O
called -X- _ O
replaced -X- _ O
token -X- _ O
detection -X- _ O
. -X- _ O
Instead -X- _ O
of -X- _ O
masking -X- _ O
the -X- _ O
input -X- _ O
, -X- _ O
our -X- _ O
approach -X- _ O
cor- -X- _ O
rupts -X- _ O
it -X- _ O
by -X- _ O
replacing -X- _ O
some -X- _ O
tokens -X- _ O
with -X- _ O
plausible -X- _ O
alternatives -X- _ O
sampled -X- _ O
from -X- _ O
a -X- _ O
small -X- _ O
generator -X- _ O
network -X- _ O
. -X- _ O
Then -X- _ O
, -X- _ O
instead -X- _ O
of -X- _ O
training -X- _ O
a -X- _ O
model -X- _ O
that -X- _ O
predicts -X- _ O
the -X- _ O
original -X- _ O
identities -X- _ O
of -X- _ O
the -X- _ O
corrupted -X- _ O
tokens -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
discriminative -X- _ O
model -X- _ O
that -X- _ O
predicts -X- _ O
whether -X- _ O
each -X- _ O
token -X- _ O
in -X- _ O
the -X- _ O
corrupted -X- _ O
input -X- _ O
was -X- _ O
replaced -X- _ O
by -X- _ O
a -X- _ O
generator -X- _ O
sample -X- _ O
or -X- _ O
not -X- _ O
. -X- _ O
Thorough -X- _ O
experiments -X- _ O
demonstrate -X- _ O
this -X- _ O
new -X- _ O
pre -X- _ O
- -X- _ O
training -X- _ O
task -X- _ O
is -X- _ O
more -X- _ O
ef- -X- _ O
ﬁcient -X- _ O
than -X- _ O
MLM -X- _ O
because -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
deﬁned -X- _ O
over -X- _ O
all -X- _ O
input -X- _ O
tokens -X- _ O
rather -X- _ O
than -X- _ O
just -X- _ O
the -X- _ O
small -X- _ O
subset -X- _ O
that -X- _ O
was -X- _ O
masked -X- _ O
out -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
result -X- _ O
, -X- _ O
the -X- _ O
contextual -X- _ O
representa- -X- _ O
tions -X- _ O
learned -X- _ O
by -X- _ O
our -X- _ O
approach -X- _ O
substantially -X- _ O
outperform -X- _ O
the -X- _ O
ones -X- _ O
learned -X- _ O
by -X- _ O
BERT -X- _ B-MethodName
given -X- _ O
the -X- _ O
same -X- _ O
model -X- _ O
size -X- _ O
, -X- _ O
data -X- _ O
, -X- _ O
and -X- _ O
compute -X- _ O
. -X- _ O
The -X- _ O
gains -X- _ O
are -X- _ O
particularly -X- _ O
strong -X- _ O
for -X- _ O
small -X- _ O
models -X- _ O
; -X- _ O
for -X- _ O
example -X- _ O
, -X- _ O
we -X- _ O
train -X- _ O
a -X- _ O
model -X- _ O
on -X- _ O
one -X- _ O
GPU -X- _ O
for -X- _ O
4 -X- _ O
days -X- _ O
that -X- _ O
outperforms -X- _ O
GPT -X- _ B-MethodName
( -X- _ O
trained -X- _ O
using -X- _ O
30x -X- _ O
more -X- _ O
compute -X- _ O
) -X- _ O
on -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
natural -X- _ O
lan- -X- _ O
guage -X- _ O
understanding -X- _ O
benchmark -X- _ O
. -X- _ O
Our -X- _ O
approach -X- _ O
also -X- _ O
works -X- _ O
well -X- _ O
at -X- _ O
scale -X- _ O
, -X- _ O
where -X- _ O
it -X- _ O
performs -X- _ O
comparably -X- _ O
to -X- _ O
RoBERTa -X- _ B-MethodName
and -X- _ O
XLNet -X- _ B-MethodName
while -X- _ O
using -X- _ O
less -X- _ O
than -X- _ O
1/4 -X- _ O
of -X- _ O
their -X- _ O
compute -X- _ O
and -X- _ O
outperforms -X- _ O
them -X- _ O
when -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
amount -X- _ O
of -X- _ O
compute -X- _ O
. -X- _ O

ELECTRA -X- _ B-MethodName
: -X- _ O
PRE -X- _ O
- -X- _ O
TRAINING -X- _ O
TEXT -X- _ O
ENCODERS -X- _ O
AS -X- _ O
DISCRIMINATORS -X- _ O
RATHER -X- _ O
THAN -X- _ O
GENERATORS -X- _ O

